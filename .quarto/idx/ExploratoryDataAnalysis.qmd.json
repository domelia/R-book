{"title":"Разведочный анализ данных в R","markdown":{"yaml":{"title":"Разведочный анализ данных в R"},"headingText":"Для чего нам нужен разведочный анализ (Exploratory Data Analysis)","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\n**Разведочный анализ** в общем смысле – это предварительный анализ данных с целью выявления наиболее общих зависимостей, закономерностей и тенденций, характера и свойств анализируемых данных, законов распределения анализируемых величин. Именно с разведочного анализа начинается любая обработка данных результатов научного исследования.\n\n![](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/data/media/exploratory-data-analytics/sandboxing.png)\n\nПри этом, разведочный анализ - это не какой-то один статистический тест или метод. При разведочном анализе учитывается и сравнивается большое число признаков, а для поиска закономерностей или обоснования имеющихся различий используются самые разные процедуры и техники.\n\nТермин «разведочный анализ» и набор техник, которые применяются для его проведения, был впервые введен и популяризирован американским математиком и статистиком из Принстонского университета **Джоном Тьюки**, написавшим в 1977 году книгу «Разведочный анализ данных» (Exploratory Data Analysis).\n\n![](data:image/jpeg;base64,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)\n\nЭтот термин кажется «сухим» и «занудным», однако практики, используемые в рамках разведочного анализа, не только являются крайне важными, но и весьма волнующими для исследователя. Не случайно, сам Дж. Тьюки сравнил EDA с работой детектива: каждый новое исследование данных представляет собой «мистическую историю», которую мы должны расследовать, вскрыть скрытые свойства и секретные характеристики наших данных.\n\nОсновными целями разведочного анализа являются:\n\n- проникновение в данные и описание их во всей полноте;\n- выявление основных структур (паттернов) и тенденций;\n- идентификация взаимосвязей и корреляций между переменными\n- выбор наиболее важных переменных;\n- обнаружение отклонений и аномалий;\n- проверка основных гипотез (предположений);\n- разработка начальных моделей и подготовка данных для дальнейшего анализа.\n\nРезультаты разведочного анализа не используются напрямую для выработки управленческих решений, скорее они предоставляют помощь в разработке лучшей стратегии углубленного анализа, способствуют выдвижению новых гипотез, обосновывают возможности применения тех или иных математических методов и моделей. Без разведочного анализа дальнейший анализ данных, часто включающий разработку комплексных статистических моделей, будет производиться практически «вслепую».\n\n**Разведочный (эксплораторный, описательный)** анализ данных по своему содержанию, целям и задачам противопоставлен **подтверждающему** анализу данных (Confirmatory Data Analysis), основанному на конкретных предположениях и уже имеющихся данных.\n\nК основным методам разведочного анализа относятся анализ распределений, особенно с помощью методов визуального анализа (гистограмм, диаграмм рассеяния, ящичных диаграмм), тестирование гипотез о соответствии определенному виду распределения, методы группового и корреляционного анализа. Довольно часто к методам разведочного анализа также относят техники, позволяющие осуществить кластеризацию и снизить размерность данных, графически представить высоко-размерные данные, включающие множество переменных, в также предсказательные модели, такие как линейная регрессия, использующие данные и статистические показатели для предсказания целевых показателей. В рамках данного пособия такие методы будут рассмотрены в следующем разделе, посвященном многомерному анализу и возможностям статистического моделирования.\n\n## Анализ характеристик распределения количественной переменной\n\nМы начнем наше разведочное исследование с количественных переменных и затем перейдем к категориальным переменным, двумерному и корреляционному анализу.\n\nЧтобы наши действия были ближе к «социологической жизни», мы будем использовать результаты исследования восприятия и оценки адаптивных стратегий населения в отношении климатических рисков в высокогорных районах Алтая.\n\n:::callout-info\nЕсли Вы не сохранили данные с предыдущих занятий, скачайте их еще раз.\n\nСкачать [данные](https://github.com/domelia/R-book/blob/main/files/База_КлимРиск_2023.sav)/\n:::\n\n```{r}\nlibrary(haven)\ndf<-read_sav(\"files/База_КлимРиск_2023.sav\")\n```\n\nПрежде, чем мы начнем «препарировать» наши данные, давайте взглянем на них издалека, в целом. Для этой цели хорошо подойдут библиотеки так называемого автоматизированного разведочного анализа, позволяющие быстро подготовить отчеты сразу по всему массиву данных, представить остовные статистики и графики. В R существует по меньшей мере 10 таких библиотек, наиболее известными из которых являются:\n- summarytools\n- DataExplorer\n- visdat\n- funModeling\n- arsenal\n- dataMaid\n- dlookr\n\nПодробный анализ данных библиотек в действии, их положительных и отрицательных сторон, можно найти в статье: *Mateusz Staniak* и *Przemysław Biecek* [**The Landscape of RPackages for Automated Exploratory Data Analysis**](https://arxiv.org/pdf/1904.02101).\n\nМы воспользуемся некоторыми функциями библиотеки `DataExplorer`. \nДля начала установим ее:\n```{r eval=FALSE}\ninstall.packages(\"DataExplorer\")\n```\n\nПосле установки, как всегда, загружаем библиотеку в текущую сессию и запускаем ее:\n```{r message=FALSE, warning=FALSE}\nlibrary(DataExplorer)\n```\n\nДавайте проведем самый общий анализ по всей базе данных с помощью функции `introduce()`, которая выдаст нам самые общие сведения: количество строк и колонок (переменных), сколько из них являются дискретными и непрерывными, если такие переменные, в которых все данные пропущены, а также данные о количестве наблюдений и пропущенных значений.\n\n```{r eval=FALSE}\nintroduce(df)\n```\n\n```{r echo=FALSE}\nlibrary(tidyselect)\nlibrary(kableExtra)\nintroduce(df) %>% \n  t() %>% \n  kbl()\n```\n\n\nЧтобы визуализировать данную таблицу, можно использовать функцию `plot_intro()`. На графике отображаются основные показатели набора данных - количество дискретных и непрерывных переменных, полных наблюдений и переменных с отстутствующими значениями. \n\nПочему у нас так много пропусков и нет ни одной строки с полными данными? Все просто: ведь в ходе анализа учитываются абсолютно все переменные набора, включая дополнительные переменные «Другое», которые вполне могли остаться пустыми, если респондент не выбирал данный вариант ответа, а также переменные, предназначенные для определенных категорий респондентов, на которые по определению отвечали не все. Если бы мы отобрали меньшее количество переменных, которые нам нужны для конкретного анализа, результаты были бы совершенно иными. Кроме того, следует учитывать, что при подсчете «дискретных» и «непрерывных» переменных функция руководствуется результатам присвоения категорий данных в SPSS и их импорта в `haven`. Так что, если изначально тип переменной был задан неверно, то и результаты такого анализа, мягко скажем, не будут соответствовать действительности.\n\n```{r}\nplot_intro(df)\n```\n\nВ доказательство вышеприведенного тезиса приведем график пропущенных значений по некоторым переменным. Можно легко заметить, что переменные образуют две группы - те, где количество пропусков не составляет выше 5% и переменные, где пропусков существенно больше (обозначены оранжевым цветом). Это ответы на вопрос 9, где спрашивалось о том, каким имуществом владели домохозяйства, проживающие в горных районах (сельхозтехника, сад, огород, пастбище, участки леса и пр.). Нет ничего удивительного в том, что более пятой части опрошенных не обладали ни одним из перечисленных вариантов, более того, часть из них, учитывая, что опрос проводился в зонах экстремального земледелия (приравненных к условиям Крайнего Севера), можно считать признаками высокого статуса и богатства (например, если у жителя есть в пользовании теплица и он может сам выращивать овощи). \n\n```{r}\nplot_missing(df[,30:50])\n```\n\n### Основные описательные характеристики\n\nУ нас не так много количественных данных, и одной из непрерывных переменных является возраст (`age`).\n\nСамым простым способом анализа основных характеристик распределения является базовая функция `summary()`, предоставляющая семь ключевых статистик: минимум, максимум, среднее, медиану, 1-й и 3-й квартили, а также количество пропущенных значений:\n```{r}\nsummary(df$age)\n```\n\nБолее расширенный статистический анализ можно получить, обратившись к функции `describe()`из библиотеки `psych` (не забываем устанавливать новые библиотеки). Набор аргументов по умолчанию достаточно широк: здесь уже есть и стандартное отклонение, и усеченное среднее, и показатели асимметрии и эксцесса.\n```{r eval=FALSE}\npsych::describe(df$age)\n```\n```{r echo=FALSE}\npsych::describe(df$age) %>% \n  t() %>% \n  kbl(digits = 2, label = \"Возраст опрошенных\")\n```\nВпрочем, каждый из них можно получить отдельно, с помощью базовых функций, например, стандартное отклонение:\n```{r}\nsd(df$age, na.rm = T)\n```\nДисперсия:\n```{r}\nvar(df$age, na.rm = T)\n```\nАсимметрия:\n\n```{r}\npsych::skew(df$age, na.rm = T)\n```\n### Графические методы анализа распределения\n\nБольшую роль в анализе данных играет визуализация, и в случае анализа количественных переменных она просто незаменима. Часто именно график, без какого-либо статистического анализа, дает лучшее представление о том, что происходит с данными, тогда как статистические «точечные» оценки, такие как среднее или дисперсия, могут ввести в заблуждение. \n\nКоличественную переменную обычно графически представляют несколькими разными способами:\n- с помощью гистограмм;\n- с помощью квантильного графика;\n- с помощью ящичной диаграммы.\n\nСамый быстрый и простой способ получения гистограммы - с помощью базовой функции `hist()`:\n```{r}\nhist(df$age, col=\"steelblue\", xlab = \"Возраст (лет)\", main=\"Возраст опрошенных\")\n```\nЕсли мы хотим более «продвинутый» вариант гистограммы, можно обратиться к возможностям библиотеки `ggstatsplots`, основанной на философии создания визуальных материалов в рамках библиотеки `ggplot2` и предназначенной для создания публикабельных визуализаций, сопровожденной результатами статистического анализа и возможностями проверки статистических гипотез. При несколько излишней сложности, это, пожалуй, лучшее, что есть сегодня в плане описательного анализа. Это не просто библиотека, создающая графики, это одновременно и способ визуализации, и способ проведения статистического анализа, включая представление регрессионных моделей и мета-анализ.\n\n```{r}\nggstatsplot::gghistostats(\n  data            = df,\n  x               = age,\n  xlab            = \"Возраст\",\n  effsize.type = \"d\",\n  type = \"parametric\",\n  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян\n)\n```\nРезультаты визуального анализа указывают на то, что наше среднее (44,0 года) довольно сильно отклоняется от общероссийских данных, что было протестировано с помощью одновыборочного t-критерия. Однако, довольно заметно, что у наших данных положительная асимметрия  и довольно длинный «хвост» из больших значений. Попробуем робастный подход, где вместо среднего используется усеченное среднее (по умолчанию в настройках указывается значение «усечения» -  0.2), а для подсчета p-значения при сравнении средних используется метод [бутстрэпа](https://ru.wikipedia.org/wiki/%D0%91%D1%83%D1%82%D1%81%D1%82%D1%80%D1%8D%D0%BF_(%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0). Результаты неутешительные - различия по-прежнему значимые. \n```{r}\nggstatsplot::gghistostats(\n  data            = df,\n  x               = age,\n  xlab            = \"Возраст\",\n  effsize.type = \"d\",\n  type = \"robust\",\n  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян\n)\n```\n\nЕще один очень важный график: квантильный или Q-Q plot. \n\nАрхитектура этого графика проста: по оси x откладываются квантили для эмпирических данных, а по оси y - квантили распределения, с которыми мы их сравниваем (обычно - нормальное). Таким образом, Q-Q plot это диаграмма рассеяния, в которой два набора квантилей представлены друг напротив друга. Если оба они происходят из одного распределения, мы увидим точки, формирующие прямую. \n\nЧто такое квантиль?\n\nКвантиль — это одна из точек, делящих функцию плотности распределения на участки, вероятность попадания в которые одинакова, то есть на участки одинаковой площади.\n\n\n![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ced/171/7c6/ced1717c6ccf73d530fa4fedc8532e87.png)\n\n**Квантильная функция** — это функция, которая по значению вероятности `P` возвращает такое число (квантиль) `q`, что вероятность того, что случайная величина примет значение меньше `q` равняется `P`:\n\n![](https://habrastorage.org/getpro/habr/upload_files/233/dca/709/233dca7099c3c5e4085256e671d9c832.svg)\nВ базовом R, чтобы создать такой график, нужно соединить две функции - `qqnorm () и `qqline()`. Одна создает, собственно квантильный график, другая - референтную прямую, на которую можно ориентироваться при оценке полученных значений.\n\n\n```{r}\nqqnorm(df$age, frame = FALSE)\nqqline(df$age, col = \"steelblue\", lwd = 2)\n```\n\nКак всегда, могут быть и другие варианты. На мой личный вкус один из лучших QQ-plot создается в библиотеке `ggpubr`, позволяющей добавить на график доверительные интервалы для квантилей, а также выбрать тему, применить трансформации к шкалам (\"log2\", \"log10\", \"sqrt\"), изменить другие настройки:\n```{r warning=F}\nggpubr::ggqqplot(df, x = \"age\", color = \"steelblue\")\n```\n\nЕще одна форма графического представления количественных данных - ящичная диаграмма.\n\nАнатомию данного графика лучше представить в визуальном виде (см. рисунок ниже). \nВ центре графика - медиана, сам «ящик» формируется на основе межквартильного размаха (IQR), а «усы» ограничиваются либо минимальным и максимальным значениями, либо границами `Q3+1,5*IQR`и `Q1-1,5*IQR`, если в распределении имеются выбросы.\n\n![](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_boxplots.jpg)\nМожно воспользоваться простой функцией `boxplot(), либо использовать более изощренные варианты.\n```{r}\nboxplot(df$age, col=\"steelblue\")\n```\n```{r warning=FALSE}\nlibrary(ggplot2)\nggplot(df, aes(y=age, fill=\"red\")) + \n  geom_boxplot()+\n  theme_bw()+\n  theme(legend.position=\"none\")\n```\n\n### Нахождение аномальных наблюдений\n\nУже на гистограмме и квантиль-квантильном графе хорошо видны все «огрехи» распределения, а ящичная диаграмма даже выносит особые наблюдения («статистические выбросы») за пределы основного графика.\n\nМы могли бы представить в виде диаграммы стандартизированные значения, и сразу понять, сколько и как много в нашей выборке наблюдений, превышающих допустимый предел (например, лежащих далее, чем 3 «сигмы» от нулевого значения):\n```{r}\ndf$z_age <- scale(df$age)\nhist(df$z_age)\n\n```\nДавайте посмотрим на описательные статистики:\n```{r}\nsummary(df$z_age)\n```\nМы видим, что у нас нет маленьких значений за пределами «-3», но есть некоторые значения, превышающие «+3).\n\nМы можем посмотреть номера (строки) этих наблюдений:\n```{r}\nwhich(df$z_age > 3.0)\n```\n\nТаких значений три - 562, 593, 872. Это серьезные долгожители:\n\n```{r}\ndf[c(562,593,872),]$age\n```\n\nВопрос о том, как выявлять аномальные значения и что с ними делать, не является тривиальным. Помимо графических методов, есть и специальные статистические методы, позволяющие вычленить наблюдения, содержащие нетипичные значения.\n\n#### Фильтр Хэмпеля\n\nТак, еще один метод, известный как фильтр Хэмпеля, рассматривает в качестве выбросов значения, попадающих в интервал  ($I$), образуемый медианой плюс или минус три абсолютных отклонения от медианы (median absolute, MAD):\n\n$$I = [median - 3 \\cdot MAD; median + 3 \\cdot MAD]$$\nгде $MAD$ определяется как:\n\n$MAD = median(|X_i - \\tilde{X}|)$\n\nДавайте определим нижнюю и верхнюю границы фильтра и отберем наблюдения, которые не попадают в указанный диапазон:\n```{r}\nlower_bound <- median(df$age, na.rm = T) - 3 * mad(df$age, na.rm=T, constant = 1)\nlower_bound\n```\n\n```{r}\nupper_bound <- median(df$age, na.rm = T) + 3 * mad(df$age, na.rm=T, constant = 1)\nupper_bound\n```\n\n```{r}\noutlier_ind <- which(df$age < lower_bound | df$age > upper_bound)\noutlier_ind\n```\nЛегко увидеть, что наблюдений гораздо больше, чем было выявлено с помощью z-значений, что указывает на то, что фильтр Хэмпеля является довольно консервативным подходом.\n\n\n#### Статистические тесты для выявления аномалий\n\nКроме графических методов и механического отбора, нетипичные наблюдения можно выявлять и с помощью специальных тестов, например, таких как:\n\n- Тест Груббса\n- Тест Диксона\n- Тест Роснера \n\nЭти три статистических теста являются частью более формальных техник нахождения выбросов, так как они основаны на вычислении тестовой статистики, которая сопоставляется с табличными критическими значениями, основанными на объеме выборки и определяемого доверительного уровня).\n\n##### Grubbs’s test\n\nТест Груббса позволяет сделать вывод о том, являются ли максимальное и минимальное значение выбросами. \n\n\n$H_0$: максимальное значение **не** является аномальным.\n$H_1$: максимальное значение является аномальным.\n\nАналогичным образом формулируются гипотезы о минимальных значениях:\n\n$H_0$: минимальное значение **не** является аномальным.\n$H_1$: минимальное значение является аномальным.\n\nКак и для любого статистического теста, мы решаем, если p-значение меньше выбранного уровня значимости (чаще всего α=0,05) нулевая гипотеза отклоняется и мы делаем вывод, о том, что значения являются выбросами.\n\nЭтот тест не подходит для выборок, в которых содержится менее 6 наблюдений.\n\nЧтобы выполнить тест Груббса в R, мы будем использовать функцию `grubbs.test()` из библиотеки `{outliers}`:\n\n```{r}\n# install.packages(\"outliers\")\nlibrary(outliers)\ntest <- grubbs.test(df$age, type=10)\ntest\n```\nТест «говорит» нам о том, что максимальное значение не является выбросом.\n\n{{< iconify arcticons writer size=42px >}} **Самостоятельное задание**:\n\nПроверьте, является ли выбросом минимальное значение. Для этого в настройках установите opposite = TRUE. Проверьте гипотезу о принадлежности к выбросам обоих - минимального и максимального значений. Поменяйте настройки на type=11.\n\n##### Тест Диксона\n\nПодобно тесту Груббса, тест Диксона используется для определения того, является ли минимальное или максимальное значение выбросом. Если у нас есть подозрение относительно других значений, мы должны тестировать их индивидуально. \n\nЕще одно ограничение: этот тест хорошо работает только на маленьких выборках (n≤25).\n\nЧтобы попробовать этот метод на наших данных, мы должны сократить нашу выборку и использовать соответствующую функцию из той же библиотеки:\n\n```{r}\nsubdat <- df[1:20, ]\ntest <- dixon.test(subdat$age)\ntest\n\n```\n\n##### Тест Роснера\n\nК теста Роснера есть несколько преимуществ:\n- его можно использовать для вычленения нескольких выбросов за один раз\n- позволяет решать проблемы маскировки, когда один выброс, близкий по значению к другому выбросу, остается незамеченным\n- подходит для больших выборок.\n`\nВ R функция  `rosnerTest()` находится в библиотеке `{EnvStats}`. \nФункция требует по меньшей мере двух аргументов: ссылки на данные и количество выбросов (по умолчанию 3).\n\nФормула теста следующая:\nНаблюдаемые значения сортируются от меньшего к большему, далее определяется максимальное значение выбросов (не больше 10), и затем считается серия статистических тестов, путем последовательного удаления значений (высоких или низких), которые максимально удалены от среднего значения и пересчета стандартных значений по формуле:\n \n$$\\large R_{i+1} = \\frac{|x^{(i)} - \\bar x^{(i)}|}{s^{(i)}}$$\nКак только все статистики $ R_1...R_k$  посчитаны, начинается проверка гипотез путем сопоставления с критическими значениями для определенного уровня значимости.\n\n Попробуем провести этот тест на наших данных:\n\n```{r message=F, warning=F}\n#install.packages(\"EnvStats\")\nlibrary(EnvStats)\ntest <- rosnerTest(df$age,\n  k = 3\n)\ntest\n```\n\nВидим, что результаты также схожи с теми, что мы получили в ходе анализа стандартизированных значений, что неудивительно, учитывая сходство статистических процедур. \n\n### Проверка на нормальность\n\nПодчиняются ли анализируемые количественные переменные закону нормального распределения вероятностей? Очень многие статистические методы предполагают положительный ответ на этот вопрос, и поэтому проверка исследуемых переменных на нормальность распределения является важной составной частью разведочного анализа данных.\n\nКак известно, кривая нормального распределения имеет красивый «колоколообразный вид» и описывается формулой функции плотности вероятности (probability density function, PDF): \n\n$$f(x) = \\frac{e^{-(x - \\mu)^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}$$\n\n```{r echo=FALSE}\ncurve(dnorm(x, 0, 1), from=-4, to=4)\n```\n\n\nНапример, мы желаем проверить гипотезу о равенстве средних значений в двух независимых выборках. Для этой цели подходит критерий Стьюдента. Но применение критерия Стьюдента обосновано, только если данные подчиняются нормальному распределению. Поэтому перед применением критерия необходимо проверить гипотезу о нормальности исходных данных. Или проверка остатков линейной регрессии на нормальность — позволяет проверить, соответствует ли применяемая модель регрессии исходным данным.\n\nНормальное распределение естественным образом возникает практически везде, где речь идет об измерении с ошибками. Более того, в силу центральной предельной теоремы, распределение многих выборочных величин (например, выборочного среднего) при достаточно больших объемах выборки хорошо аппроксимируется нормальным распределением вне зависимости от того, какое распределение было у выборки исходно. \n\nПроверяя условие нормальности распределения данных, необходимо, однако, хорошо представлять себе, в каких случаях его выполнение является критическим для применения конкретного статистического метода. Так, например, метод главных компонент (Principle Components Analysis, PCA) не требует, чтобы данные были распределены нормально. Линейная регрессия (Linear Regression) хотя и предполагает нормальность распределения зависимой переменной, является достаточно робастным методом при незначительных отклонениях от этого условия. В то же время для успешного применения дискриминантного анализа (Discriminant Analysis) нормальность распределениях признаков в каждой группе классифицируемых объектов - условие обязательное (Мастицкий, 2012).\n\n\nПроверку выборки на нормальность можно производить несколькими путями. \n\n- Большое распространение получили графические методы – анализ распределения с помощью гистограммы, диаграммы плотности, визуально показывающие, насколько велики отклонения от нормальности.\n\nМы уже строили для наших данных квантиль-квантиль график, гистограмму и ящичную диаграмму. Пожалуй, единственный график, который мы еще не делали - график плотности.\n\n```{r warning=FALSE}\n ggplot(df, aes(x=age)) + \n  geom_density(fill=\"lightblue\")+\n  theme_bw()\n  \n```\n\n- Можно использовать и данные описательных статистик, помня как в нормальном распределении соотносятся среднее, мода, медиана, какими должны быть асимметрия и эксцесс, выполняется ли «правило 3-х сигм». Обычно обращают внимание на показатели асимметрии и эксцесса, анализируют их абсолютные значения и сравнивают их со стандартными ошибками. \nВыше мы пробовали функцию `describe()` из библиотеки `psych`. Еще один хороший вариант - функция `Desc()` из библиотеки `DescTools`:\n\n```{r}\nlibrary(DescTools)\nDesc(df$age, plotit = TRUE)\n```\n\nОтдельно можно посчитать показатели асимметрии и эксцесса вместе с доверительными интервалами. У нормального распределения они должны быть близкими к нулю.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Negative_and_positive_skew_diagrams_%28English%29.svg/669px-Negative_and_positive_skew_diagrams_%28English%29.svg.png)\n![](https://img.tfd.com/mk/K/X2604-K-11.png)\n\nАсимметрия:\n\n```{r}\nSkew(df$age, na.rm=TRUE, conf.level = 0.95, ci.type = \"classic\")\n```\n\nЭксцесс:\n  \n```{r}\nKurt(df$age, na.rm=TRUE, method=2, conf.level = 0.95, ci.type = \"classic\")\n```\n\n\n- особая группа методов — критерии нормальности. Их существует множество - по меньшей мере 15. Подробные материалы про все критерии с формулами и нюансами интерпретации можно посмотреть [вот здесь](https://yadi.sk/i/QwrWjkIkrKAwF)\n\n\nВ R реализованы практически все имеющиеся тесты на нормальность — либо в виде стандарных функций, либо в виде функций, входящих в состав отдельных пакетов. Примером базовой функции является `shapiro.test()`, при помощи которой можно выполнить широко используемый тест Шапиро-Уилка\n\n#### Тест Шапиро-Уилка\n\nТест Шапиро-Уилка был впервые опубликован в 1965 году Самюэлем Санфордом Шапиро и Мартином Уилком.\n\n$$W=\\frac{(\\Sigma^n_{i=1}a_ix_{(i)})^2}{\\Sigma^n_{i=1}(x_i-\\bar{x})^2}$$\nгде:\n\n$x_i$ – упорядоченные значения анализируемой переменной\n$a_i$ – константы, созданные на основе ковариаций, дисперсий и средних значений по выборке (размера $n$) из нормального распределения (обычно берутся из таблиц).\n\nСчитается одним из лучших и наиболее мощных тестов.\n\n```{r}\nshapiro.test(df$age)\n```\n\nОсновные классические критерии проверки на нормальность собраны в пакете `nortest`. Пакет можно установить с CRAN при помощи вызова функции `install.packages()`:\n\n```{r eval=FALSE}\ninstall.packages(\"nortest\")\n```\n\n\n#### Тест Колмогорова-Смирнова\n\nнаверное, одним из самых известных является тест Колмогорова-Смирнова, носящий имена российских математиков Андрея Николаевича Колмогорова и Николая Васильевича Смирнова.\n\nСтатистика  $D$ Колмогорова-Смирнова вычисляется как максимум модуля разности между эмпирической и теоретической функциями распределения. Эта статистика критерия согласия используется для проверки гипотезы о том, что наблюдения взяты из указанного распределения:\n\n$$D = \\max_{1 \\le i \\le N} \\left( F(Y_{i}) -\n               \\frac{i-1} {N}, \\frac{i}{N} - F(Y_{i}) \\right)$$\nгде $F$ является теоретическим кумулятивным распределением, которое должно обязательно принадлежать к семейству непрерывных распределений. Нулевая гипотеза отклоняется в случае, если тестовая статистика, $D$, превышает критическое значение.\n\nКогда данные сравниваются с теоретическим нормальным распределением, используется поправка Лиллиефорса.\n\n```{r}\nnortest::lillie.test(df$age)\n```\n```{r warning=FALSE}\nplot(ecdf(scale(df$age)), col=\"red\", main=\"Эмпирическая и теоретическая кумулятивные функции\")\ncurve(pnorm, from = -10, to = 10, add = TRUE, col=\"blue\")\n```\n\n#### Тест Андерсона-Дарлинга\n\nТест Андерсона-Дарлинга (Stephens, 1974) используется для тестирования гипотезы о том, что выборочные данные имеют специфическое распределение. Это модификация теста Колмогорова-Смирнова (K-S test), в которой больший вес придается крайним значениям (хвостам), по сравнению с оригинальным тестом\n\nФормула для вычисления критерия такова:\n\n$$A^{2} = -N - S$$\n\n$$S = \\sum_{i=1}^{N}\\frac{(2i - 1)}{N}[\\ln{F(Y_{i})} + \\ln{(1 - F(Y_{N+1-i}))}]$$\n\nгде $F$ - это кумулятивная функция распределения, показывающая вероятность того, что целевое значение меньше указанного значения либо равно ему.\n\nВ библиотеке `nortest` тест Андерсона-Дарлинга реализован в функции `ad.test()`:\n```{r}\nnortest::ad.test(df$age)\n```\n\n#### Тест Крамера-фон-Мизеса\n\nТест Крамера-фон-Мизеса является еще одной альтернативой тесту Колмогорова-Смирнова и представляет собой комплексный тест для проверки нормальности. Он использует сумму квадратов различий между наблюдаемыми и ожидаемыми кумулятивными пропорциями в качестве тестовой статистики. \n\nТест имеет следующую формулу:\n\n$$\\begin{align}\nW_n^2:=n\\int(F_n(x)-F_0(x))^2\\,\\mathrm{d}F_0(x).\n\\end{align}$$\n\nЕсли $H_0: F=F_0$ справедливо, то  $W^2_n$ являются маленькими значениями. Соответственно, отвержение гипотезы происходит при больших значениях $W^2_n$. Считается, что тест Крамера-фон-Мизеса более мощный, по сравнению с классическим тестом Колмогорова-Смирнова.\n\nВ библиотеке `nortest` для теста Крамера-фон-Мизеса используется функция `cvm.test()`:\n```{r}\nnortest::cvm.test(df$age)\n```\n\n## Анализ категориальных переменных\n\nРассмотрев возможности разведочного анализа количественных переменных, перейдем к категориальным данным, представленным в номинальных и порядковых шкалах\n\n### Описание таблиц без их представления в тексте\n\nВо многих случаях в ходе анализа нам нужны просто цифры, ведь не все результаты представляются в виде таблиц и графиков, что-то просто описывается словами, поэтому иногда проще и быстрее использовать базовый код, без премудростей.\n\nПредставим ситуацию, что мы описываем нашу выборочную совокупность и хотим представить информацию по количеству опрошенных по разным регионам исследования.\n\nИтак, если нам нужны простые частоты, не проценты, одним из простых решений будет функция из базового R `table ()`. \n\nНапример, посмотрим распределение по регионам, предварительно переведя все переменные факторные, поскольку их большинство:\n\n```{r echo=TRUE}\ndf <- haven::as_factor(df)\ntable(df$Region)\n```\n\n\n\nЕсли нам нужны не абсолютные, а относительные частоты по отдельным вопросам, для которых мы не собираемся делать какие-то таблицы или графики (то есть эти данные нужны только для описания), то для этой цели можно использовать , базовую функцию `prop.table`. \n\nНапример, мы хотим узнать пропорции по полу во всех регионах исследования (умножим на 100, чтобы получить значения в процентах, а не долях: \n\n```{r}\nprop.table(table(df$V1))*100\n\n```\nС помощью этих же функций можно создать и двумерные таблицы:\n```{r}\nprop.table(table(df$V1, df$Region), margin = 2)*100\n```\n\nБолее интересный вариант предлагает функция `flat_table` (переводится как \"плоская таблица\") из библиотеки `sjmisc`. \n\n\n```{r echo=TRUE}\nsjmisc::flat_table(df, V1, margin = \"cell\")\n```\n\nМы видим, что в наших исследованиях приняло участие гораздо больше женщин (почти 68%), чем мужчин (35%).\n\nЕсли нужна двумерная таблица, функция `flat_table` также подойдет (так же как и функции `prop.table`, `sjt.xtab` и другие, запомним, что в R всегда можно сделать одно и то же разными путями, здесь дело вкуса):\n\n\n```{r echo=TRUE}\ntable<-sjmisc::flat_table(df, Region, V1, margin = \"row\")# df - наша база данных, Region V1 - переменные для строк и столбцов, margin = \"row\"  - процент по строке\ntable\n\n```\n\nВыглядит не очень с точки зрения оформления, зато мы быстро получили результаты и можем их описать. Видим, что женщины превалируют во всех регионах, из доля составляет более 60%, в Республике Тыва - 75%.\n\nБолее того, мы можем сохранить эту таблицу в формате датафрейма и потом использовать в других приложениях:\n```{r}\ntable<-tidyr::as_tibble(table)\ntable\n```\n\nЕсли мы посмотрим, то получилось не совсем то, что нам бы хотелось: у нас получилась таблица в «длинном формате», вместо широкого. К счастью это можно быстро исправить с помощью уже знакомой нам функции `pivot_wider()`из библиотеки `tidyr`, являющейся частью экосистемы `tidyverse`.\n\n```{r}\nlibrary(tidyr)\ntable<-table %>% \n  pivot_wider(names_from = V1, values_from = Freq)\ntable\n```\n\nЕще нам постоянно мешает это единственное наблюдение из Монголии. Давайте его уберем и пересчитаем все заново.\n\nДля начала отфильтруем переменную `Region` так, чтобы в нее входили все регионы, кроме Монголии:\n\n```{r}\nlibrary(dplyr)\ndf<-df %>% \n  filter(Region!=\"Монголия\")\n```\n\nПопробуем сделать простую таблицу:\n```{r}\ntable(df$Region, df$V1)\n```\nКак видим, наблюдение мы удалили, но метка (уровень факторной переменной) осталась, и нам нужно его убрать. Сделать это можно с помощью функции `droplevels`. Удалим уровень и сделаем новую таблицу\n```{r}\ndf$Region<-droplevels(df$Region)\nsjmisc::flat_table(df, Region, V1, margin = \"row\")\n```\nВсе получилось!\n\nМежду тем, очевидно, что для хорошей статьи (диссертации, отчета об исследовании) описания результатов частотного анализа недостаточно, требуется представлять результаты комплексно, сразу по нескольким переменным, часто с учетом группировки, и приводить доказательства значимости имеющихся различий на основе применения статистических методов.\n\n### Создание таблиц по нескольким переменным: возможности библиотек `gtsummary` и `flextable`\n\n* **flextable** -- чудо-библиотека от Дэвида Гоэля - француза и сотрудника ArData, созданная специально для работы с таблицами и улучшения их отображения в различных форматах, в частности в Word и Power Point\n* **gtsummary** -- библиотека для создания эффектных таблиц с описательными статистиками для научных публикаций\n\nПредположим, что для нашей будущей статьи, которую мы готовим по результатам исследования, мы хотим создать большую таблицу, содержащую распределения сразу по нескольким переменным, описывающим все важные демографические и социальные характеристики, такие как пол, возраст по группам, социальный статус, в том числе - с учетом региональных различий. Желательно также посчитать, являются ли эти различия значимыми, используя для этого критерий $\\chi^2$ Пирсона. \n\nБиблиотека `gtsummary` была создана специально для того, чтобы быстро создавать гибкие с точки зрения форматирования таблицы с описательными статистиками и результатами регрессионного анализа, оформленные по стандартам для научных публикаций. \n\nНастоятельно рекомендуется посетить сайт проекта и подробно ознакомиться с возможностями данной библиотеки. \nhttps://www.danieldsjoberg.com/gtsummary/index.html\n\nДля начала создадим общую таблицу, где в строках будут располагаться данные по возрасту, полу, региону проживания, социальному статусу, а также наличию гражданства другой страны.\n\n```{r, message = FALSE, warning=FALSE}\nlibrary(dplyr)\n#install.packages(\"gtsummary\") - убрать решетку и запустить строку\nlibrary(gtsummary)\n#вспоминаем урок по dplyr\ntable<-df %>% \n  select(Region, V1, age_cats3, V10, V6)  #отберем нужные переменные в отдельный сет и сохраним его под именем table\n# создадим таблицу\ntable %>% \n  tbl_summary(missing=\"no\") #функция tbl_summary позволяет создать комплексные таблицы\n\n```\n\n\nВ принципе, очень неплохо. Добавим группировку по региону и поменяем заголовок у переменных с \"Characteristic\" на \"Характеристику\":\n\n```{r, message = FALSE, warning=FALSE}\ntable %>% \n  tbl_summary(by=Region, missing=\"no\") %>%#by=V004 - так мы обозначаем группирующую переменную\n  modify_header(#функция, позволяющая изменить заголовок\n    update = list(\n      label ~ \"Характеристика\" #\n    )\n  )\n```\n\nПрочитать подробнее о функции tbl_summary, ее атрибутах, с подробным разбором примеров и возможностей изменения таблицы:\nhttp://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html\n\nМожно сделать и простую двумерную таблицу:\n```{r}\n table %>%\n  tbl_cross(row = V1, col = age_cats3, percent = \"cell\", missing=\"no\", ) %>%\n  add_p(test=\"chisq.test\") %>% #добавляем статистику хи-квадрат\n  modify_header(#функция, позволяющая изменить заголовок\n    update = list(\n      label ~ \"**Характеристика**\" #\n    )\n  ) %>% \n  modify_caption(\"**Взаимосвязь пола и возраста** (N = {N})\") #меняем заголовок на нужный, причем заголовок вставляем количество опрошенных\n```\n\n \n\n### Пример анализа вопроса с множественными ответами\n\nДля выполнения данного задания нам понадобится `questionr` - библиотека, позволяющая анализировать таблицы с множественными ответами.\n\nПрежде чем выполнить последующий код, установите пакет questionr на свой комьютер и запустите библиотеку:\n```{r, fig.width=10, fig.height=3}\n#install.packages(\"questionr\") - убрать решетку и запустить строку\nlibrary(questionr)\n```\n\nУ нас в анкете был вопрос 9, в котором изучалось, чем владеет домохозяйство. Можно было выбрать несколько вариантов ответа, а также дать собственный вариант ответа - «Другое». Ответы были закодированы дихотомическим способом, выбор кодировался как 1, а его отсутствие - как 0. \n\nКак в других программах статистической обработки, в R нам потребуется сделать два шага для того, чтобы проанализировать вопрос с множественным выбором:\n- создать набор данных, в который объединяются отдельные подвопросы;\n- сделать таблицу, которая может быть как одномерной, так и многомерной.\n\nДавайте объединим все подвопросы вопроса V9 в один набор и сохраним его под отдельным именем  - V9. Воспользуемся знакомыми нам функциями `select()` - для отбора переменных и `contains()` - отбора переменных, имена которых содержат определенный паттерн:\n\n```{r message=FALSE, warning=FALSE}\nlibrary(dplyr)\nV9<-df %>% \n  select(contains(\"V9\")) %>% \n  select_if(is.factor)#дополнительный select нужен, чтобы убрать текстовую переменную «другое»\n```\n\nДалее, создадим таблицу и сохраним ее в качестве отдельного датафрейма.\n\n```{r}\nlibrary(questionr)\nlibrary(dplyr)\nV9tab<-V9 %>% \nmulti.table(true.codes=list(\"да\"), freq=TRUE) %>% \n    as.data.frame() %>% \n  rename(Pct=`%multi`) %>% \n  arrange(desc(Pct))\nV9tab\n```\nДа, выглядит так себе, но зато все посчитано) сразу.\n\nПоясним, что `true.codes=list(\"да\")` - обозначаем вариант ответа, используемый для подсчета частот и процентов, `freq=TRUE` - вывод процентов, а не только частот.\n\n\nКак добавить метки вопросов в нашу таблицу? \nИзвлечем метки вопросов по блоку V9 в отдельное место:\n\n\n```{r message=FALSE, warning=FALSE}\nlibrary(sjlabelled)\nV9labs<-df %>% \nselect(contains(\"V9\")) %>% \n  select_if(is.factor) %>% \n  get_label()\nV9labs\n```\n\nПрисвоим имена в переменную `n`:\n```{r}\nV9tab$n<-V9labs\nV9tab\n```\n\n### Таблица сопряженности с множественными ответами\n\n\n```{r}\nV9Regiontab<-cross.multi.table(V9, df$Region, true.codes=list(\"да\"), freq=TRUE)\nV9Regiontab<-as_tibble(V9Regiontab)\nV9Regiontab$n<-V9labs\nV9Regiontab<-V9Regiontab %>% \n  relocate(n)\n```\n\n\n### Графики для категориальных переменных\n\nОсновными графиками для категориальных переменных являются круговые и столбиковые диаграммы, а также мозаичные и ассоциативные графики, когда в анализе задействовано более двух переменных.\n\nДавайте создадим такие графики для переменных по возрасту. Красивые минималистичные графики с небольшим количеством кода и исправлений можно создать с помощью библиотеки `ggpubr` от Alboukadel Kassambara (биолог, автор книг по биоинформатике и биологии рака).\n\nСоздадим одномерную таблицу для возраста и двумерную для взаимосвязи между полом и возрастом.\n\n```{r}\nage<- as.data.frame(sjmisc::flat_table(df, age_cats3, margin = \"cell\", digits = 1))\nage_sex<-as.data.frame(sjmisc::flat_table(df, age_cats3, V1, margin = \"row\", digits = 1))\n```\n\nСделаем простую столбиковую диаграмму по возрастным группам, в качестве «изюминки» добавим красивые шрифты.\n\nПрежде чем сделать сам график, установим шрифты, чтобы потом ими можно было пользоваться постоянно.\n```{r eval=FALSE}\ninstall.packages(\"extrafont\")\nlibrary(extrafont)\nfont_import()#шрифты устанавливаются сразу все, это может занять некоторое время\n```\n\n```{r echo=FALSE, message=FALSE}\nlibrary(extrafont)\n```\n\nВ результате будут импортированы следующие шрифты:\n![](http://gradientdescending.com/plots/fonttable_big.png)\nПосле установки шрифты нужно загружать каждую сессию: \n```{r}\nloadfonts(device = \"win\", quiet = TRUE)\n```\n\nТеперь займемся самим графиком.\nРазберем его структуру строчка за строчкой:\n- `ggplot(data=age, aes(x=age_cats3, y=Freq)) +` - создаем базовый график, где по оси x у нас будут возрастные категории, а по y - проценты\n- `geom_bar(stat=\"identity\", fill=\"steelblue\", width = 0.6)+` - добавляем слой для столбиковой диаграммы, `stat=\"identity\"` - означает, что мы будем использовать данные «как есть», а не агрегировать на основе исходных, `fill=\"steelblue\"` - задаем цвет, `width = 0.6` - устанавливаем ширину столбцов чуть меньше обычного, для красоты))\n- `geom_text(aes(label=scales::number(Freq,accuracy=0.1, decimal.mark = \",\")),  family = \"Ink Free\", vjust=0.5, hjust=-0.5, color=\"steelblue\", size=4)+` - тут много всего, эта часть кода отвечает за подписи к столбцам. `label=number(Freq,accuracy=0.1, decimal.mark = \",\"))` - устанавливаем подписи в числовом формате, запятую в качестве разделителя и округление до одного знака после запятой, `family = \"Ink Free\", vjust=0.5, hjust=-0.5` - задаем шрифт Ink Free, делаем выравнивание, чтобы число было ровно посредине столбца и слегка выходило за его пределы (можно поэкспериментировать с этими настройками), `color=\"steelblue\", size=4` - эти настройки отвечают за цвет и размер текста\n- `coord_flip()` - переворачиваем диаграмму в горизонтальную проекцию\n- `theme_void()`- устанавливаем тему, в которой есть только белый фон\n- `expand_limits(y=c(0,50))` - раздвигаем границы по оси y, там, где проценты (это неважно, что при повороте диаграмма «ложится на бок» и оси вроде как меняются местами)\n- `theme(axis.text.y = element_text(size = 10, family = \"Ink Free\")` - устанавливаем размер и семейство шрифтов для подписей - категорий возраста\n- `scale_x_discrete(limits=rev)` - ну и, напоследок, меняем порядок категорий, от младшей возрастной группы к старшей\n```{r}\n#| fig-width: 7\n#| fig-height: 3\nlibrary(ggplot2)\nlibrary(scales)#нужна для того, чтобы отформатировать подпись\nggplot(data=age, aes(x=age_cats3, y=Freq)) +\n  geom_bar(stat=\"identity\", fill=\"steelblue\", width = 0.6)+\n  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")),  family = \"Ink Free\", vjust=0.5, hjust=-0.5, color=\"steelblue\", size=4)+\n  coord_flip()+\n  theme_void()+\n  expand_limits(y=c(0,50))+\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+\n  scale_x_discrete(limits=rev)\n```\n\nДобавим данные по полу. В нашем коде почти ничего не поменялось, за исключением некоторых моментов:\n- `fill=V1` - мы добавили в исходный график, чтобы сделать разбивку по полу\n- в `geom_bar(stat=\"identity\", position=\"dodge\", width = 0.6)` добавили `position=\"dodge\"` - чтобы столбцы располагались рядом друг с другом, такой же аргумент добавлен и в `geom_text`\n- в конце появилось две новых строки   `theme(legend.position=\"bottom\")+  theme(legend.title=element_blank())`, они нужны для оформления легенды\n\n```{r}\n#| fig-width: 7\n#| fig-height: 3\nlibrary(ggplot2)\nlibrary(scales)#нужна для того, чтобы отформатировать подпись\nggplot(data=age_sex, aes(x=age_cats3, y=Freq, fill=V1)) +\n  geom_bar(stat=\"identity\", position=\"dodge\", width = 0.6)+\n  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")),  position = position_dodge(width = 0.6), hjust=-0.3, family = \"Ink Free\", size=4)+\n  coord_flip()+\n  theme_void()+\n  expand_limits(y=c(0,100))+\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+\n  scale_x_discrete(limits=rev)+\n  theme(legend.position=\"bottom\")+\n  theme(legend.title=element_blank())\n```\n\n В качестве альтернативы можно создать сгруппированные столбиковые диаграммы в библиотеке `ggstatsplot`:\n \n\n```{r}\nggstatsplot::ggbarstats(df, x = V1, y = age_cats3)\n```\n \n \n создать круговую диаграмму:\n \n```{r warning=FALSE}\n#| fig-width: 4\n#| fig-height: 4\nggplot(age, aes(x = \"\", y = Freq, fill = age_cats3)) +\n  geom_col(color = \"black\") +\n  geom_label(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")), color = \"white\",\n            position = position_stack(vjust = 0.5),\n            show.legend = FALSE) +\n  guides(fill = guide_legend(title = \"Возраст\")) +\n  scale_fill_viridis_d() +#эта строка добавляет цветовую палитру\n  coord_polar(theta = \"y\") + \n  theme_void()\n```\n \n \n Более простым решением является создание круговой диаграммы с помощью функции `ggpiestats` из библиотеки `ggstatsplot`:\n\n\n```{r}\nggstatsplot::ggpiestats(df, age_cats3, legend.title = \"Возраст\")\n\n```\nС помощью этой же функции можно создать серию круговых диаграмм:\n```{r}\nggstatsplot::ggpiestats(df, V1, age_cats3)\n```\nПосмотреть отдельно хи-квадрат:\n\n```{r}\nchisq.test(df$V1, df$age_cats3)\n```\n\nСделаем график для вопросов с множественными ответами, по вопросу V9. В описаниях вариантов ответов есть длинные формулировки, которые будут не очень хорошо смотреться на графике, поэтому прежде, чем создавать график, давайте уберем все, что написано в скобках, так как это скорее не основная, а уточняющая информация.\n\nДля этого мы воспользуемся функцией `gsub`, в которую включим выражение, позволяющее отсечь текст, лежащий после знака `(`.\n\n\n```{r}\nV9tab$n<-gsub(\"\\\\(.*\", \"\", V9tab$n)\n```\n\nХотя в таблице значения отсортированы, на графике они все равно будут отображаться в том порядке, в котором представлены уровни факторной переменной. Поэтому, чтобы на графике у нас были отображены значения по убыванию (мы же не хотим, чтобы у нас получился хаос из 14 вариантов ответа), нам нужно отсортировать уровни,  для чего нам потребуется библиотека `forcats`.\n\nИ поскольку ширина подписей, несмотря на то, что мы их сократили, будет довольно существенной, мы сделаем самые длинные подписи в две строки, что, в свою очередь, потребует работы с библиотекой `stringr` (раз это новые для нас библиотеки и мы про них не слышали, нужно их установить).\n```{r}\nlibrary(forcats)\nlibrary(stringr)\n#| fig-width: 200%\nV9tab %>%\n  mutate(n = fct_reorder(n, Pct)) %>% # переставим местами уровни\nggplot(aes(x=n, y=Pct, fill=n)) + # создадим типовой график\n  geom_bar(stat=\"identity\", width = 0.6)+  # добавим geom\n  geom_text(aes(label=number(Pct,accuracy=0.1, decimal.mark = \",\")), hjust=-0.3, family = \"Ink Free\", size=4)+   # поработаем с подписями данных\n  expand_limits(y=c(0,80))+# увеличим лимит оси \n  coord_flip()+  # перевернем график в горизонтальное положение\n  theme_void()+   # добавим минималистичную тему\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+    # установим шрифт для подписей\n  theme(legend.position=\"none\")+       # уберем легенду\n  scale_x_discrete(labels = function(x) str_wrap(x, width = 30))       # Сделаем длинные подписи в несколько строк\n```\n\n## Самостоятельная работа\n\n1. Провести комплексную проверку на нормальность переменной `Sepal.Length` из набора `iris.\n2. Провести одномерный анализ по переменным V12, V13, V15. Сделать двумерный анализ по региону и возрасту.\n3. Проанализировать переменные с множественным выбором V14 и V16, также сделать двумерный анализ по региону. По всем видам анализа сделать таблицы и графики.\n4. Представить все в виде отдельного документа - по желанию в каком формате.\n\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Для чего нам нужен разведочный анализ (Exploratory Data Analysis)\n\n**Разведочный анализ** в общем смысле – это предварительный анализ данных с целью выявления наиболее общих зависимостей, закономерностей и тенденций, характера и свойств анализируемых данных, законов распределения анализируемых величин. Именно с разведочного анализа начинается любая обработка данных результатов научного исследования.\n\n![](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/data/media/exploratory-data-analytics/sandboxing.png)\n\nПри этом, разведочный анализ - это не какой-то один статистический тест или метод. При разведочном анализе учитывается и сравнивается большое число признаков, а для поиска закономерностей или обоснования имеющихся различий используются самые разные процедуры и техники.\n\nТермин «разведочный анализ» и набор техник, которые применяются для его проведения, был впервые введен и популяризирован американским математиком и статистиком из Принстонского университета **Джоном Тьюки**, написавшим в 1977 году книгу «Разведочный анализ данных» (Exploratory Data Analysis).\n\n![](data:image/jpeg;base64,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)\n\nЭтот термин кажется «сухим» и «занудным», однако практики, используемые в рамках разведочного анализа, не только являются крайне важными, но и весьма волнующими для исследователя. Не случайно, сам Дж. Тьюки сравнил EDA с работой детектива: каждый новое исследование данных представляет собой «мистическую историю», которую мы должны расследовать, вскрыть скрытые свойства и секретные характеристики наших данных.\n\nОсновными целями разведочного анализа являются:\n\n- проникновение в данные и описание их во всей полноте;\n- выявление основных структур (паттернов) и тенденций;\n- идентификация взаимосвязей и корреляций между переменными\n- выбор наиболее важных переменных;\n- обнаружение отклонений и аномалий;\n- проверка основных гипотез (предположений);\n- разработка начальных моделей и подготовка данных для дальнейшего анализа.\n\nРезультаты разведочного анализа не используются напрямую для выработки управленческих решений, скорее они предоставляют помощь в разработке лучшей стратегии углубленного анализа, способствуют выдвижению новых гипотез, обосновывают возможности применения тех или иных математических методов и моделей. Без разведочного анализа дальнейший анализ данных, часто включающий разработку комплексных статистических моделей, будет производиться практически «вслепую».\n\n**Разведочный (эксплораторный, описательный)** анализ данных по своему содержанию, целям и задачам противопоставлен **подтверждающему** анализу данных (Confirmatory Data Analysis), основанному на конкретных предположениях и уже имеющихся данных.\n\nК основным методам разведочного анализа относятся анализ распределений, особенно с помощью методов визуального анализа (гистограмм, диаграмм рассеяния, ящичных диаграмм), тестирование гипотез о соответствии определенному виду распределения, методы группового и корреляционного анализа. Довольно часто к методам разведочного анализа также относят техники, позволяющие осуществить кластеризацию и снизить размерность данных, графически представить высоко-размерные данные, включающие множество переменных, в также предсказательные модели, такие как линейная регрессия, использующие данные и статистические показатели для предсказания целевых показателей. В рамках данного пособия такие методы будут рассмотрены в следующем разделе, посвященном многомерному анализу и возможностям статистического моделирования.\n\n## Анализ характеристик распределения количественной переменной\n\nМы начнем наше разведочное исследование с количественных переменных и затем перейдем к категориальным переменным, двумерному и корреляционному анализу.\n\nЧтобы наши действия были ближе к «социологической жизни», мы будем использовать результаты исследования восприятия и оценки адаптивных стратегий населения в отношении климатических рисков в высокогорных районах Алтая.\n\n:::callout-info\nЕсли Вы не сохранили данные с предыдущих занятий, скачайте их еще раз.\n\nСкачать [данные](https://github.com/domelia/R-book/blob/main/files/База_КлимРиск_2023.sav)/\n:::\n\n```{r}\nlibrary(haven)\ndf<-read_sav(\"files/База_КлимРиск_2023.sav\")\n```\n\nПрежде, чем мы начнем «препарировать» наши данные, давайте взглянем на них издалека, в целом. Для этой цели хорошо подойдут библиотеки так называемого автоматизированного разведочного анализа, позволяющие быстро подготовить отчеты сразу по всему массиву данных, представить остовные статистики и графики. В R существует по меньшей мере 10 таких библиотек, наиболее известными из которых являются:\n- summarytools\n- DataExplorer\n- visdat\n- funModeling\n- arsenal\n- dataMaid\n- dlookr\n\nПодробный анализ данных библиотек в действии, их положительных и отрицательных сторон, можно найти в статье: *Mateusz Staniak* и *Przemysław Biecek* [**The Landscape of RPackages for Automated Exploratory Data Analysis**](https://arxiv.org/pdf/1904.02101).\n\nМы воспользуемся некоторыми функциями библиотеки `DataExplorer`. \nДля начала установим ее:\n```{r eval=FALSE}\ninstall.packages(\"DataExplorer\")\n```\n\nПосле установки, как всегда, загружаем библиотеку в текущую сессию и запускаем ее:\n```{r message=FALSE, warning=FALSE}\nlibrary(DataExplorer)\n```\n\nДавайте проведем самый общий анализ по всей базе данных с помощью функции `introduce()`, которая выдаст нам самые общие сведения: количество строк и колонок (переменных), сколько из них являются дискретными и непрерывными, если такие переменные, в которых все данные пропущены, а также данные о количестве наблюдений и пропущенных значений.\n\n```{r eval=FALSE}\nintroduce(df)\n```\n\n```{r echo=FALSE}\nlibrary(tidyselect)\nlibrary(kableExtra)\nintroduce(df) %>% \n  t() %>% \n  kbl()\n```\n\n\nЧтобы визуализировать данную таблицу, можно использовать функцию `plot_intro()`. На графике отображаются основные показатели набора данных - количество дискретных и непрерывных переменных, полных наблюдений и переменных с отстутствующими значениями. \n\nПочему у нас так много пропусков и нет ни одной строки с полными данными? Все просто: ведь в ходе анализа учитываются абсолютно все переменные набора, включая дополнительные переменные «Другое», которые вполне могли остаться пустыми, если респондент не выбирал данный вариант ответа, а также переменные, предназначенные для определенных категорий респондентов, на которые по определению отвечали не все. Если бы мы отобрали меньшее количество переменных, которые нам нужны для конкретного анализа, результаты были бы совершенно иными. Кроме того, следует учитывать, что при подсчете «дискретных» и «непрерывных» переменных функция руководствуется результатам присвоения категорий данных в SPSS и их импорта в `haven`. Так что, если изначально тип переменной был задан неверно, то и результаты такого анализа, мягко скажем, не будут соответствовать действительности.\n\n```{r}\nplot_intro(df)\n```\n\nВ доказательство вышеприведенного тезиса приведем график пропущенных значений по некоторым переменным. Можно легко заметить, что переменные образуют две группы - те, где количество пропусков не составляет выше 5% и переменные, где пропусков существенно больше (обозначены оранжевым цветом). Это ответы на вопрос 9, где спрашивалось о том, каким имуществом владели домохозяйства, проживающие в горных районах (сельхозтехника, сад, огород, пастбище, участки леса и пр.). Нет ничего удивительного в том, что более пятой части опрошенных не обладали ни одним из перечисленных вариантов, более того, часть из них, учитывая, что опрос проводился в зонах экстремального земледелия (приравненных к условиям Крайнего Севера), можно считать признаками высокого статуса и богатства (например, если у жителя есть в пользовании теплица и он может сам выращивать овощи). \n\n```{r}\nplot_missing(df[,30:50])\n```\n\n### Основные описательные характеристики\n\nУ нас не так много количественных данных, и одной из непрерывных переменных является возраст (`age`).\n\nСамым простым способом анализа основных характеристик распределения является базовая функция `summary()`, предоставляющая семь ключевых статистик: минимум, максимум, среднее, медиану, 1-й и 3-й квартили, а также количество пропущенных значений:\n```{r}\nsummary(df$age)\n```\n\nБолее расширенный статистический анализ можно получить, обратившись к функции `describe()`из библиотеки `psych` (не забываем устанавливать новые библиотеки). Набор аргументов по умолчанию достаточно широк: здесь уже есть и стандартное отклонение, и усеченное среднее, и показатели асимметрии и эксцесса.\n```{r eval=FALSE}\npsych::describe(df$age)\n```\n```{r echo=FALSE}\npsych::describe(df$age) %>% \n  t() %>% \n  kbl(digits = 2, label = \"Возраст опрошенных\")\n```\nВпрочем, каждый из них можно получить отдельно, с помощью базовых функций, например, стандартное отклонение:\n```{r}\nsd(df$age, na.rm = T)\n```\nДисперсия:\n```{r}\nvar(df$age, na.rm = T)\n```\nАсимметрия:\n\n```{r}\npsych::skew(df$age, na.rm = T)\n```\n### Графические методы анализа распределения\n\nБольшую роль в анализе данных играет визуализация, и в случае анализа количественных переменных она просто незаменима. Часто именно график, без какого-либо статистического анализа, дает лучшее представление о том, что происходит с данными, тогда как статистические «точечные» оценки, такие как среднее или дисперсия, могут ввести в заблуждение. \n\nКоличественную переменную обычно графически представляют несколькими разными способами:\n- с помощью гистограмм;\n- с помощью квантильного графика;\n- с помощью ящичной диаграммы.\n\nСамый быстрый и простой способ получения гистограммы - с помощью базовой функции `hist()`:\n```{r}\nhist(df$age, col=\"steelblue\", xlab = \"Возраст (лет)\", main=\"Возраст опрошенных\")\n```\nЕсли мы хотим более «продвинутый» вариант гистограммы, можно обратиться к возможностям библиотеки `ggstatsplots`, основанной на философии создания визуальных материалов в рамках библиотеки `ggplot2` и предназначенной для создания публикабельных визуализаций, сопровожденной результатами статистического анализа и возможностями проверки статистических гипотез. При несколько излишней сложности, это, пожалуй, лучшее, что есть сегодня в плане описательного анализа. Это не просто библиотека, создающая графики, это одновременно и способ визуализации, и способ проведения статистического анализа, включая представление регрессионных моделей и мета-анализ.\n\n```{r}\nggstatsplot::gghistostats(\n  data            = df,\n  x               = age,\n  xlab            = \"Возраст\",\n  effsize.type = \"d\",\n  type = \"parametric\",\n  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян\n)\n```\nРезультаты визуального анализа указывают на то, что наше среднее (44,0 года) довольно сильно отклоняется от общероссийских данных, что было протестировано с помощью одновыборочного t-критерия. Однако, довольно заметно, что у наших данных положительная асимметрия  и довольно длинный «хвост» из больших значений. Попробуем робастный подход, где вместо среднего используется усеченное среднее (по умолчанию в настройках указывается значение «усечения» -  0.2), а для подсчета p-значения при сравнении средних используется метод [бутстрэпа](https://ru.wikipedia.org/wiki/%D0%91%D1%83%D1%82%D1%81%D1%82%D1%80%D1%8D%D0%BF_(%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0). Результаты неутешительные - различия по-прежнему значимые. \n```{r}\nggstatsplot::gghistostats(\n  data            = df,\n  x               = age,\n  xlab            = \"Возраст\",\n  effsize.type = \"d\",\n  type = \"robust\",\n  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян\n)\n```\n\nЕще один очень важный график: квантильный или Q-Q plot. \n\nАрхитектура этого графика проста: по оси x откладываются квантили для эмпирических данных, а по оси y - квантили распределения, с которыми мы их сравниваем (обычно - нормальное). Таким образом, Q-Q plot это диаграмма рассеяния, в которой два набора квантилей представлены друг напротив друга. Если оба они происходят из одного распределения, мы увидим точки, формирующие прямую. \n\nЧто такое квантиль?\n\nКвантиль — это одна из точек, делящих функцию плотности распределения на участки, вероятность попадания в которые одинакова, то есть на участки одинаковой площади.\n\n\n![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ced/171/7c6/ced1717c6ccf73d530fa4fedc8532e87.png)\n\n**Квантильная функция** — это функция, которая по значению вероятности `P` возвращает такое число (квантиль) `q`, что вероятность того, что случайная величина примет значение меньше `q` равняется `P`:\n\n![](https://habrastorage.org/getpro/habr/upload_files/233/dca/709/233dca7099c3c5e4085256e671d9c832.svg)\nВ базовом R, чтобы создать такой график, нужно соединить две функции - `qqnorm () и `qqline()`. Одна создает, собственно квантильный график, другая - референтную прямую, на которую можно ориентироваться при оценке полученных значений.\n\n\n```{r}\nqqnorm(df$age, frame = FALSE)\nqqline(df$age, col = \"steelblue\", lwd = 2)\n```\n\nКак всегда, могут быть и другие варианты. На мой личный вкус один из лучших QQ-plot создается в библиотеке `ggpubr`, позволяющей добавить на график доверительные интервалы для квантилей, а также выбрать тему, применить трансформации к шкалам (\"log2\", \"log10\", \"sqrt\"), изменить другие настройки:\n```{r warning=F}\nggpubr::ggqqplot(df, x = \"age\", color = \"steelblue\")\n```\n\nЕще одна форма графического представления количественных данных - ящичная диаграмма.\n\nАнатомию данного графика лучше представить в визуальном виде (см. рисунок ниже). \nВ центре графика - медиана, сам «ящик» формируется на основе межквартильного размаха (IQR), а «усы» ограничиваются либо минимальным и максимальным значениями, либо границами `Q3+1,5*IQR`и `Q1-1,5*IQR`, если в распределении имеются выбросы.\n\n![](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_boxplots.jpg)\nМожно воспользоваться простой функцией `boxplot(), либо использовать более изощренные варианты.\n```{r}\nboxplot(df$age, col=\"steelblue\")\n```\n```{r warning=FALSE}\nlibrary(ggplot2)\nggplot(df, aes(y=age, fill=\"red\")) + \n  geom_boxplot()+\n  theme_bw()+\n  theme(legend.position=\"none\")\n```\n\n### Нахождение аномальных наблюдений\n\nУже на гистограмме и квантиль-квантильном графе хорошо видны все «огрехи» распределения, а ящичная диаграмма даже выносит особые наблюдения («статистические выбросы») за пределы основного графика.\n\nМы могли бы представить в виде диаграммы стандартизированные значения, и сразу понять, сколько и как много в нашей выборке наблюдений, превышающих допустимый предел (например, лежащих далее, чем 3 «сигмы» от нулевого значения):\n```{r}\ndf$z_age <- scale(df$age)\nhist(df$z_age)\n\n```\nДавайте посмотрим на описательные статистики:\n```{r}\nsummary(df$z_age)\n```\nМы видим, что у нас нет маленьких значений за пределами «-3», но есть некоторые значения, превышающие «+3).\n\nМы можем посмотреть номера (строки) этих наблюдений:\n```{r}\nwhich(df$z_age > 3.0)\n```\n\nТаких значений три - 562, 593, 872. Это серьезные долгожители:\n\n```{r}\ndf[c(562,593,872),]$age\n```\n\nВопрос о том, как выявлять аномальные значения и что с ними делать, не является тривиальным. Помимо графических методов, есть и специальные статистические методы, позволяющие вычленить наблюдения, содержащие нетипичные значения.\n\n#### Фильтр Хэмпеля\n\nТак, еще один метод, известный как фильтр Хэмпеля, рассматривает в качестве выбросов значения, попадающих в интервал  ($I$), образуемый медианой плюс или минус три абсолютных отклонения от медианы (median absolute, MAD):\n\n$$I = [median - 3 \\cdot MAD; median + 3 \\cdot MAD]$$\nгде $MAD$ определяется как:\n\n$MAD = median(|X_i - \\tilde{X}|)$\n\nДавайте определим нижнюю и верхнюю границы фильтра и отберем наблюдения, которые не попадают в указанный диапазон:\n```{r}\nlower_bound <- median(df$age, na.rm = T) - 3 * mad(df$age, na.rm=T, constant = 1)\nlower_bound\n```\n\n```{r}\nupper_bound <- median(df$age, na.rm = T) + 3 * mad(df$age, na.rm=T, constant = 1)\nupper_bound\n```\n\n```{r}\noutlier_ind <- which(df$age < lower_bound | df$age > upper_bound)\noutlier_ind\n```\nЛегко увидеть, что наблюдений гораздо больше, чем было выявлено с помощью z-значений, что указывает на то, что фильтр Хэмпеля является довольно консервативным подходом.\n\n\n#### Статистические тесты для выявления аномалий\n\nКроме графических методов и механического отбора, нетипичные наблюдения можно выявлять и с помощью специальных тестов, например, таких как:\n\n- Тест Груббса\n- Тест Диксона\n- Тест Роснера \n\nЭти три статистических теста являются частью более формальных техник нахождения выбросов, так как они основаны на вычислении тестовой статистики, которая сопоставляется с табличными критическими значениями, основанными на объеме выборки и определяемого доверительного уровня).\n\n##### Grubbs’s test\n\nТест Груббса позволяет сделать вывод о том, являются ли максимальное и минимальное значение выбросами. \n\n\n$H_0$: максимальное значение **не** является аномальным.\n$H_1$: максимальное значение является аномальным.\n\nАналогичным образом формулируются гипотезы о минимальных значениях:\n\n$H_0$: минимальное значение **не** является аномальным.\n$H_1$: минимальное значение является аномальным.\n\nКак и для любого статистического теста, мы решаем, если p-значение меньше выбранного уровня значимости (чаще всего α=0,05) нулевая гипотеза отклоняется и мы делаем вывод, о том, что значения являются выбросами.\n\nЭтот тест не подходит для выборок, в которых содержится менее 6 наблюдений.\n\nЧтобы выполнить тест Груббса в R, мы будем использовать функцию `grubbs.test()` из библиотеки `{outliers}`:\n\n```{r}\n# install.packages(\"outliers\")\nlibrary(outliers)\ntest <- grubbs.test(df$age, type=10)\ntest\n```\nТест «говорит» нам о том, что максимальное значение не является выбросом.\n\n{{< iconify arcticons writer size=42px >}} **Самостоятельное задание**:\n\nПроверьте, является ли выбросом минимальное значение. Для этого в настройках установите opposite = TRUE. Проверьте гипотезу о принадлежности к выбросам обоих - минимального и максимального значений. Поменяйте настройки на type=11.\n\n##### Тест Диксона\n\nПодобно тесту Груббса, тест Диксона используется для определения того, является ли минимальное или максимальное значение выбросом. Если у нас есть подозрение относительно других значений, мы должны тестировать их индивидуально. \n\nЕще одно ограничение: этот тест хорошо работает только на маленьких выборках (n≤25).\n\nЧтобы попробовать этот метод на наших данных, мы должны сократить нашу выборку и использовать соответствующую функцию из той же библиотеки:\n\n```{r}\nsubdat <- df[1:20, ]\ntest <- dixon.test(subdat$age)\ntest\n\n```\n\n##### Тест Роснера\n\nК теста Роснера есть несколько преимуществ:\n- его можно использовать для вычленения нескольких выбросов за один раз\n- позволяет решать проблемы маскировки, когда один выброс, близкий по значению к другому выбросу, остается незамеченным\n- подходит для больших выборок.\n`\nВ R функция  `rosnerTest()` находится в библиотеке `{EnvStats}`. \nФункция требует по меньшей мере двух аргументов: ссылки на данные и количество выбросов (по умолчанию 3).\n\nФормула теста следующая:\nНаблюдаемые значения сортируются от меньшего к большему, далее определяется максимальное значение выбросов (не больше 10), и затем считается серия статистических тестов, путем последовательного удаления значений (высоких или низких), которые максимально удалены от среднего значения и пересчета стандартных значений по формуле:\n \n$$\\large R_{i+1} = \\frac{|x^{(i)} - \\bar x^{(i)}|}{s^{(i)}}$$\nКак только все статистики $ R_1...R_k$  посчитаны, начинается проверка гипотез путем сопоставления с критическими значениями для определенного уровня значимости.\n\n Попробуем провести этот тест на наших данных:\n\n```{r message=F, warning=F}\n#install.packages(\"EnvStats\")\nlibrary(EnvStats)\ntest <- rosnerTest(df$age,\n  k = 3\n)\ntest\n```\n\nВидим, что результаты также схожи с теми, что мы получили в ходе анализа стандартизированных значений, что неудивительно, учитывая сходство статистических процедур. \n\n### Проверка на нормальность\n\nПодчиняются ли анализируемые количественные переменные закону нормального распределения вероятностей? Очень многие статистические методы предполагают положительный ответ на этот вопрос, и поэтому проверка исследуемых переменных на нормальность распределения является важной составной частью разведочного анализа данных.\n\nКак известно, кривая нормального распределения имеет красивый «колоколообразный вид» и описывается формулой функции плотности вероятности (probability density function, PDF): \n\n$$f(x) = \\frac{e^{-(x - \\mu)^{2}/(2\\sigma^{2}) }} {\\sigma\\sqrt{2\\pi}}$$\n\n```{r echo=FALSE}\ncurve(dnorm(x, 0, 1), from=-4, to=4)\n```\n\n\nНапример, мы желаем проверить гипотезу о равенстве средних значений в двух независимых выборках. Для этой цели подходит критерий Стьюдента. Но применение критерия Стьюдента обосновано, только если данные подчиняются нормальному распределению. Поэтому перед применением критерия необходимо проверить гипотезу о нормальности исходных данных. Или проверка остатков линейной регрессии на нормальность — позволяет проверить, соответствует ли применяемая модель регрессии исходным данным.\n\nНормальное распределение естественным образом возникает практически везде, где речь идет об измерении с ошибками. Более того, в силу центральной предельной теоремы, распределение многих выборочных величин (например, выборочного среднего) при достаточно больших объемах выборки хорошо аппроксимируется нормальным распределением вне зависимости от того, какое распределение было у выборки исходно. \n\nПроверяя условие нормальности распределения данных, необходимо, однако, хорошо представлять себе, в каких случаях его выполнение является критическим для применения конкретного статистического метода. Так, например, метод главных компонент (Principle Components Analysis, PCA) не требует, чтобы данные были распределены нормально. Линейная регрессия (Linear Regression) хотя и предполагает нормальность распределения зависимой переменной, является достаточно робастным методом при незначительных отклонениях от этого условия. В то же время для успешного применения дискриминантного анализа (Discriminant Analysis) нормальность распределениях признаков в каждой группе классифицируемых объектов - условие обязательное (Мастицкий, 2012).\n\n\nПроверку выборки на нормальность можно производить несколькими путями. \n\n- Большое распространение получили графические методы – анализ распределения с помощью гистограммы, диаграммы плотности, визуально показывающие, насколько велики отклонения от нормальности.\n\nМы уже строили для наших данных квантиль-квантиль график, гистограмму и ящичную диаграмму. Пожалуй, единственный график, который мы еще не делали - график плотности.\n\n```{r warning=FALSE}\n ggplot(df, aes(x=age)) + \n  geom_density(fill=\"lightblue\")+\n  theme_bw()\n  \n```\n\n- Можно использовать и данные описательных статистик, помня как в нормальном распределении соотносятся среднее, мода, медиана, какими должны быть асимметрия и эксцесс, выполняется ли «правило 3-х сигм». Обычно обращают внимание на показатели асимметрии и эксцесса, анализируют их абсолютные значения и сравнивают их со стандартными ошибками. \nВыше мы пробовали функцию `describe()` из библиотеки `psych`. Еще один хороший вариант - функция `Desc()` из библиотеки `DescTools`:\n\n```{r}\nlibrary(DescTools)\nDesc(df$age, plotit = TRUE)\n```\n\nОтдельно можно посчитать показатели асимметрии и эксцесса вместе с доверительными интервалами. У нормального распределения они должны быть близкими к нулю.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Negative_and_positive_skew_diagrams_%28English%29.svg/669px-Negative_and_positive_skew_diagrams_%28English%29.svg.png)\n![](https://img.tfd.com/mk/K/X2604-K-11.png)\n\nАсимметрия:\n\n```{r}\nSkew(df$age, na.rm=TRUE, conf.level = 0.95, ci.type = \"classic\")\n```\n\nЭксцесс:\n  \n```{r}\nKurt(df$age, na.rm=TRUE, method=2, conf.level = 0.95, ci.type = \"classic\")\n```\n\n\n- особая группа методов — критерии нормальности. Их существует множество - по меньшей мере 15. Подробные материалы про все критерии с формулами и нюансами интерпретации можно посмотреть [вот здесь](https://yadi.sk/i/QwrWjkIkrKAwF)\n\n\nВ R реализованы практически все имеющиеся тесты на нормальность — либо в виде стандарных функций, либо в виде функций, входящих в состав отдельных пакетов. Примером базовой функции является `shapiro.test()`, при помощи которой можно выполнить широко используемый тест Шапиро-Уилка\n\n#### Тест Шапиро-Уилка\n\nТест Шапиро-Уилка был впервые опубликован в 1965 году Самюэлем Санфордом Шапиро и Мартином Уилком.\n\n$$W=\\frac{(\\Sigma^n_{i=1}a_ix_{(i)})^2}{\\Sigma^n_{i=1}(x_i-\\bar{x})^2}$$\nгде:\n\n$x_i$ – упорядоченные значения анализируемой переменной\n$a_i$ – константы, созданные на основе ковариаций, дисперсий и средних значений по выборке (размера $n$) из нормального распределения (обычно берутся из таблиц).\n\nСчитается одним из лучших и наиболее мощных тестов.\n\n```{r}\nshapiro.test(df$age)\n```\n\nОсновные классические критерии проверки на нормальность собраны в пакете `nortest`. Пакет можно установить с CRAN при помощи вызова функции `install.packages()`:\n\n```{r eval=FALSE}\ninstall.packages(\"nortest\")\n```\n\n\n#### Тест Колмогорова-Смирнова\n\nнаверное, одним из самых известных является тест Колмогорова-Смирнова, носящий имена российских математиков Андрея Николаевича Колмогорова и Николая Васильевича Смирнова.\n\nСтатистика  $D$ Колмогорова-Смирнова вычисляется как максимум модуля разности между эмпирической и теоретической функциями распределения. Эта статистика критерия согласия используется для проверки гипотезы о том, что наблюдения взяты из указанного распределения:\n\n$$D = \\max_{1 \\le i \\le N} \\left( F(Y_{i}) -\n               \\frac{i-1} {N}, \\frac{i}{N} - F(Y_{i}) \\right)$$\nгде $F$ является теоретическим кумулятивным распределением, которое должно обязательно принадлежать к семейству непрерывных распределений. Нулевая гипотеза отклоняется в случае, если тестовая статистика, $D$, превышает критическое значение.\n\nКогда данные сравниваются с теоретическим нормальным распределением, используется поправка Лиллиефорса.\n\n```{r}\nnortest::lillie.test(df$age)\n```\n```{r warning=FALSE}\nplot(ecdf(scale(df$age)), col=\"red\", main=\"Эмпирическая и теоретическая кумулятивные функции\")\ncurve(pnorm, from = -10, to = 10, add = TRUE, col=\"blue\")\n```\n\n#### Тест Андерсона-Дарлинга\n\nТест Андерсона-Дарлинга (Stephens, 1974) используется для тестирования гипотезы о том, что выборочные данные имеют специфическое распределение. Это модификация теста Колмогорова-Смирнова (K-S test), в которой больший вес придается крайним значениям (хвостам), по сравнению с оригинальным тестом\n\nФормула для вычисления критерия такова:\n\n$$A^{2} = -N - S$$\n\n$$S = \\sum_{i=1}^{N}\\frac{(2i - 1)}{N}[\\ln{F(Y_{i})} + \\ln{(1 - F(Y_{N+1-i}))}]$$\n\nгде $F$ - это кумулятивная функция распределения, показывающая вероятность того, что целевое значение меньше указанного значения либо равно ему.\n\nВ библиотеке `nortest` тест Андерсона-Дарлинга реализован в функции `ad.test()`:\n```{r}\nnortest::ad.test(df$age)\n```\n\n#### Тест Крамера-фон-Мизеса\n\nТест Крамера-фон-Мизеса является еще одной альтернативой тесту Колмогорова-Смирнова и представляет собой комплексный тест для проверки нормальности. Он использует сумму квадратов различий между наблюдаемыми и ожидаемыми кумулятивными пропорциями в качестве тестовой статистики. \n\nТест имеет следующую формулу:\n\n$$\\begin{align}\nW_n^2:=n\\int(F_n(x)-F_0(x))^2\\,\\mathrm{d}F_0(x).\n\\end{align}$$\n\nЕсли $H_0: F=F_0$ справедливо, то  $W^2_n$ являются маленькими значениями. Соответственно, отвержение гипотезы происходит при больших значениях $W^2_n$. Считается, что тест Крамера-фон-Мизеса более мощный, по сравнению с классическим тестом Колмогорова-Смирнова.\n\nВ библиотеке `nortest` для теста Крамера-фон-Мизеса используется функция `cvm.test()`:\n```{r}\nnortest::cvm.test(df$age)\n```\n\n## Анализ категориальных переменных\n\nРассмотрев возможности разведочного анализа количественных переменных, перейдем к категориальным данным, представленным в номинальных и порядковых шкалах\n\n### Описание таблиц без их представления в тексте\n\nВо многих случаях в ходе анализа нам нужны просто цифры, ведь не все результаты представляются в виде таблиц и графиков, что-то просто описывается словами, поэтому иногда проще и быстрее использовать базовый код, без премудростей.\n\nПредставим ситуацию, что мы описываем нашу выборочную совокупность и хотим представить информацию по количеству опрошенных по разным регионам исследования.\n\nИтак, если нам нужны простые частоты, не проценты, одним из простых решений будет функция из базового R `table ()`. \n\nНапример, посмотрим распределение по регионам, предварительно переведя все переменные факторные, поскольку их большинство:\n\n```{r echo=TRUE}\ndf <- haven::as_factor(df)\ntable(df$Region)\n```\n\n\n\nЕсли нам нужны не абсолютные, а относительные частоты по отдельным вопросам, для которых мы не собираемся делать какие-то таблицы или графики (то есть эти данные нужны только для описания), то для этой цели можно использовать , базовую функцию `prop.table`. \n\nНапример, мы хотим узнать пропорции по полу во всех регионах исследования (умножим на 100, чтобы получить значения в процентах, а не долях: \n\n```{r}\nprop.table(table(df$V1))*100\n\n```\nС помощью этих же функций можно создать и двумерные таблицы:\n```{r}\nprop.table(table(df$V1, df$Region), margin = 2)*100\n```\n\nБолее интересный вариант предлагает функция `flat_table` (переводится как \"плоская таблица\") из библиотеки `sjmisc`. \n\n\n```{r echo=TRUE}\nsjmisc::flat_table(df, V1, margin = \"cell\")\n```\n\nМы видим, что в наших исследованиях приняло участие гораздо больше женщин (почти 68%), чем мужчин (35%).\n\nЕсли нужна двумерная таблица, функция `flat_table` также подойдет (так же как и функции `prop.table`, `sjt.xtab` и другие, запомним, что в R всегда можно сделать одно и то же разными путями, здесь дело вкуса):\n\n\n```{r echo=TRUE}\ntable<-sjmisc::flat_table(df, Region, V1, margin = \"row\")# df - наша база данных, Region V1 - переменные для строк и столбцов, margin = \"row\"  - процент по строке\ntable\n\n```\n\nВыглядит не очень с точки зрения оформления, зато мы быстро получили результаты и можем их описать. Видим, что женщины превалируют во всех регионах, из доля составляет более 60%, в Республике Тыва - 75%.\n\nБолее того, мы можем сохранить эту таблицу в формате датафрейма и потом использовать в других приложениях:\n```{r}\ntable<-tidyr::as_tibble(table)\ntable\n```\n\nЕсли мы посмотрим, то получилось не совсем то, что нам бы хотелось: у нас получилась таблица в «длинном формате», вместо широкого. К счастью это можно быстро исправить с помощью уже знакомой нам функции `pivot_wider()`из библиотеки `tidyr`, являющейся частью экосистемы `tidyverse`.\n\n```{r}\nlibrary(tidyr)\ntable<-table %>% \n  pivot_wider(names_from = V1, values_from = Freq)\ntable\n```\n\nЕще нам постоянно мешает это единственное наблюдение из Монголии. Давайте его уберем и пересчитаем все заново.\n\nДля начала отфильтруем переменную `Region` так, чтобы в нее входили все регионы, кроме Монголии:\n\n```{r}\nlibrary(dplyr)\ndf<-df %>% \n  filter(Region!=\"Монголия\")\n```\n\nПопробуем сделать простую таблицу:\n```{r}\ntable(df$Region, df$V1)\n```\nКак видим, наблюдение мы удалили, но метка (уровень факторной переменной) осталась, и нам нужно его убрать. Сделать это можно с помощью функции `droplevels`. Удалим уровень и сделаем новую таблицу\n```{r}\ndf$Region<-droplevels(df$Region)\nsjmisc::flat_table(df, Region, V1, margin = \"row\")\n```\nВсе получилось!\n\nМежду тем, очевидно, что для хорошей статьи (диссертации, отчета об исследовании) описания результатов частотного анализа недостаточно, требуется представлять результаты комплексно, сразу по нескольким переменным, часто с учетом группировки, и приводить доказательства значимости имеющихся различий на основе применения статистических методов.\n\n### Создание таблиц по нескольким переменным: возможности библиотек `gtsummary` и `flextable`\n\n* **flextable** -- чудо-библиотека от Дэвида Гоэля - француза и сотрудника ArData, созданная специально для работы с таблицами и улучшения их отображения в различных форматах, в частности в Word и Power Point\n* **gtsummary** -- библиотека для создания эффектных таблиц с описательными статистиками для научных публикаций\n\nПредположим, что для нашей будущей статьи, которую мы готовим по результатам исследования, мы хотим создать большую таблицу, содержащую распределения сразу по нескольким переменным, описывающим все важные демографические и социальные характеристики, такие как пол, возраст по группам, социальный статус, в том числе - с учетом региональных различий. Желательно также посчитать, являются ли эти различия значимыми, используя для этого критерий $\\chi^2$ Пирсона. \n\nБиблиотека `gtsummary` была создана специально для того, чтобы быстро создавать гибкие с точки зрения форматирования таблицы с описательными статистиками и результатами регрессионного анализа, оформленные по стандартам для научных публикаций. \n\nНастоятельно рекомендуется посетить сайт проекта и подробно ознакомиться с возможностями данной библиотеки. \nhttps://www.danieldsjoberg.com/gtsummary/index.html\n\nДля начала создадим общую таблицу, где в строках будут располагаться данные по возрасту, полу, региону проживания, социальному статусу, а также наличию гражданства другой страны.\n\n```{r, message = FALSE, warning=FALSE}\nlibrary(dplyr)\n#install.packages(\"gtsummary\") - убрать решетку и запустить строку\nlibrary(gtsummary)\n#вспоминаем урок по dplyr\ntable<-df %>% \n  select(Region, V1, age_cats3, V10, V6)  #отберем нужные переменные в отдельный сет и сохраним его под именем table\n# создадим таблицу\ntable %>% \n  tbl_summary(missing=\"no\") #функция tbl_summary позволяет создать комплексные таблицы\n\n```\n\n\nВ принципе, очень неплохо. Добавим группировку по региону и поменяем заголовок у переменных с \"Characteristic\" на \"Характеристику\":\n\n```{r, message = FALSE, warning=FALSE}\ntable %>% \n  tbl_summary(by=Region, missing=\"no\") %>%#by=V004 - так мы обозначаем группирующую переменную\n  modify_header(#функция, позволяющая изменить заголовок\n    update = list(\n      label ~ \"Характеристика\" #\n    )\n  )\n```\n\nПрочитать подробнее о функции tbl_summary, ее атрибутах, с подробным разбором примеров и возможностей изменения таблицы:\nhttp://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html\n\nМожно сделать и простую двумерную таблицу:\n```{r}\n table %>%\n  tbl_cross(row = V1, col = age_cats3, percent = \"cell\", missing=\"no\", ) %>%\n  add_p(test=\"chisq.test\") %>% #добавляем статистику хи-квадрат\n  modify_header(#функция, позволяющая изменить заголовок\n    update = list(\n      label ~ \"**Характеристика**\" #\n    )\n  ) %>% \n  modify_caption(\"**Взаимосвязь пола и возраста** (N = {N})\") #меняем заголовок на нужный, причем заголовок вставляем количество опрошенных\n```\n\n \n\n### Пример анализа вопроса с множественными ответами\n\nДля выполнения данного задания нам понадобится `questionr` - библиотека, позволяющая анализировать таблицы с множественными ответами.\n\nПрежде чем выполнить последующий код, установите пакет questionr на свой комьютер и запустите библиотеку:\n```{r, fig.width=10, fig.height=3}\n#install.packages(\"questionr\") - убрать решетку и запустить строку\nlibrary(questionr)\n```\n\nУ нас в анкете был вопрос 9, в котором изучалось, чем владеет домохозяйство. Можно было выбрать несколько вариантов ответа, а также дать собственный вариант ответа - «Другое». Ответы были закодированы дихотомическим способом, выбор кодировался как 1, а его отсутствие - как 0. \n\nКак в других программах статистической обработки, в R нам потребуется сделать два шага для того, чтобы проанализировать вопрос с множественным выбором:\n- создать набор данных, в который объединяются отдельные подвопросы;\n- сделать таблицу, которая может быть как одномерной, так и многомерной.\n\nДавайте объединим все подвопросы вопроса V9 в один набор и сохраним его под отдельным именем  - V9. Воспользуемся знакомыми нам функциями `select()` - для отбора переменных и `contains()` - отбора переменных, имена которых содержат определенный паттерн:\n\n```{r message=FALSE, warning=FALSE}\nlibrary(dplyr)\nV9<-df %>% \n  select(contains(\"V9\")) %>% \n  select_if(is.factor)#дополнительный select нужен, чтобы убрать текстовую переменную «другое»\n```\n\nДалее, создадим таблицу и сохраним ее в качестве отдельного датафрейма.\n\n```{r}\nlibrary(questionr)\nlibrary(dplyr)\nV9tab<-V9 %>% \nmulti.table(true.codes=list(\"да\"), freq=TRUE) %>% \n    as.data.frame() %>% \n  rename(Pct=`%multi`) %>% \n  arrange(desc(Pct))\nV9tab\n```\nДа, выглядит так себе, но зато все посчитано) сразу.\n\nПоясним, что `true.codes=list(\"да\")` - обозначаем вариант ответа, используемый для подсчета частот и процентов, `freq=TRUE` - вывод процентов, а не только частот.\n\n\nКак добавить метки вопросов в нашу таблицу? \nИзвлечем метки вопросов по блоку V9 в отдельное место:\n\n\n```{r message=FALSE, warning=FALSE}\nlibrary(sjlabelled)\nV9labs<-df %>% \nselect(contains(\"V9\")) %>% \n  select_if(is.factor) %>% \n  get_label()\nV9labs\n```\n\nПрисвоим имена в переменную `n`:\n```{r}\nV9tab$n<-V9labs\nV9tab\n```\n\n### Таблица сопряженности с множественными ответами\n\n\n```{r}\nV9Regiontab<-cross.multi.table(V9, df$Region, true.codes=list(\"да\"), freq=TRUE)\nV9Regiontab<-as_tibble(V9Regiontab)\nV9Regiontab$n<-V9labs\nV9Regiontab<-V9Regiontab %>% \n  relocate(n)\n```\n\n\n### Графики для категориальных переменных\n\nОсновными графиками для категориальных переменных являются круговые и столбиковые диаграммы, а также мозаичные и ассоциативные графики, когда в анализе задействовано более двух переменных.\n\nДавайте создадим такие графики для переменных по возрасту. Красивые минималистичные графики с небольшим количеством кода и исправлений можно создать с помощью библиотеки `ggpubr` от Alboukadel Kassambara (биолог, автор книг по биоинформатике и биологии рака).\n\nСоздадим одномерную таблицу для возраста и двумерную для взаимосвязи между полом и возрастом.\n\n```{r}\nage<- as.data.frame(sjmisc::flat_table(df, age_cats3, margin = \"cell\", digits = 1))\nage_sex<-as.data.frame(sjmisc::flat_table(df, age_cats3, V1, margin = \"row\", digits = 1))\n```\n\nСделаем простую столбиковую диаграмму по возрастным группам, в качестве «изюминки» добавим красивые шрифты.\n\nПрежде чем сделать сам график, установим шрифты, чтобы потом ими можно было пользоваться постоянно.\n```{r eval=FALSE}\ninstall.packages(\"extrafont\")\nlibrary(extrafont)\nfont_import()#шрифты устанавливаются сразу все, это может занять некоторое время\n```\n\n```{r echo=FALSE, message=FALSE}\nlibrary(extrafont)\n```\n\nВ результате будут импортированы следующие шрифты:\n![](http://gradientdescending.com/plots/fonttable_big.png)\nПосле установки шрифты нужно загружать каждую сессию: \n```{r}\nloadfonts(device = \"win\", quiet = TRUE)\n```\n\nТеперь займемся самим графиком.\nРазберем его структуру строчка за строчкой:\n- `ggplot(data=age, aes(x=age_cats3, y=Freq)) +` - создаем базовый график, где по оси x у нас будут возрастные категории, а по y - проценты\n- `geom_bar(stat=\"identity\", fill=\"steelblue\", width = 0.6)+` - добавляем слой для столбиковой диаграммы, `stat=\"identity\"` - означает, что мы будем использовать данные «как есть», а не агрегировать на основе исходных, `fill=\"steelblue\"` - задаем цвет, `width = 0.6` - устанавливаем ширину столбцов чуть меньше обычного, для красоты))\n- `geom_text(aes(label=scales::number(Freq,accuracy=0.1, decimal.mark = \",\")),  family = \"Ink Free\", vjust=0.5, hjust=-0.5, color=\"steelblue\", size=4)+` - тут много всего, эта часть кода отвечает за подписи к столбцам. `label=number(Freq,accuracy=0.1, decimal.mark = \",\"))` - устанавливаем подписи в числовом формате, запятую в качестве разделителя и округление до одного знака после запятой, `family = \"Ink Free\", vjust=0.5, hjust=-0.5` - задаем шрифт Ink Free, делаем выравнивание, чтобы число было ровно посредине столбца и слегка выходило за его пределы (можно поэкспериментировать с этими настройками), `color=\"steelblue\", size=4` - эти настройки отвечают за цвет и размер текста\n- `coord_flip()` - переворачиваем диаграмму в горизонтальную проекцию\n- `theme_void()`- устанавливаем тему, в которой есть только белый фон\n- `expand_limits(y=c(0,50))` - раздвигаем границы по оси y, там, где проценты (это неважно, что при повороте диаграмма «ложится на бок» и оси вроде как меняются местами)\n- `theme(axis.text.y = element_text(size = 10, family = \"Ink Free\")` - устанавливаем размер и семейство шрифтов для подписей - категорий возраста\n- `scale_x_discrete(limits=rev)` - ну и, напоследок, меняем порядок категорий, от младшей возрастной группы к старшей\n```{r}\n#| fig-width: 7\n#| fig-height: 3\nlibrary(ggplot2)\nlibrary(scales)#нужна для того, чтобы отформатировать подпись\nggplot(data=age, aes(x=age_cats3, y=Freq)) +\n  geom_bar(stat=\"identity\", fill=\"steelblue\", width = 0.6)+\n  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")),  family = \"Ink Free\", vjust=0.5, hjust=-0.5, color=\"steelblue\", size=4)+\n  coord_flip()+\n  theme_void()+\n  expand_limits(y=c(0,50))+\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+\n  scale_x_discrete(limits=rev)\n```\n\nДобавим данные по полу. В нашем коде почти ничего не поменялось, за исключением некоторых моментов:\n- `fill=V1` - мы добавили в исходный график, чтобы сделать разбивку по полу\n- в `geom_bar(stat=\"identity\", position=\"dodge\", width = 0.6)` добавили `position=\"dodge\"` - чтобы столбцы располагались рядом друг с другом, такой же аргумент добавлен и в `geom_text`\n- в конце появилось две новых строки   `theme(legend.position=\"bottom\")+  theme(legend.title=element_blank())`, они нужны для оформления легенды\n\n```{r}\n#| fig-width: 7\n#| fig-height: 3\nlibrary(ggplot2)\nlibrary(scales)#нужна для того, чтобы отформатировать подпись\nggplot(data=age_sex, aes(x=age_cats3, y=Freq, fill=V1)) +\n  geom_bar(stat=\"identity\", position=\"dodge\", width = 0.6)+\n  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")),  position = position_dodge(width = 0.6), hjust=-0.3, family = \"Ink Free\", size=4)+\n  coord_flip()+\n  theme_void()+\n  expand_limits(y=c(0,100))+\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+\n  scale_x_discrete(limits=rev)+\n  theme(legend.position=\"bottom\")+\n  theme(legend.title=element_blank())\n```\n\n В качестве альтернативы можно создать сгруппированные столбиковые диаграммы в библиотеке `ggstatsplot`:\n \n\n```{r}\nggstatsplot::ggbarstats(df, x = V1, y = age_cats3)\n```\n \n \n создать круговую диаграмму:\n \n```{r warning=FALSE}\n#| fig-width: 4\n#| fig-height: 4\nggplot(age, aes(x = \"\", y = Freq, fill = age_cats3)) +\n  geom_col(color = \"black\") +\n  geom_label(aes(label=number(Freq,accuracy=0.1, decimal.mark = \",\")), color = \"white\",\n            position = position_stack(vjust = 0.5),\n            show.legend = FALSE) +\n  guides(fill = guide_legend(title = \"Возраст\")) +\n  scale_fill_viridis_d() +#эта строка добавляет цветовую палитру\n  coord_polar(theta = \"y\") + \n  theme_void()\n```\n \n \n Более простым решением является создание круговой диаграммы с помощью функции `ggpiestats` из библиотеки `ggstatsplot`:\n\n\n```{r}\nggstatsplot::ggpiestats(df, age_cats3, legend.title = \"Возраст\")\n\n```\nС помощью этой же функции можно создать серию круговых диаграмм:\n```{r}\nggstatsplot::ggpiestats(df, V1, age_cats3)\n```\nПосмотреть отдельно хи-квадрат:\n\n```{r}\nchisq.test(df$V1, df$age_cats3)\n```\n\nСделаем график для вопросов с множественными ответами, по вопросу V9. В описаниях вариантов ответов есть длинные формулировки, которые будут не очень хорошо смотреться на графике, поэтому прежде, чем создавать график, давайте уберем все, что написано в скобках, так как это скорее не основная, а уточняющая информация.\n\nДля этого мы воспользуемся функцией `gsub`, в которую включим выражение, позволяющее отсечь текст, лежащий после знака `(`.\n\n\n```{r}\nV9tab$n<-gsub(\"\\\\(.*\", \"\", V9tab$n)\n```\n\nХотя в таблице значения отсортированы, на графике они все равно будут отображаться в том порядке, в котором представлены уровни факторной переменной. Поэтому, чтобы на графике у нас были отображены значения по убыванию (мы же не хотим, чтобы у нас получился хаос из 14 вариантов ответа), нам нужно отсортировать уровни,  для чего нам потребуется библиотека `forcats`.\n\nИ поскольку ширина подписей, несмотря на то, что мы их сократили, будет довольно существенной, мы сделаем самые длинные подписи в две строки, что, в свою очередь, потребует работы с библиотекой `stringr` (раз это новые для нас библиотеки и мы про них не слышали, нужно их установить).\n```{r}\nlibrary(forcats)\nlibrary(stringr)\n#| fig-width: 200%\nV9tab %>%\n  mutate(n = fct_reorder(n, Pct)) %>% # переставим местами уровни\nggplot(aes(x=n, y=Pct, fill=n)) + # создадим типовой график\n  geom_bar(stat=\"identity\", width = 0.6)+  # добавим geom\n  geom_text(aes(label=number(Pct,accuracy=0.1, decimal.mark = \",\")), hjust=-0.3, family = \"Ink Free\", size=4)+   # поработаем с подписями данных\n  expand_limits(y=c(0,80))+# увеличим лимит оси \n  coord_flip()+  # перевернем график в горизонтальное положение\n  theme_void()+   # добавим минималистичную тему\n  theme(axis.text.y = element_text(size = 10, family = \"Ink Free\"))+    # установим шрифт для подписей\n  theme(legend.position=\"none\")+       # уберем легенду\n  scale_x_discrete(labels = function(x) str_wrap(x, width = 30))       # Сделаем длинные подписи в несколько строк\n```\n\n## Самостоятельная работа\n\n1. Провести комплексную проверку на нормальность переменной `Sepal.Length` из набора `iris.\n2. Провести одномерный анализ по переменным V12, V13, V15. Сделать двумерный анализ по региону и возрасту.\n3. Проанализировать переменные с множественным выбором V14 и V16, также сделать двумерный анализ по региону. По всем видам анализа сделать таблицы и графики.\n4. Представить все в виде отдельного документа - по желанию в каком формате.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["include/webex.css"],"include-after-body":["include/webex.js"],"embed-resources":false,"output-file":"ExploratoryDataAnalysis.html"},"language":{"toc-title-document":"Содержание","toc-title-website":"Содержание","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","other-links-title":"Другие ссылки","code-links-title":"Ссылки на код","launch-dev-container-title":"Запустить Dev Container","launch-binder-title":"Запустить Binder","article-notebook-label":"Блокнот статьи","notebook-preview-download":"Скачать блокнот","notebook-preview-download-src":"Скачать исходный код","notebook-preview-back":"Вернуться к статье","manuscript-meca-bundle":"Архив MECA","section-title-abstract":"Аннотация","section-title-appendices":"Приложения","section-title-footnotes":"Сноски","section-title-references":"использованная литература","section-title-reuse":"Повторное использование","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Пожалуйста, цитируйте эту работу как:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Просмотреть Лицензию","title-block-author-single":"Автор","title-block-author-plural":"Авторы","title-block-affiliation-single":"принадлежность","title-block-affiliation-plural":"Принадлежности","title-block-published":"Дата публикации","title-block-modified":"Файл изменен","title-block-keywords":"Ключевые слова","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Развернуть код","code-tools-hide-all-code":"Скрыть код","code-tools-view-source":"Показать код","code-tools-source-code":"Исходный код","tools-share":"Share","tools-download":"Download","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Скопировать текст","copy-button-tooltip-success":"Скопировано","repo-action-links-edit":"Редактировать страницу","repo-action-links-source":"Показать код","repo-action-links-issue":"Сообщить о проблеме","back-to-top":"Наверх","search-no-results-text":"Поиск не дал результатов","search-matching-documents-text":"Результаты поиска","search-copy-link-title":"Скопировать ссылку","search-hide-matches-text":"Скрыть дополнительные результаты","search-more-match-text":"дополнительный результат в этом документе","search-more-matches-text":"дополнительных результата(-ов) в этом документе","search-clear-button-title":"Очистить","search-text-placeholder":"","search-detached-cancel-button-title":"Отменить","search-submit-button-title":"Найти","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рисунок","crossref-tbl-title":"Таблица","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лемма","crossref-cor-title":"Следствие","crossref-prp-title":"Утверждение","crossref-cnj-title":"Гипотеза","crossref-def-title":"Определение","crossref-exm-title":"Пример","crossref-exr-title":"Упражнение","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Приложение","crossref-sec-prefix":"Глава","crossref-eq-prefix":"Уравнение","crossref-lof-title":"Список Иллюстраций","crossref-lot-title":"Список Таблиц","crossref-lol-title":"Список Каталогов","environment-proof-title":"Доказательство","environment-remark-title":"Примечание","environment-solution-title":"Решение","listing-page-order-by":"Сортировать по","listing-page-order-by-default":"предварительно выбранный","listing-page-order-by-date-asc":"Самый старый","listing-page-order-by-date-desc":"Новейшие","listing-page-order-by-number-desc":"нисходящий","listing-page-order-by-number-asc":"по возрастанию","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Описание","listing-page-field-author":"Автор","listing-page-field-filename":"Имя файла","listing-page-field-filemodified":"Файл изменен","listing-page-field-subtitle":"Подзаголовок","listing-page-field-readingtime":"Время чтения","listing-page-field-wordcount":"Подсчет слов","listing-page-field-categories":"Категории","listing-page-minutes-compact":"{0} минут","listing-page-category-all":"Все","listing-page-no-matches":"Нет подходящих элементов","listing-page-words":"{0} слов","listing-page-filter":"Фильтр","draft":"Черновик"},"metadata":{"lang":"ru","fig-responsive":true,"quarto-version":"1.5.57","comments":{"hypothesis":true},"bibliography":["references.bib"],"editor":"visual","theme":"Pulse","title":"Разведочный анализ данных в R"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}