{"title":"Основы многомерного анализа: снижение размерности","markdown":{"yaml":{"title":"Основы многомерного анализа: снижение размерности"},"headingText":"Общие цели занятия и возможности библиотеки`factoextra`","containsRefs":true,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\n**Многомерный анализ данных** представляет собой сложную, но очень интересную задачу, которая часто встречается в деятельности аналитика данных. Задачи анализа взаимосвязей между переменными, их структурирование в виде кластеров, факторов, компонент и представление в визуально интерпретируемом виде часто встречаются, как в фундаментальных, так и прикладных исследованиях.\n\nМногомерный анализ основан на принципе многомерной статистики, который предполагает наблюдение и анализ более чем одной переменной за один раз. Обычно многомерный анализ используется для решения ситуаций, когда в ходе научного эксперимента выполняются несколько измерений, и взаимосвязь между этими измерениями и их структурами имеет важное значение.\n\nМногомерный анализ охватывает большой репертуар методов, включая факторный анализ, кластерный анализ, регрессионный анализ, метод главных компонент и другие, поэтому эта обширная тема, в которой мы изучим только некоторые направления анализа.\n\nМногомерный анализ включает в себя:\n\n-   модели, основанные на многомерном нормальном распределении и генерализованные модели\n-   измерение и анализ взаимосвязей между отдельными переменными\n-   расчеты вероятностей на многомерных данных\n-   изучение структур и паттернов в данных\n\nДля подобных целей на языке R разработано множество библиотек, но определенными преимуществами обладает одна из них - `factoextra`. Ее цель заключается в извлечении результатов и визуализации **эксплораторного** многомерного анализа данных, включая:\n\n**Метод главных компонент - Principal Component Analysis (PCA)** - анализирующий количественные (непрерывные) переменные путем сокращения размерности данных без потери важной информации (например, представление множества шкал психологических тестов в виде нескольких компонент или представление множества показателей социально-экономического развития регионов в виде нескольких интегральных показателей).\n\n**Корреспондентский анализ (анализ соответствий) - Correspondence Analysis (CA)**, выступающий расширением метода главных компонент для анализа больших таблиц сопряженности, образуемых на основе двух качественных переменных (категориальных данных)(например, продукты и их характеристики, метод хорошо подходит для вопросов с множественным выбором).\n\n**Множественный корреспондентский анализ, множественный анализ соответствий - Multiple Correspondence Analysis (MCA)**, являющийся адаптацией метода CA к таблице данных, содержащих более двух категориальных переменных (например, взаимосвязь между занятостью, национальностью и полом).\n\n**Множественный факторный анализ - Multiple Factor Analysis (MFA)** - предназначен для работы с данными, где переменные организованы в группы, блоки или наборы (качественных и / или количественных) переменныех. MFA позволяет обнаружить общие структуры, присутствующие во всех или некоторых наборах данных. Выполняется в два этапа. На первом этапе на каждом наборе данных проводится анализ главных компонент, а затем исходные данные в каждом наборе «нормализуются» путем деления каждого элемента на квадратный корень из собственного значения, полученного из МГК на данном наборе. Затем, нормализованные данные объединяются в единую матрицу, над которой проводится общий анализ главных компонент, а индивидуальные наборы данных проектируются на результаты этого анализа, чтобы найти общие зависимости и расхождения [@abdi2007multiple]\n\n**Иерархический множественный факторный анализ - Hierarchical Multiple Factor Analysis (HMFA)**: расширение метода MFA, подходящий для ситуации, где данные организованы в иерархические структуры.\n\n**Факторный анализ смешанных данных - Factor Analysis of Mixed Data (FAMD)** - особый случай MFA, предназначенный для анализа данных, содержащих как количественные, так и качественные переменные.\n\n::: {.alert .alert-info role=\"alert\"}\n**Важно!** Сам анализ проводится с помощью других библиотек, библиотека factoextra используется для извлечения результатов и визуализации.\n:::\n\nСуществует большое количество пакетов, в которых можно сделать анализ главных компонент, например, `FactoMineR`, `ade4`, `stats`, `ca`, `MASS` и `ExPosition`.\n\nРезультаты будут представлены по-разному, в зависимости от того, какие функции будут использованы. Помочь в интерпретации и визуализации полученных результатов многомерного анализа, например, кластерного анализа или результатов снижения размерности, нам как раз и поможет библиотека `factoextra`.\n\nВ рамках данного занятия мы будем использовать библиотеку `FactoMineR` [@le2008factominer] для расчетов, а библиотеку `factoextra` для извлечения и анализа результатов.\n\nС какими методами может работать библиотека `factoextra`:\n\n![](https://cran.r-project.org/web/packages/factoextra/readme/tools/factoextra-r-package.png)\n\n### Как сделать правильный выбор?\n\nВыбор метода для анализа будет зависеть от формата данных и их структуры:\n\nТак, например, если у нас количественные данные, то нам подойдет метод главных компонент, а если качественные, то в зависимости от их количества - анализ соответствий - простой или множественный.\n\nВ случае, если данные разной природы, то нам лучше обратиться к смешанным методам - иерархическому множественному факторному анализу или факторному анализу для смешанных данных. . ![](https://cran.r-project.org/web/packages/factoextra/readme/tools/multivariate-analysis-factoextra.png)\n\n### Установка и загрузка библиотек\n\nУстанавливаем библиотеки:\n\n```{r, eval=FALSE, message=FALSE, warning=FALSE}\ninstall.packages(\"factoextra\")\ninstall.packages(\"FactoMineR\")\n```\n\nЗагружаем:\n\n```{r}\nlibrary(\"factoextra\")\nlibrary(\"FactoMineR\")\n```\n\n## Метод главных компонент (Principal component analysis)\n\nМетод главных компонент (PCA) позволяет суммировать и визуализировать информацию, представленную в наборе данных, где некоторые индивиды / наблюдения описываются через большое количество взаимосвязанных друг с другом количественных переменных. Каждая переменная может быть представлена в качестве отдельного измерения. Если переменных больше трех, то визуализация результатов становится затруднительным.\n\nМетод главных компонент извлекает информацию из многомерной таблицы данных $n \\times k$ и представляет ее в виде новых переменных, чье количество меньше количества исходных переменных.\n\nЭто новые переменные и называются **главные компоненты**, они являются линейной комбинацией исходных переменных. Количество главных компонент всегда меньше или равно количеству исходных переменных.\n\nИнформация набора данных соответствует дисперсии переменных, которые в него входят.\n\nЦель МГК заключается в идентификации главных компонент, описывающих максимум дисперсии переменных. Снижение размерности заключается в определении ведущих направлений (векторов), или главных компонент, показывающих изменение данных.\n\nМетод МГК предполагает, что эти главные направления описывают большую часть дисперсии, поэтому являются более важными.\n\n::: {#fig-proj}\n![](https://i.sstatic.net/Q7HIP.gif) Геометрический смысл нахождения главной компоненты.\n:::\n\nДругими словами, МГК сокращает размерность данных, путем выделения двух или трех самых важных компонент, которые мы может визуализировать графически и минимальной потерей информации.\n\nТаким образом, главными задачами метода главных компонент являются:\n\n-   выявление скрытой структуры в наборе данных,\n-   снизить размерность данных, путем удаления статистического шума и избыточных переменных\n-   идентифицировать взаимосвязанные переменные\n\nНа практике этот метод реализуется двумя возможными подходами:\n\n-   путем разложения исходной матрицы взаимосвязей (ковариаций или корреляций) на произведение матриц собственных значений и собственных векторов\n-   путем сингулярного разложения данной матрицы.\n\n### Собственные значения и собственные вектора\n\nДопустим наши данные представлены в матрице $\\mathbf X$ размера $n \\times p$, где $n$ – количество наблюдений, а $p$ – количество признаков. Наши данные должны быть центрированы, то есть в каждом столбце из каждого элемента должно быть вычтено среднее значение, так чтобы среднее значение по каждому признаку равнялось нулю.\n\nТогда $p \\times p$ матрица ковариаций $\\mathbf C$ может быть представлена как:\n\n$$\\mathbf C = \\mathbf X^\\top \\mathbf X/(n-1)$$\n\nПоскольку эта матрица симметричная, она может быть диагонализирована, то есть представлена в виде произведения трех матриц, в результате чего находится соответствующая диагональной матрицы собственных значений:\n\n$$\\mathbf C = \\mathbf V \\mathbf L \\mathbf V^\\top,$$\n\nгде $\\mathbf V$ - это матрица собственных векторов,а $\\mathbf L$ - это диагональная матрица, на диагонали которой находятся собственные значения $λ_i$, упорядоченные по убыванию:\n\n$$\\mathbf L = \\begin{bmatrix}\n\\lambda_1 &  & & \\\\ \n & \\lambda_2 & & \\\\ \n & & \\lambda_{...} & \\\\\n & & & \\lambda_p  \\\\\n\\end{bmatrix}$$\n\nСобственные вектора называются **главными осями** или **главными направлениями**.\n\nПроекции данных на главные оси собственно и называются **главными компонентами**, представляющими собой новые, трансформированные переменные.\n\nГлавная компонента $j$ находится в $j$ столбце матрицы $\\mathbf {XV}$.\n\nКоординаты $i-ой$ точки данных в новом пространстве главных компонент заданы $i-й$ строкой $\\mathbf XV$.\n\nДля нахождения собственных значений решается характеристическое уравнение:\n\n$$|\\mathbf C-\\mathbf \\Lambda \\mathbf I|\\vec{x}=0,$$\n\nпредполагающее вычисление детерминанта $|\\mathbf C-\\mathbf \\Lambda \\mathbf I|$ и корней уравнения степени $n$, в результате которого находятся $\\lambda_1, \\lambda_2, ... \\lambda_p$.\n\nДалее, путем подстановки собственных значений в исходное уравнение, для каждого $\\lambda$ находится собственный вектор.\n\nФундаментальным для метода главных компонент является уравнение:\n\n$$\\mathbf C=\\mathbf A \\mathbf {A}',$$\n\nгде $\\mathbf A$ – матрица нагрузок, а $\\mathbf {A}'$ - транспонированная ей матрица.\n\nНагрузки получаются путем умножения собственных векторов на квадрат из собственных значений:\n\n$$\\mathbf A= \\mathbf V \\sqrt{\\mathbf \\Lambda}$$\n\nТаким образом, главную компоненту можно представить как линейную комбинацию исходных данных и компонентных нагрузок.\n\nПример с первой компонентой:\n\n$$PC_k = a_{k1}X_1 + a_{k2}X_2 + … + a_{kp}X_p,$$\n\nгде a$_ij$ является нагрузкой переменной $x_j$ по компоненте $PC_i$, $x_j$ – $j-ая$ переменная матрицы признаков $\\mathbf X$.\n\n### Сингулярное разложение\n\nКогда мы осуществляем сингулярное разложение матрицы взаимосвязей, у нас получается несколько иная картина:\n\n$$\\mathbf X = \\mathbf U \\mathbf S \\mathbf V^\\top,$$\n\nгде $\\mathbf U$ - являются унитарной матрицей (столбцы которой называются левыми сингулярными векторами), $\\mathbf S$ - диагональная матрица сингулярных значений $s_i$, а столбцы матрицы $\\mathbf V$ называются правыми сингулярными векторами.\n\nПравые сингулярные вектора – это и есть собственные вектора $A^\\top A$, то есть между методами есть тесная взаимосвязь, и $\\lambda_i = s_i^2/(n-1)$.\n\n> {{< iconify arcticons anz size=42px >}} **Пример**: Рассмотрим пример с данными соревнований по десятиборью, в которые входят следующие дисциплины:\n\n-   \"X100m\" - бег на 100 метров\n-   \"Long.jump\" - прыжки в длину\n-   \"Shot.put\" - толкание ядра\n-   \"High.jump\" - прыжки в высоту\n-   \"X400m\" - бег на 400 метров\n-   \"X110m.hurdle\" - бег с препятсвиями\n-   \"Discus\" - метание диска\n-   \"Pole.vault\" - прыжок с шестом\n-   \"Javeline\" - метание копья\n-   \"X1500m\" - без на 1500 метров\n\n![](https://sportsmatik.com/uploads/matik-sports-corner/matik-know-how/decathlon_1499492047_83444.jpg)\n\n```{r}\ndata(decathlon2)\nhead(decathlon2)\n```\n\n![](images/PCA/pic3.png)\n\nИтак, наши данные описывают выполнение атлетами испытаний в двух типах спортивных соревнований (Desctar и OlympicG). Набор содержит информацию о 27 спортсменах и 13 переменных.\n\n**Активные спортсмены** (голубой цвел, строки 1:23) : Данные, которые будут использованы для проведения анализа методом главных компонент. **Дополнительные спортсмены** (синий цвет, строки 24:27) : Координаты по этим спортсменам будут использованы для предсказания параметров с помощью МГК по информации полученной по активным спортсменам / переменным **Активные переменные** (розовый цвет, столбцы 1:10) : переменные, используемые в МГК **Дополнительные переменные**: используются для предсказания, включая:\n\n**Дополнительные количественные переменные** (красные): Столбцы 11 и 12 соответствуют рангу и баллам.\n\n**Дополнительные качественные переменные** (зеленые): данные по соревнованиям (категориальная переменная).\n\nНачнем с разделения наших данных на активные и дополнительные части:\n\n```{r}\ndecathlon2.active <- decathlon2[1:23, 1:10]\nhead(decathlon2.active[, 1:6], 4)\n```\n\n### Стандартизация данных\n\nКогда проводится анализ главных компонент, переменные часто стандартизируются. Эта процедура особенно рекомендуется тогда, когда переменные измеряются в разных единицах (килограммы, сантиметры и пр.).\n\nГлавная цель стандартизации - сделать переменные сопоставимыми. Обычно стандартизация происходит таким образом, чтобы переменная имела 1) стандартное отклонение равным 1, и 2) среднее значение 0.\n\nТипичная формула для стандартизации:\n\n$$\\frac{x_i−mean(x)}{sd(x)}$$\n\nГде $mean(x)$ это среднее значение, а $sd(x)$ стандартное отклонение (SD).\n\nВы уже знакомы с функцией `scale()`, которая может быть использована для стандартизации.\n\nОднако, стандартизация может быть осуществлена сразу в процессе анализа (это действие по умолчанию).\n\nПроведем анализ главных компонент на активных данных по декатлону:\n\n```{r}\nres.pca <- PCA(decathlon2.active, graph = FALSE)\n```\n\nНа выходе функции мы получаем следующие результаты:\n\n```{r}\nprint(res.pca)\n```\n\n### Визуализация и интерпретация\n\nМы будем использовать библиотеку `factoextra`, чтобы разобраться с результатами анализа.\n\nПолезные функции:\n\n-   `get_eigenvalue(res.pca)`: - извлекает собственные значения / дисперсию главных компонент\n-   `fviz_eig(res.pca)`: визуализация собственных значений\n-   `get_pca_ind(res.pca)`, `get_pca_var(res.pca)` - извлекает результаты для наблюдений и переменных\n-   `fviz_pca_ind(res.pca)`, `fviz_pca_var(res.pca)` - визуализирует результаты по наблюдениям и переменным\n-   `fviz_pca_biplot(res.pca)` - создает двойной график (биплот) по индивидам и переменным\n\n### Собственные значения / Дисперсия\n\nСобственные значения показывают, какую долю дисперсии переменных представляет каждая компонента. Собственные значения больше для первых компонент и меньше - для последующих.\n\nСобственные значения могут быть использованы для определения количества главных компонент, которые достойны рассмотрения.\n\nДля получения информации о собственных значениях и дисперсии можно использовать следующий код:\n\n```{r}\neig.val <- get_eigenvalue(res.pca)\neig.val\n```\n\nСумма всех собственных значений равняется 10, то есть общему количеству переменных.\n\nДоля дисперсии, объясняемой каждым собственным значением, представлена во второй колонке.\n\nНапример, если 4.124 разделить на 10 получится 0.4124, или около 41.24% изменчивости, объясненной первой компонентой.\n\nКумулятивный процент представлен в последнем столбце\n\nВидим, что четыре первых компоненты объясняют 80% дисперсии.\n\nСобственные значения могут быть использованы для определения количества компонент. По правилу Кайзера собственное значение \\> 1 обозначает, что эта главная компонента описывает дисперсию хотя бы одной переменной.\n\nМы можем также ограничить число компонент теми, которые описывают какую-то определенную долю дисперсии (например, 70%).\n\nЕдиного правила не существует!\n\nВ нашем анализе первые три компоненты объясняют 72% дисперсии, это достаточно приемлемый результат.\n\nАльтернативный метод заключается в рассмотрении диаграммы рассеяния собственных значений, упорядоченных по убыванию (правило локтя или каменистой осыпи).\n\nОтбирается количество компонент выше точки, фиксирующей спад собственных значений, которые становятся очень близки друг другу (Jollife 2002, Peres-Neto, Jackson, and Somers (2005)).\n\nПопробуем сделать такой график:\n\n```{r}\nfviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))\n```\n\n### Результаты. Работаем с переменными\n\nСамый простой способ извлечь информацию о переменных, это воспользоваться функцией `get_pca_var()`.\n\nЭта функция предоставляет список матриц, содержащих результаты для активных переменных (координаты, корреляцию между переменными и осями, квадрат косинуса и вклады).\n\n```{r}\nvar <- get_pca_var(res.pca)\nvar\n```\n\nРассмотрим эти параметры подробнее\n\n-   var\\$coord: координаты, используемые для создания графика (проекции, нагрузки)\n-   var\\$cos2: квадрат косинуса - качество представленности переменных в факторном пространстве Рассчитывается как квадрат координат: var.cos2 = var.coord \\* var.coord.\n-   var\\$contrib: вклады - показывает вклад переменной в главную компоненту (в процентах): (var.cos2 \\* 100) / (total cos2 of the component). Чем важнее переменная для этой компоненты, тем выше у нее вклад.\n\nМы можем создать графики, основываясь либо на: 1) их качестве (cos2) или 2) на их вкладах в главные компоненты\n\nПредставим результаты:\n\n```{r, eval=FALSE}\n# Координаты\nhead(var$coord)\n# Cos2: качество анализа\nhead(var$cos2)\n# Вклады в компоненты\nhead(var$contrib)\n\n```\n\nРассмотрим, как визуализировать результаты анализа по отдельным наблюдениям и переменным и как сделать выводы о взаимосвязах между ними.\n\n### Корреляционный круг\n\nКорреляция между переменной и главной компонентой используется в качестве координаты переменной на графике.\n\nПредставление переменных зависит от графика наблюдений, наблюдения представлены своими проекциями, тогда как переменные - корреляциями [@abdi2010principal].\n\n```{r}\n# Координаты переменных\nhead(var$coord, 4)\n```\n\nПредставим переменные в виде графика:\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"black\")\n```\n\nТакой график показывает взаимосвязи между всеми переменными. Он может быть интерпретирован следующим образом:\n\n-   переменные с положительной корреляцией сгруппированы вместе;\n-   переменные, имеющие отрицательную корреляцию, находятся на разных сторонах графика (квадрантах);\n-   расстояние между переменными и началом координат показывает качество переменных в факторном пространстве;\n-   переменные, расположенные как можно дальше от начала координат, представлены лучше.\n\n### Качество представленности переменных\n\nКачество представленности переменных в факторном пространстве называется `cos2` (квадрат косинуса, квадрат координаты).\n\nИх можно «добыть» следующим образом:\n\n```{r}\nhead(var$cos2, 4)\n```\n\nМы можем визуализировать этот показатель с помощью очень интересного графика из библиотеки `corrplot` (не забываем устанавливать):\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(var$cos2, is.corr=FALSE)\n```\n\nМожно сделать и столбчатую диаграмму (по первым двум компонентам:\n\n```{r}\nfviz_cos2(res.pca, choice = \"var\", axes = 1:2)\n```\n\nОтметим, что: - высокие значения cos2 обозначают, что переменная хорошо описывается главной компонентой. В этом случае переменная располагается ближе к окружности на графике. - низкие значения cos2 обозначают, что переменные на очень хорошо представлены полученной компонентной структурой. В этом случае переменная - ближе к центру.\n\nСумма всех квадратов косинуса по всем компонентам равна 1 - то есть 100% дисперсии.\n\nСделаем цветной график, так, чтобы: - переменные с низкими значениями cos2 будут окрашены в голубой цвет - переменные со средними значениями cos2 будут иметь оранжевый цвет - переменные с высокими значениями cos2 будут иметь красный цвет\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE # Avoid text overlapping\n             )\n```\n\nМожно представить не с помощью цвета, а с помощью прозрачности:\n\n```{r}\nfviz_pca_var(res.pca, alpha.var = \"cos2\")\n```\n\n### Оценка вклада переменной в компоненту\n\nВклад переменной оценку дисперсии данной главной компоненты представлен в процентном соотношении.\n\nПеременные, которые коррелируют и с первой компонентой PC1 (Dim.1) и со второй компонентой (PC2, Dim.2) являются самыми главными в описании измечивости данных в наборе.\n\nПеременные, которые не коррелируют ни с одной компонентой или коррелируют с последними компонентами не являются важными и могут быть исключены из анализа.\n\nПосмотрим вклад переменных:\n\n```{r}\nhead(var$contrib, 4)\n```\n\nЧем выше вклад, тем больше переменная \"вкладывает\" в компоненту.\n\nВоспользуемся функцией `corrplot`, чтобы это визуализировать:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(var$contrib, is.corr=FALSE)\n```\n\nФункция `fviz_contrib()` может быть использована для того, чтобы построить столбчатую диаграмму по данному показателю:\n\n```{r}\n# Вклад переменных в PC1\nfviz_contrib(res.pca, choice = \"var\", axes = 1, top = 10)\n# Вклад переменных в PC2\nfviz_contrib(res.pca, choice = \"var\", axes = 2, top = 10)\n```\n\nОбщий вклад переменных в обе компоненты:\n\n```{r}\nfviz_contrib(res.pca, choice = \"var\", axes = 1:2, top = 10)\n```\n\nКрасная линия показывает некоторый средний вклад. Если бы вклад всех переменных был бы одинаковый, то каждая вносила бы по 1/10 = 10%. Соответственно, переменная, превышающая данный уровень, может считаться более важной, а менее - незначимой.\n\nСамые важные переменные в нашем анализе - X100m, Long.jump (прыжок в длину) и Pole.vault (прыжок с шестом).\n\nВклад переменных может быть визуализирован следующим образом:\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n             )\n```\n\n### Анализ по группам\n\nМы можем также провести анализ по отдельным группам и использовать данные о группировке в визулизации.\n\nТак как у нас нет группирующей переменной, давайте ее создадим.\n\nМы разобьем переменные на три кластера, используя метод `kmeans`, и затем информацию о кластере включим в график в качестве группирующей переменной.\n\n```{r}\n# Сначала - кластерный анализ, создаем 3 кластера на основе координат\n\nset.seed(123)\nres.km <- kmeans(var$coord, centers = 3, nstart = 25)\ngrp <- as.factor(res.km$cluster)\n\n# Распределяем переменные по кластерам\n\nfviz_pca_var(res.pca, col.var = grp, \n             palette = c(\"#0073C2FF\", \"#EFC000FF\", \"#868686FF\"),\n             legend.title = \"Cluster\")\n```\n\n### Описание отдельных измерений\n\nВ предыдущем разделе мы проанализировали переменные с позиции их вклада в главные компоненты.\n\nВозникает вопросы, что же эти компоненты из себя представляют.\n\nФункция`dimdesc()` может быть использована для анализа отдельных измерений:\n\n```{r}\nres.desc <- dimdesc(res.pca, axes = c(1,2), proba = 0.05)\n# Описание измерения 1\nres.desc$Dim.1\n```\n\nВ результатах выше, \\$quanti означает результаты по количественным переменным, переменные отсортированы по значению p-value.\n\n### Анализ отдельных наблюдений\n\nРезультаты по отдельным наблюдениям могут быть получены с помощью аналогичной функции `get_pca_ind()`. Так же, как и `get_pca_var()`, функция `get_pca_ind()` позволяет получить список матриц с результатами по наблюдениям (координаты, корреляции с осями, квадрат косинуса и вклады)\n\n```{r}\nind <- get_pca_ind(res.pca)\nind\n```\n\nПосмотрим результаты по отдельным показателям\n\n```{r}\n# Координаты наблюдений\nhead(ind$coord)\n# Качество\nhead(ind$cos2)\n# Вклады\nhead(ind$contrib)\n```\n\n### Графики качества и вкладов\n\nФункция `fviz_pca_ind()` помогает получить график по наблюдениям (спортсменам):\n\n```{r}\nfviz_pca_ind(res.pca)\n```\n\nКак и в случае с переменными, мы можем раскрасить наблюдения в зависимости от значений cos2:\n\n```{r}\nfviz_pca_ind(res.pca, col.ind = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE # Avoid text overlapping (slow if many points)\n             )\n```\n\nОтметим, что наблюдения с похожими значениями на графике располагаются близко друг к другу.\n\nСтолбчатый график по наблюдениям:\n\n```{r}\n\nfviz_cos2(res.pca, choice = \"ind\")\n```\n\nВизуализация вклада спортсменов в первые две компоненты:\n\n```{r}\nfviz_contrib(res.pca, choice = \"ind\", axes = 1:2)\n```\n\n### Анализ по группам\n\nЧтобы показать разбивку по группам, давайте воспользуемся известным нам набором по ирисам.\n\nПеременная вида “Species” будет использована в качестве группирующей переменной:\n\n```{r}\niris.pca <- PCA(iris[,-5], graph = FALSE)\n```\n\nСоздаем график:\n\n```{r}\nfviz_pca_ind(iris.pca,\n             geom.ind = \"point\", # показываем только точки, не метки\n             col.ind = iris$Species, # группирующая переменная\n             palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             addEllipses = TRUE, # эллипсы концентрации\n             legend.title = \"Группы\"\n             )\n```\n\n### Создаем биплот\n\nЭто, конечно, самый интересный момент. Чтобы сделать простой биплот по переменным и наблюдениям, можно воспользоваться следующим кодом:\n\n```{r}\nfviz_pca_biplot(res.pca, repel = TRUE,\n                col.var = \"#2E9FDF\", # Цвет переменных\n                col.ind = \"#696969\"  # Цвет наблюдений\n                )\n```\n\nОтметим, что такой график целесообразен, если у нас мало переменных и наблюдений, в противном случае он может быть нечитаемым.\n\nОтметим также, что координаты переменных и наблюдений рассчитываются не в одном пространстве. Иными словами, в биплоте для нас больше важны направления переменных, чем абсолютные значения расстояний на графике.\n\nГрубо говоря, смысл биплота заключается в следующем:\n\n-   наблюдение, которое находится с той же стороны, что и переменная, имеет большие значения именно по данной переменной;\n-   наблюдение, которое находится с другой стороны от переменной, имеет по ней маленькие значения.\n\nСделаем график по ирисам:\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                col.ind = iris$Species, palette = \"jco\", \n                addEllipses = TRUE, label = \"var\",\n                col.var = \"black\", repel = TRUE,\n                legend.title = \"Species\") \n                \n```\n\nВ следующем графике мы хотим раскрасить как наблюдения, так и переменные по группам.\n\nЧтобы разобраться с цветами, мы воспользуемся вспомогательными функциями `fill_palette()` и `color_palette()` \\[ggpubr\\].\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                # Наблюдения по группам\n                geom.ind = \"point\",\n                pointshape = 21,\n                pointsize = 2.5,\n                fill.ind = iris$Species,\n                col.ind = \"black\",\n                # Цвет переменных по группам\n                col.var = factor(c(\"sepal\", \"sepal\", \"petal\", \"petal\")),\n                \n                legend.title = list(fill = \"Species\", color = \"Clusters\"),\n                repel = TRUE        # чтобы не было пересечений\n             )+\n  ggpubr::fill_palette(\"jco\")+      # цвет для наблюдений\n  ggpubr::color_palette(\"npg\")      # цвет для переменных\n```\n\nВ следующем графике наблюдения раскрашены по группам, а переменные - по вкладу в главные компоненты (градиентная заливка).\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                # Individuals\n                geom.ind = \"point\",\n                fill.ind = iris$Species, col.ind = \"black\",\n                pointshape = 21, pointsize = 2,\n                palette = \"jco\",\n                addEllipses = TRUE,\n                # Variables\n                alpha.var =\"contrib\", col.var = \"contrib\",\n                gradient.cols = \"RdYlBu\",\n                \n                legend.title = list(fill = \"Species\", color = \"Contrib\",\n                                    alpha = \"Contrib\")\n                )\n```\n\n### Дополнительные элементы\n\nПомните, мы разделили наш набор на две части - активные и дополнительные переменные?\n\nУ нас есть две количественные дополнительные переменные (`quanti.sup`, колонки 11:12), и одна дополнительная качественная переменная (`quali.sup`, колонка 13) и четыре дополнительных спортсмена (`ind.sup`, строки 24:27).\n\nДополнительные элементы не используются в основном анализе, а их координаты предсказываются исходя из информации, полученной в результате анализа, полученного на активных данных.\n\nКак такой анализ может быть проведен?\n\n```{r}\nres.pca <- PCA(decathlon2, ind.sup = 24:27, \n               quanti.sup = 11:12, quali.sup = 13, graph=FALSE)\n\n```\n\n### Количественные переменные\n\nРезультаты предсказания (координаты, корреляции и квадрат косинуса) для дополнительных переменных:\n\n```{r}\nres.pca$quanti.sup\n```\n\nВизуализация переменных (и активных, и дополнительных)\n\n```{r}\nfviz_pca_var(res.pca)\n```\n\n### Данные по наблюдениям\n\nПредсказанные результаты по наблюдениям:\n\n```{r}\nres.pca$ind.sup\n```\n\nВизуализация наблюдений (активных и дополнительных). Мы можем представить также качественные переменные (`quali.sup`), а их координаты можно извлечь через `res.pca$quali.supp$coord`.\n\n```{r}\np <- fviz_pca_ind(res.pca, col.ind.sup = \"blue\", repel = TRUE)\np <- fviz_add(p, res.pca$quali.sup$coord, color = \"red\")\np\n```\n\n### Данные по качественным переменным\n\nДополнительные качественные переменные могут также быть использованы для группировки. Это может помочь с интерпретацией данных.\n\nРезультаты по качественным переменным:\n\n```{r}\nres.pca$quali\n```\n\nЧтобы использовать эту переменную в качестве группирующей, нужно использовать аргумент `habillage` (по-французски это \"одевание\"), в который вносится индекс этой переменной.\n\n```{r}\nfviz_pca_ind(res.pca, habillage = 13,\n             addEllipses =TRUE, ellipse.type = \"confidence\",\n             palette = \"jco\", repel = TRUE) \n\n\n```\n\n### Фильтр результатов\n\nЕсли у нас много наблюдений или переменных, то можно визуализировать только некоторые из них через аргументы `select.ind` и `select.var`.\n\nМожно сделать сортировку по имени, по косинусу или вкладу.\n\nПримеры:\n\n```{r}\n# Отбор переменных с cos2 >= 0.6\nfviz_pca_var(res.pca, select.var = list(cos2 = 0.6))\n# Top 5 активных переменных с самым высоким cos2\nfviz_pca_var(res.pca, select.var= list(cos2 = 5))\n# Отбор по именам\nname <- list(name = c(\"Long.jump\", \"High.jump\", \"X100m\"))\nfviz_pca_var(res.pca, select.var = name)\n# top 5 самых важных наблюдений и переменных\nfviz_pca_biplot(res.pca, select.ind = list(contrib = 5), \n               select.var = list(contrib = 5),\n               ggtheme = theme_minimal())\n\n```\n\n## Анализ соответствий\n\n**Анализ соответствий**, по-английски - Correspondence analysis (CA), яляется расширением метода главных компонент, предназначенным для исследования взаимосвязей между качественными (категориальными) переменными. Подобно методу главных компонент, он позволяет обобщить информацию и визуализировать данные в виде двумерных графиков.\n\nВ рамках данного занятия мы будем рассматривать пример данных, представленных в виде таблице сопряженности. Координаты, полученные в ходе анализа соответствий будут использоваться для того, чтобы в графическом виде представить ассоциации между строковых и столбцовых элементов.\n\nКогда мы анализируем двумерную таблицу сопряженности, мы обычно стремимся сопоставить отдельные строки каким-либо столбцам. Например, выявляя различия между различыми типами поведения по полу, мы хотели бы выяснить, какие из них являются \"мужскими\", а какие \"женскими\".\n\nАнализ соответствий дает нам такую возможность, поскольку он представляет геометрический подход к визуализации строк и столбцов двумерной таблицы в качестве точек в пространстве меньшей размерности (меньшей - значит, что в нем меньше измерений, чем количество строк или столбцов), так, что расположение точек, соответствующих строкам или столбцам, будет нам показывать их взаимосвязи. Главная цель такого анализа - в наглядном виде представить глобальное видение этих взаимосвязей, удобное для интерпретации.\n\nМы будем анализировать набор данных, который называется `housetasks`, включенный в библиотеку `factoextra`. Не трудно догадаться, в нем содержатся данные о ведении домашнего хозяйства.\n\n```{r}\ndata(housetasks)\nhousetasks\n```\n\nНабор данных представляет собой таблицу частот, где в строках содержится описание 13 различных домашних дел и их распределение в супружеской чете:\n\n-   \"Laundry\" - стирка\n-   \"Main_meal\" - приготовление еды (основное блюдо)\n-   \"Dinner\" - ужин\n-   \"Breakfeast\" - завтрак\n-   \"Tidying\" - уборка дома\n-   \"Dishes\" - мытье посуды\n-   \"Shopping\" - покупки\n-   \"Official\" - работа с документами\n-   \"Driving\" - вождение\n-   \"Finances\" - финансы\n-   \"Insurance\" - страховка\n-   \"Repairs\" - ремонтные работы\n-   \"Holidays\" - подготовка к праздникам\n\nСтроки - разная работа, значения в таблице - частоты, полученные в зависимости от выполнения дел:\n\n-   wife - только женой\n-   alternatively - совместно (по очереди)\n-   husband - только мужем\n-   jointly - совместно (вместе)\n\n![](images/PCA/pic4.png)\n\n### Графическое представление таблицы и тест хи-квадрат\n\nНаша таблица не очень большая, и значит мы легко можем проанализировать профили строк и столбцов.\n\nОчевидно,что стирка, приготовление основного блюда и ужин чаще всего - это женские занятия.\n\nРемонт и вождение автомобили - преимущественно мужские, а вот к праздникам супруги готовятся чаще вместе.\n\nДавайте представим эти результаты графически с помощью библиотеки `gplots`и функции `balloonplot()`:\n\n```{r}\nlibrary(\"gplots\")\n# 1. Переконвертируем данные в таблицу\ndt <- as.table(as.matrix(housetasks))\n# 2. Сделаем красивый график\nballoonplot(t(dt), main =\"housetasks\", xlab =\"\", ylab=\"\",\n            label = FALSE, show.margins = FALSE)\n\n```\n\nЧтобы проверить данные на наличие взаимосвязи или независимости между двумя признаками, можно обратиться к тесту хи-квадрат, который показывает отклонение наблюдаемых частот от ожидаемых (равномерно распределенных):\n\n```{r}\nchisq <- chisq.test(housetasks)\nchisq\n\n```\n\nВ нашем примере мы видим, что переменные, представленные в строках и столбцах статистически значимо взаимосвязаны (p-value = r chisq\\$p.value).\n\n### Как провести анализ соответствий в R\n\nФормула очень напоминает метод главных компонент:\n\n```{r}\nlibrary(\"FactoMineR\")\nres.ca <- CA(housetasks, graph = FALSE)\n```\n\nВывод функции CA() включает следующие результаты:\n\n```{r}\nprint(res.ca)\n```\n\n### Визуализация и интепретация\n\nФункции, которые используются в `factoextra` для извлечения и визуализации данных, очень напоминают те, которые использовались нами в методе главных компонент:\n\n-   get_eigenvalue(res.ca): извлекает собственные значения / долю дисперсии, описываемые по каждому измерению (оси)\n-   fviz_eig(res.ca): визуализация собственных значений\n-   get_ca_row(res.ca), get_ca_col(res.ca): извлечение результатов отдельно по строкам и столбцам\n-   fviz_ca_row(res.ca), fviz_ca_col(res.ca): визуализация результатов отдельно по строкам и столбцам\n-   fviz_ca_biplot(res.ca): биплот\n\n### Собственные значения / дисперсия\n\nВспомним, что мы рассматриваем собственные значения, чтобы определиться с количеством измерений (компонент, осей), которые мы будем рассматривать. Собственные значения и соответствующие им доли дисперсии могут быть извлечены с помощью функции `get_eigenvalue()`. У первой оси собственное значение будет максимальным и оно будет уменьшаться для последующих измерений.\n\n```{r}\neig.val <- get_eigenvalue(res.ca)\neig.val\n```\n\nСобственные значения описывают количество информации, обобщаемой по каждой оси. Измрения упорядочены по убыванию и приводятся в соответствии с долями дисперсии.\n\nТак же, как и в МГК, собственные значения могут быть использованы для определения оптимального количества осей для анализа.\n\nХотя единого \"рецепта\" на этот случай не существует, хороший анализ характеризуется большой долей дисперсии, описываемой через небольшое количество измерений.\n\nВ нашем анализе первые два измерения объясняют 88.6% дисперсии, и это достаточно неплохой результат.\n\nАльтернативный метод - посмотреть на график рассеяния, построенный для упорядоченных собственных значений.\n\n```{r}\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 50))\n\n```\n\nТочка, после которой возникает спад (так называемый “локоть”) означает оптимальную размерность.\n\nМы можем также посчитать среднее собственное значение и оставить те измерения (оси), собственные значения по которым выше:\n\nУ нас 13 строк и 4 столбца, значит, если бы данные были бы случайно распределены по категориям, то ожидаемое собственное значение по каждому измерению равнялось бы: 1/(nrow(housetasks)-1) = 1/12 = 8.33%.\n\nТочно такую же процедуру нужно провести и по столбцам: 1/(ncol(housetasks)-1) = 1/3 = 33.33%\n\nВ соответствии с рекомендациями (M. T. Bendixen 1995):\n\nЛюбая ось, вносящая больше вклада, чем максимальное из этих двух процентов, должна рассматриваться в качестве важной и включаться в интерпретацию результатов анализа.\n\nУ нас максимальное значение - 33,3%\n\n```{r}\nfviz_screeplot(res.ca) +\n geom_hline(yintercept=33.33, linetype=2, color=\"red\")\n```\n\nКак хорошо видно на графике, мы должны оставить два измерения. Отметим, что оставшиеся измерения на самом деле нам мало помогут, поскольку их вклад в объяснение изменчивости данных очень мал.\n\nИзмерения 1 и 2 объясняют около 48.7% и 39.9% общей инерции (аналог дисперсии для анализа соответствий). В совокупности это составляет 88.6%.\n\n### График для строк\n\nАналогичным образом получим и визуализируем результаты для строк.\n\n```{r}\nrow <- get_ca_row(res.ca)\nrow\n```\n\nКомпоненты, содержащиеся в функции `get_ca_row()` могут быть использованы для построения графика:\n\n-   row\\$coord: координаты по каждому измерению (1, 2 and 3). Используются для построения диаграммы рассеяния.\n-   row\\$cos2: качесто представленности строк.\n-   var\\$contrib: вклад строк в процентах в определение измерений\n\n::: {.alert .alert-info role=\"alert\"}\nОтметим, что можно визуализировать данные по строкам либо 1) по качеству их представленности в факторной структуре (cos2) или 2) по их вкладу в определение направлений.\n:::\n\nКак это сделать?\n\n```{r}\n# Координаты\nhead(row$coord)\n# Cos2\nhead(row$cos2)\n# Вклады в измерения\nhead(row$contrib)\n```\n\n### Координаты строк\n\nВизуализируем только строки:\n\n```{r}\nfviz_ca_row(res.ca, repel = TRUE)\n```\n\n### Качество репрезентации строк\n\nРезультаты показывают, что таблица сопряженности была успешно представлена в пространстве меньшей размерности с помощью анализа соответствий, и мы смогли успешно описать 88.6% дисперции (инерции) данных.\n\nТем не менее, не все точки одинаково хорошо расположились вдоль двух осей (измерений).\n\nВспомним, что качество представленности переменной (строки) измеряется через показатель (cos2 - квадрат косинуса), что аналогично квадрату корреляции (или квадрату координаты по направлению).\n\nПоказатель cos2 измеряет степень ассоциации между строками / столбцами и конкретной осью.\n\nКак этот показатель извлечь?\n\n```{r}\nhead(row$cos2, 4)\n\n```\n\nЗначения cos2 изменяются в диапазоне между 0 и 1. Сумма всех cos2 для всех по всем измерениям равна 1. Чем больше сумма квадратов косинусов для отдельной строки по всем измерениям, тем лучше информация, которую она представляет, описывается полученной моделью.\n\nДавайте эту информацию представим графически:\n\n```{r}\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n```\n\n### Альтернативный способ представления значений cos2\n\nМы можем визуализировать качество представленности строк с помощью библиотеки `corrplot`:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(row$cos2, is.corr=FALSE)\n```\n\nЕще один вариант - столбчатая диаграмма:\n\n```{r}\nfviz_cos2(res.ca, choice = \"row\", axes = 1:2)\n```\n\n### Вклад строк в измерения\n\nВклад строк (в %) в определение измерений может быть извлечена путем:\n\n```{r}\nhead(row$contrib)\n```\n\nСоответственно, строки с большими значениями вносят больший вклад в определение измерений и являются более важными.\n\nМожем сделать аналогичный корплот:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(row$contrib, is.corr=FALSE)    \n```\n\nФункция `fviz_contrib()` полезна для анализа вклада по отдельным измерениям:\n\n```{r}\n# Вклад строк в измерение 1\nfviz_contrib(res.ca, choice = \"row\", axes = 1, top = 10)\n# Вклад строк в измерение 2\nfviz_contrib(res.ca, choice = \"row\", axes = 2, top = 10)\n\n```\n\nОбщий вклад в два измерения\n\n```{r}\nfviz_contrib(res.ca, choice = \"row\", axes = 1:2, top = 10)\n```\n\nОтметим, что такие дела, как ремонт, стирка, приготовление еды и вождение являются самыми важными по первому измерению.\n\nТогда как выходные и ремонт - для второго измерения.\n\nВизуализируем это:\n\n```{r}\nfviz_ca_row(res.ca, col.row = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n```\n\nДанный график может нам дать некоторые идеи по поводу содержания осей. Очевидно, что первая ось - собственно делит наши занятия на мужские и женские - по критерию физического труда (интеллектуальной активности) - рутинного труда. Второе измерение скорее охватывает аспекты совместной деятельности или одиночной (водить машину вдвоем довольно затруднительно.\n\n### Представление переменных по столбцам\n\nЧтобы извлечь результаты по вариантам ответа, представленным в столбцах, понадобится функция `get_ca_col()`:\n\n```{r}\ncol <- get_ca_col(res.ca)\ncol\n```\n\nЧтобы обратиться к отдельным компонентам вывода, нужно набрать:\n\n```{r}\n# Координаты\nhead(col$coord)\n# Качество репрезентации\nhead(col$cos2)\n# Вклады\nhead(col$contrib)\n```\n\n### Графики качества и вклада\n\nВоспользуемся аналогичными функциями визуализации, чтобы провести анализ качества и вклада по столбцам:\n\n```{r}\nfviz_ca_col(res.ca, col.col = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE)\n\n```\n\n```{r}\nfviz_cos2(res.ca, choice = \"col\", axes = 1:2)\n```\n\nСудя по нашим результатам, вариант ответа \"по очереди\" (Alternating) представлен первыми двумя измерениями не самым наилучшим образом.\n\nЧтобы визуализировать вклад столбцов в первые два фактора, можно использовать следующий код:\n\n```{r}\nfviz_contrib(res.ca, choice = \"col\", axes = 1:2)\n```\n\nРезультаты - аналогичные. График еще раз подтвердил, что наибольший вклад вносят три варианта ответа - \"муж\", \"жена\" и \"совместные действия\".\n\n### Делаем биплот\n\nАналогично тому, как мы делали биплот в ходе анализа методом главных компонент, можно визуализировать результаты анализа соответствий.\n\nСтандартным является симметричный биплот, в котором строки (синие точки) и столбцы (красные треугольники) представлены в одном пространстве на основе главных координат, показывающих их профили. В этом случае, только расстояние между точками одной группы может быть реально проинтерпретировано, тогда как расстояния между строками и столбцами интерпретировать напрямую некорректно, можно делать только самые общие выводы и обобщения.\n\n```{r}\nfviz_ca_biplot(res.ca, repel = TRUE)\n```\n\n### Биплот, учитывающий вклад переменных\n\nВ стандартном симметричном биплоте, который мы только что сделали, довольно трудно понять, какие точки (переменные) вносят больший вклад в полученную модель.\n\nМайкл Гринэкр (Michael Greenacre) предложил новый тип шкалирования (масштабирования), получивший название \"биплот вкладов\" (contribution biplot), который позволяет визуализировать эти моменты (M. Greenacre 2013). При таком отображении, точки, которые вносят маленький вклад и являющиеся не очень важными, располагаются ближе к центру координат.\n\nТакой график можно получить, задав аргумент `map = “rowgreen”` или `map = “colgreen”`.\n\n```{r}\nfviz_ca_biplot(res.ca, map =\"colgreen\", arrow = c(TRUE, FALSE),\n               repel = TRUE)\n```\n\nВ принципе, графики - аналогичны предыдущему, в них лишь ставится больший акцент на значимости переменных.\n\n### Описание измерений\n\nЧтобы понять, какие строки или столбцы в большей степени связаны с главными измерениями, можно подробно исследовать информацию по каждому из них, что удобно сделать с помощью функции `dimdesc()`(FactoMineR). Строки и столбцы в выводе отсортировываются по их координатам.\n\n```{r}\nres.desc <- dimdesc(res.ca, axes = c(1,2))\n```\n\n### Пример анализа по климатическому исследованию\n\nПроведем анализ соответствий на основе данных таблицы сопряженности между регионом исследования и вопросом V14, описывающем наиболее частые природные явления, происходящие в зимнее время.\n\nПодключим необходимые пакеты для загрузки и обработки данных, загрузим наши данные:\n\n```{r message=FALSE, warning=FALSE}\nlibrary(haven)\nlibrary(dplyr)\nlibrary(questionr)\ndf<-read_sav(\"База_КлимРиск_2023.sav\")\n```\n\nПоскольку вопрос V14 является вопросом с множественным выбором, создадим набор:\n\n```{r}\nV14<-df %>% \n  select(contains(\"V14\"))\n```\n\nПо набору и переменной региона сделаем таблицу сопряженности, укажем `freq=FALSE`, чтобы у нас получилась таблица с абсолютными значениями, а не с процентами (хотя результаты были бы очень похожими):\n\n```{r}\ntable_V14_region<-cross.multi.table(V14, df$Region, true.codes=list(\"да\"), freq=FALSE)\n```\n\nУдалим лишний столбец (по Монголии) и строки, в которых содержатся переменные с вариантами ответа «Другое»:\n\n```{r}\ntable_V14_region<-table_V14_region[1:10, 1:3]\n```\n\nСоздадим подписи, обозначив имена столбцов (регионы) и строк (природные явления):\n\n```{r}\ncolnames(table_V14_region)<-c(\"АК\", \"РА\", \"РТ\")\nrownames(table_V14_region)<-c(\"Перепад.темп\", \"Аном.холод\", \"Оттеп.\", \"Гололед\", \"Снегопад\", \"Лавины\", \"Пасм.дни\", \"Реч.лед\", \"Зажоры\", \"Ветра, метели\")\n```\n\nПроведем корреспондентский анализ:\n\n```{r}\nres.ca <- CA(table_V14_region, graph = FALSE)\n```\n\nПосмотрим, сколько измерений у нас получилось:\n\n```{r}\nget_eigenvalue(res.ca)\n```\n\nВидим, что наши данные описываются всего двумя измерениями, первое из которых описывает 88,8% дисперсии, второе - 11,2%.\n\n```{r}\nrow <- get_ca_row(res.ca)\nrow\n```\n\nПосмотрим показатель квадрата косинуса:\n\n```{r}\nrow$cos2\n```\n\nПочти все строки максимально хорошо описываются первым измерением, кроме гололедных явлений, по второму измерению максимальные оценки, напротив у голодеда и процессов, связанных с образованием речного льда.\n\nПосмотрим вклады:\n\n```{r}\nrow$contrib\n```\n\nВ первое измерение наибольший вклад вносили перепады температуры, оппепели и аномальные холода, тогда как для второго измерения важными были переменные, связанные с гололедом, аномальными холодами и сдвигами в периодах образования речного льда.\n\nСделаем биплот:\n\n```{r}\nfviz_ca_biplot(res.ca, repel = TRUE)\n```\n\n## Самостоятельная работа\n\n1.  Проанализировать данные психосемантического исследования по религии.\n\n{{< iconify arcticons 1dm size=42px >}}[Скачать данные](https://github.com/domelia/rcourse/blob/main/religions.sav)\n\n2.  Сделать анализ главных компонент. Вывести результаты по собственным значениям и дисперсии (вместе с графиками), по координатам (корреляциям) и вкладам - по дескрипторам и ролям\n3.  Сделать визуализацию - отдельно по дескрипторам, по ролям и биплот.\n4.  Сделать анализ соответствий в базе данных по климату по переменной V16 (вопрос с множественным выбором по природным явлениям, происходящим в летний период).\n\n## Источники\n\n::: {#refs}\n:::\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Общие цели занятия и возможности библиотеки`factoextra`\n\n**Многомерный анализ данных** представляет собой сложную, но очень интересную задачу, которая часто встречается в деятельности аналитика данных. Задачи анализа взаимосвязей между переменными, их структурирование в виде кластеров, факторов, компонент и представление в визуально интерпретируемом виде часто встречаются, как в фундаментальных, так и прикладных исследованиях.\n\nМногомерный анализ основан на принципе многомерной статистики, который предполагает наблюдение и анализ более чем одной переменной за один раз. Обычно многомерный анализ используется для решения ситуаций, когда в ходе научного эксперимента выполняются несколько измерений, и взаимосвязь между этими измерениями и их структурами имеет важное значение.\n\nМногомерный анализ охватывает большой репертуар методов, включая факторный анализ, кластерный анализ, регрессионный анализ, метод главных компонент и другие, поэтому эта обширная тема, в которой мы изучим только некоторые направления анализа.\n\nМногомерный анализ включает в себя:\n\n-   модели, основанные на многомерном нормальном распределении и генерализованные модели\n-   измерение и анализ взаимосвязей между отдельными переменными\n-   расчеты вероятностей на многомерных данных\n-   изучение структур и паттернов в данных\n\nДля подобных целей на языке R разработано множество библиотек, но определенными преимуществами обладает одна из них - `factoextra`. Ее цель заключается в извлечении результатов и визуализации **эксплораторного** многомерного анализа данных, включая:\n\n**Метод главных компонент - Principal Component Analysis (PCA)** - анализирующий количественные (непрерывные) переменные путем сокращения размерности данных без потери важной информации (например, представление множества шкал психологических тестов в виде нескольких компонент или представление множества показателей социально-экономического развития регионов в виде нескольких интегральных показателей).\n\n**Корреспондентский анализ (анализ соответствий) - Correspondence Analysis (CA)**, выступающий расширением метода главных компонент для анализа больших таблиц сопряженности, образуемых на основе двух качественных переменных (категориальных данных)(например, продукты и их характеристики, метод хорошо подходит для вопросов с множественным выбором).\n\n**Множественный корреспондентский анализ, множественный анализ соответствий - Multiple Correspondence Analysis (MCA)**, являющийся адаптацией метода CA к таблице данных, содержащих более двух категориальных переменных (например, взаимосвязь между занятостью, национальностью и полом).\n\n**Множественный факторный анализ - Multiple Factor Analysis (MFA)** - предназначен для работы с данными, где переменные организованы в группы, блоки или наборы (качественных и / или количественных) переменныех. MFA позволяет обнаружить общие структуры, присутствующие во всех или некоторых наборах данных. Выполняется в два этапа. На первом этапе на каждом наборе данных проводится анализ главных компонент, а затем исходные данные в каждом наборе «нормализуются» путем деления каждого элемента на квадратный корень из собственного значения, полученного из МГК на данном наборе. Затем, нормализованные данные объединяются в единую матрицу, над которой проводится общий анализ главных компонент, а индивидуальные наборы данных проектируются на результаты этого анализа, чтобы найти общие зависимости и расхождения [@abdi2007multiple]\n\n**Иерархический множественный факторный анализ - Hierarchical Multiple Factor Analysis (HMFA)**: расширение метода MFA, подходящий для ситуации, где данные организованы в иерархические структуры.\n\n**Факторный анализ смешанных данных - Factor Analysis of Mixed Data (FAMD)** - особый случай MFA, предназначенный для анализа данных, содержащих как количественные, так и качественные переменные.\n\n::: {.alert .alert-info role=\"alert\"}\n**Важно!** Сам анализ проводится с помощью других библиотек, библиотека factoextra используется для извлечения результатов и визуализации.\n:::\n\nСуществует большое количество пакетов, в которых можно сделать анализ главных компонент, например, `FactoMineR`, `ade4`, `stats`, `ca`, `MASS` и `ExPosition`.\n\nРезультаты будут представлены по-разному, в зависимости от того, какие функции будут использованы. Помочь в интерпретации и визуализации полученных результатов многомерного анализа, например, кластерного анализа или результатов снижения размерности, нам как раз и поможет библиотека `factoextra`.\n\nВ рамках данного занятия мы будем использовать библиотеку `FactoMineR` [@le2008factominer] для расчетов, а библиотеку `factoextra` для извлечения и анализа результатов.\n\nС какими методами может работать библиотека `factoextra`:\n\n![](https://cran.r-project.org/web/packages/factoextra/readme/tools/factoextra-r-package.png)\n\n### Как сделать правильный выбор?\n\nВыбор метода для анализа будет зависеть от формата данных и их структуры:\n\nТак, например, если у нас количественные данные, то нам подойдет метод главных компонент, а если качественные, то в зависимости от их количества - анализ соответствий - простой или множественный.\n\nВ случае, если данные разной природы, то нам лучше обратиться к смешанным методам - иерархическому множественному факторному анализу или факторному анализу для смешанных данных. . ![](https://cran.r-project.org/web/packages/factoextra/readme/tools/multivariate-analysis-factoextra.png)\n\n### Установка и загрузка библиотек\n\nУстанавливаем библиотеки:\n\n```{r, eval=FALSE, message=FALSE, warning=FALSE}\ninstall.packages(\"factoextra\")\ninstall.packages(\"FactoMineR\")\n```\n\nЗагружаем:\n\n```{r}\nlibrary(\"factoextra\")\nlibrary(\"FactoMineR\")\n```\n\n## Метод главных компонент (Principal component analysis)\n\nМетод главных компонент (PCA) позволяет суммировать и визуализировать информацию, представленную в наборе данных, где некоторые индивиды / наблюдения описываются через большое количество взаимосвязанных друг с другом количественных переменных. Каждая переменная может быть представлена в качестве отдельного измерения. Если переменных больше трех, то визуализация результатов становится затруднительным.\n\nМетод главных компонент извлекает информацию из многомерной таблицы данных $n \\times k$ и представляет ее в виде новых переменных, чье количество меньше количества исходных переменных.\n\nЭто новые переменные и называются **главные компоненты**, они являются линейной комбинацией исходных переменных. Количество главных компонент всегда меньше или равно количеству исходных переменных.\n\nИнформация набора данных соответствует дисперсии переменных, которые в него входят.\n\nЦель МГК заключается в идентификации главных компонент, описывающих максимум дисперсии переменных. Снижение размерности заключается в определении ведущих направлений (векторов), или главных компонент, показывающих изменение данных.\n\nМетод МГК предполагает, что эти главные направления описывают большую часть дисперсии, поэтому являются более важными.\n\n::: {#fig-proj}\n![](https://i.sstatic.net/Q7HIP.gif) Геометрический смысл нахождения главной компоненты.\n:::\n\nДругими словами, МГК сокращает размерность данных, путем выделения двух или трех самых важных компонент, которые мы может визуализировать графически и минимальной потерей информации.\n\nТаким образом, главными задачами метода главных компонент являются:\n\n-   выявление скрытой структуры в наборе данных,\n-   снизить размерность данных, путем удаления статистического шума и избыточных переменных\n-   идентифицировать взаимосвязанные переменные\n\nНа практике этот метод реализуется двумя возможными подходами:\n\n-   путем разложения исходной матрицы взаимосвязей (ковариаций или корреляций) на произведение матриц собственных значений и собственных векторов\n-   путем сингулярного разложения данной матрицы.\n\n### Собственные значения и собственные вектора\n\nДопустим наши данные представлены в матрице $\\mathbf X$ размера $n \\times p$, где $n$ – количество наблюдений, а $p$ – количество признаков. Наши данные должны быть центрированы, то есть в каждом столбце из каждого элемента должно быть вычтено среднее значение, так чтобы среднее значение по каждому признаку равнялось нулю.\n\nТогда $p \\times p$ матрица ковариаций $\\mathbf C$ может быть представлена как:\n\n$$\\mathbf C = \\mathbf X^\\top \\mathbf X/(n-1)$$\n\nПоскольку эта матрица симметричная, она может быть диагонализирована, то есть представлена в виде произведения трех матриц, в результате чего находится соответствующая диагональной матрицы собственных значений:\n\n$$\\mathbf C = \\mathbf V \\mathbf L \\mathbf V^\\top,$$\n\nгде $\\mathbf V$ - это матрица собственных векторов,а $\\mathbf L$ - это диагональная матрица, на диагонали которой находятся собственные значения $λ_i$, упорядоченные по убыванию:\n\n$$\\mathbf L = \\begin{bmatrix}\n\\lambda_1 &  & & \\\\ \n & \\lambda_2 & & \\\\ \n & & \\lambda_{...} & \\\\\n & & & \\lambda_p  \\\\\n\\end{bmatrix}$$\n\nСобственные вектора называются **главными осями** или **главными направлениями**.\n\nПроекции данных на главные оси собственно и называются **главными компонентами**, представляющими собой новые, трансформированные переменные.\n\nГлавная компонента $j$ находится в $j$ столбце матрицы $\\mathbf {XV}$.\n\nКоординаты $i-ой$ точки данных в новом пространстве главных компонент заданы $i-й$ строкой $\\mathbf XV$.\n\nДля нахождения собственных значений решается характеристическое уравнение:\n\n$$|\\mathbf C-\\mathbf \\Lambda \\mathbf I|\\vec{x}=0,$$\n\nпредполагающее вычисление детерминанта $|\\mathbf C-\\mathbf \\Lambda \\mathbf I|$ и корней уравнения степени $n$, в результате которого находятся $\\lambda_1, \\lambda_2, ... \\lambda_p$.\n\nДалее, путем подстановки собственных значений в исходное уравнение, для каждого $\\lambda$ находится собственный вектор.\n\nФундаментальным для метода главных компонент является уравнение:\n\n$$\\mathbf C=\\mathbf A \\mathbf {A}',$$\n\nгде $\\mathbf A$ – матрица нагрузок, а $\\mathbf {A}'$ - транспонированная ей матрица.\n\nНагрузки получаются путем умножения собственных векторов на квадрат из собственных значений:\n\n$$\\mathbf A= \\mathbf V \\sqrt{\\mathbf \\Lambda}$$\n\nТаким образом, главную компоненту можно представить как линейную комбинацию исходных данных и компонентных нагрузок.\n\nПример с первой компонентой:\n\n$$PC_k = a_{k1}X_1 + a_{k2}X_2 + … + a_{kp}X_p,$$\n\nгде a$_ij$ является нагрузкой переменной $x_j$ по компоненте $PC_i$, $x_j$ – $j-ая$ переменная матрицы признаков $\\mathbf X$.\n\n### Сингулярное разложение\n\nКогда мы осуществляем сингулярное разложение матрицы взаимосвязей, у нас получается несколько иная картина:\n\n$$\\mathbf X = \\mathbf U \\mathbf S \\mathbf V^\\top,$$\n\nгде $\\mathbf U$ - являются унитарной матрицей (столбцы которой называются левыми сингулярными векторами), $\\mathbf S$ - диагональная матрица сингулярных значений $s_i$, а столбцы матрицы $\\mathbf V$ называются правыми сингулярными векторами.\n\nПравые сингулярные вектора – это и есть собственные вектора $A^\\top A$, то есть между методами есть тесная взаимосвязь, и $\\lambda_i = s_i^2/(n-1)$.\n\n> {{< iconify arcticons anz size=42px >}} **Пример**: Рассмотрим пример с данными соревнований по десятиборью, в которые входят следующие дисциплины:\n\n-   \"X100m\" - бег на 100 метров\n-   \"Long.jump\" - прыжки в длину\n-   \"Shot.put\" - толкание ядра\n-   \"High.jump\" - прыжки в высоту\n-   \"X400m\" - бег на 400 метров\n-   \"X110m.hurdle\" - бег с препятсвиями\n-   \"Discus\" - метание диска\n-   \"Pole.vault\" - прыжок с шестом\n-   \"Javeline\" - метание копья\n-   \"X1500m\" - без на 1500 метров\n\n![](https://sportsmatik.com/uploads/matik-sports-corner/matik-know-how/decathlon_1499492047_83444.jpg)\n\n```{r}\ndata(decathlon2)\nhead(decathlon2)\n```\n\n![](images/PCA/pic3.png)\n\nИтак, наши данные описывают выполнение атлетами испытаний в двух типах спортивных соревнований (Desctar и OlympicG). Набор содержит информацию о 27 спортсменах и 13 переменных.\n\n**Активные спортсмены** (голубой цвел, строки 1:23) : Данные, которые будут использованы для проведения анализа методом главных компонент. **Дополнительные спортсмены** (синий цвет, строки 24:27) : Координаты по этим спортсменам будут использованы для предсказания параметров с помощью МГК по информации полученной по активным спортсменам / переменным **Активные переменные** (розовый цвет, столбцы 1:10) : переменные, используемые в МГК **Дополнительные переменные**: используются для предсказания, включая:\n\n**Дополнительные количественные переменные** (красные): Столбцы 11 и 12 соответствуют рангу и баллам.\n\n**Дополнительные качественные переменные** (зеленые): данные по соревнованиям (категориальная переменная).\n\nНачнем с разделения наших данных на активные и дополнительные части:\n\n```{r}\ndecathlon2.active <- decathlon2[1:23, 1:10]\nhead(decathlon2.active[, 1:6], 4)\n```\n\n### Стандартизация данных\n\nКогда проводится анализ главных компонент, переменные часто стандартизируются. Эта процедура особенно рекомендуется тогда, когда переменные измеряются в разных единицах (килограммы, сантиметры и пр.).\n\nГлавная цель стандартизации - сделать переменные сопоставимыми. Обычно стандартизация происходит таким образом, чтобы переменная имела 1) стандартное отклонение равным 1, и 2) среднее значение 0.\n\nТипичная формула для стандартизации:\n\n$$\\frac{x_i−mean(x)}{sd(x)}$$\n\nГде $mean(x)$ это среднее значение, а $sd(x)$ стандартное отклонение (SD).\n\nВы уже знакомы с функцией `scale()`, которая может быть использована для стандартизации.\n\nОднако, стандартизация может быть осуществлена сразу в процессе анализа (это действие по умолчанию).\n\nПроведем анализ главных компонент на активных данных по декатлону:\n\n```{r}\nres.pca <- PCA(decathlon2.active, graph = FALSE)\n```\n\nНа выходе функции мы получаем следующие результаты:\n\n```{r}\nprint(res.pca)\n```\n\n### Визуализация и интерпретация\n\nМы будем использовать библиотеку `factoextra`, чтобы разобраться с результатами анализа.\n\nПолезные функции:\n\n-   `get_eigenvalue(res.pca)`: - извлекает собственные значения / дисперсию главных компонент\n-   `fviz_eig(res.pca)`: визуализация собственных значений\n-   `get_pca_ind(res.pca)`, `get_pca_var(res.pca)` - извлекает результаты для наблюдений и переменных\n-   `fviz_pca_ind(res.pca)`, `fviz_pca_var(res.pca)` - визуализирует результаты по наблюдениям и переменным\n-   `fviz_pca_biplot(res.pca)` - создает двойной график (биплот) по индивидам и переменным\n\n### Собственные значения / Дисперсия\n\nСобственные значения показывают, какую долю дисперсии переменных представляет каждая компонента. Собственные значения больше для первых компонент и меньше - для последующих.\n\nСобственные значения могут быть использованы для определения количества главных компонент, которые достойны рассмотрения.\n\nДля получения информации о собственных значениях и дисперсии можно использовать следующий код:\n\n```{r}\neig.val <- get_eigenvalue(res.pca)\neig.val\n```\n\nСумма всех собственных значений равняется 10, то есть общему количеству переменных.\n\nДоля дисперсии, объясняемой каждым собственным значением, представлена во второй колонке.\n\nНапример, если 4.124 разделить на 10 получится 0.4124, или около 41.24% изменчивости, объясненной первой компонентой.\n\nКумулятивный процент представлен в последнем столбце\n\nВидим, что четыре первых компоненты объясняют 80% дисперсии.\n\nСобственные значения могут быть использованы для определения количества компонент. По правилу Кайзера собственное значение \\> 1 обозначает, что эта главная компонента описывает дисперсию хотя бы одной переменной.\n\nМы можем также ограничить число компонент теми, которые описывают какую-то определенную долю дисперсии (например, 70%).\n\nЕдиного правила не существует!\n\nВ нашем анализе первые три компоненты объясняют 72% дисперсии, это достаточно приемлемый результат.\n\nАльтернативный метод заключается в рассмотрении диаграммы рассеяния собственных значений, упорядоченных по убыванию (правило локтя или каменистой осыпи).\n\nОтбирается количество компонент выше точки, фиксирующей спад собственных значений, которые становятся очень близки друг другу (Jollife 2002, Peres-Neto, Jackson, and Somers (2005)).\n\nПопробуем сделать такой график:\n\n```{r}\nfviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))\n```\n\n### Результаты. Работаем с переменными\n\nСамый простой способ извлечь информацию о переменных, это воспользоваться функцией `get_pca_var()`.\n\nЭта функция предоставляет список матриц, содержащих результаты для активных переменных (координаты, корреляцию между переменными и осями, квадрат косинуса и вклады).\n\n```{r}\nvar <- get_pca_var(res.pca)\nvar\n```\n\nРассмотрим эти параметры подробнее\n\n-   var\\$coord: координаты, используемые для создания графика (проекции, нагрузки)\n-   var\\$cos2: квадрат косинуса - качество представленности переменных в факторном пространстве Рассчитывается как квадрат координат: var.cos2 = var.coord \\* var.coord.\n-   var\\$contrib: вклады - показывает вклад переменной в главную компоненту (в процентах): (var.cos2 \\* 100) / (total cos2 of the component). Чем важнее переменная для этой компоненты, тем выше у нее вклад.\n\nМы можем создать графики, основываясь либо на: 1) их качестве (cos2) или 2) на их вкладах в главные компоненты\n\nПредставим результаты:\n\n```{r, eval=FALSE}\n# Координаты\nhead(var$coord)\n# Cos2: качество анализа\nhead(var$cos2)\n# Вклады в компоненты\nhead(var$contrib)\n\n```\n\nРассмотрим, как визуализировать результаты анализа по отдельным наблюдениям и переменным и как сделать выводы о взаимосвязах между ними.\n\n### Корреляционный круг\n\nКорреляция между переменной и главной компонентой используется в качестве координаты переменной на графике.\n\nПредставление переменных зависит от графика наблюдений, наблюдения представлены своими проекциями, тогда как переменные - корреляциями [@abdi2010principal].\n\n```{r}\n# Координаты переменных\nhead(var$coord, 4)\n```\n\nПредставим переменные в виде графика:\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"black\")\n```\n\nТакой график показывает взаимосвязи между всеми переменными. Он может быть интерпретирован следующим образом:\n\n-   переменные с положительной корреляцией сгруппированы вместе;\n-   переменные, имеющие отрицательную корреляцию, находятся на разных сторонах графика (квадрантах);\n-   расстояние между переменными и началом координат показывает качество переменных в факторном пространстве;\n-   переменные, расположенные как можно дальше от начала координат, представлены лучше.\n\n### Качество представленности переменных\n\nКачество представленности переменных в факторном пространстве называется `cos2` (квадрат косинуса, квадрат координаты).\n\nИх можно «добыть» следующим образом:\n\n```{r}\nhead(var$cos2, 4)\n```\n\nМы можем визуализировать этот показатель с помощью очень интересного графика из библиотеки `corrplot` (не забываем устанавливать):\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(var$cos2, is.corr=FALSE)\n```\n\nМожно сделать и столбчатую диаграмму (по первым двум компонентам:\n\n```{r}\nfviz_cos2(res.pca, choice = \"var\", axes = 1:2)\n```\n\nОтметим, что: - высокие значения cos2 обозначают, что переменная хорошо описывается главной компонентой. В этом случае переменная располагается ближе к окружности на графике. - низкие значения cos2 обозначают, что переменные на очень хорошо представлены полученной компонентной структурой. В этом случае переменная - ближе к центру.\n\nСумма всех квадратов косинуса по всем компонентам равна 1 - то есть 100% дисперсии.\n\nСделаем цветной график, так, чтобы: - переменные с низкими значениями cos2 будут окрашены в голубой цвет - переменные со средними значениями cos2 будут иметь оранжевый цвет - переменные с высокими значениями cos2 будут иметь красный цвет\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE # Avoid text overlapping\n             )\n```\n\nМожно представить не с помощью цвета, а с помощью прозрачности:\n\n```{r}\nfviz_pca_var(res.pca, alpha.var = \"cos2\")\n```\n\n### Оценка вклада переменной в компоненту\n\nВклад переменной оценку дисперсии данной главной компоненты представлен в процентном соотношении.\n\nПеременные, которые коррелируют и с первой компонентой PC1 (Dim.1) и со второй компонентой (PC2, Dim.2) являются самыми главными в описании измечивости данных в наборе.\n\nПеременные, которые не коррелируют ни с одной компонентой или коррелируют с последними компонентами не являются важными и могут быть исключены из анализа.\n\nПосмотрим вклад переменных:\n\n```{r}\nhead(var$contrib, 4)\n```\n\nЧем выше вклад, тем больше переменная \"вкладывает\" в компоненту.\n\nВоспользуемся функцией `corrplot`, чтобы это визуализировать:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(var$contrib, is.corr=FALSE)\n```\n\nФункция `fviz_contrib()` может быть использована для того, чтобы построить столбчатую диаграмму по данному показателю:\n\n```{r}\n# Вклад переменных в PC1\nfviz_contrib(res.pca, choice = \"var\", axes = 1, top = 10)\n# Вклад переменных в PC2\nfviz_contrib(res.pca, choice = \"var\", axes = 2, top = 10)\n```\n\nОбщий вклад переменных в обе компоненты:\n\n```{r}\nfviz_contrib(res.pca, choice = \"var\", axes = 1:2, top = 10)\n```\n\nКрасная линия показывает некоторый средний вклад. Если бы вклад всех переменных был бы одинаковый, то каждая вносила бы по 1/10 = 10%. Соответственно, переменная, превышающая данный уровень, может считаться более важной, а менее - незначимой.\n\nСамые важные переменные в нашем анализе - X100m, Long.jump (прыжок в длину) и Pole.vault (прыжок с шестом).\n\nВклад переменных может быть визуализирован следующим образом:\n\n```{r}\nfviz_pca_var(res.pca, col.var = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\")\n             )\n```\n\n### Анализ по группам\n\nМы можем также провести анализ по отдельным группам и использовать данные о группировке в визулизации.\n\nТак как у нас нет группирующей переменной, давайте ее создадим.\n\nМы разобьем переменные на три кластера, используя метод `kmeans`, и затем информацию о кластере включим в график в качестве группирующей переменной.\n\n```{r}\n# Сначала - кластерный анализ, создаем 3 кластера на основе координат\n\nset.seed(123)\nres.km <- kmeans(var$coord, centers = 3, nstart = 25)\ngrp <- as.factor(res.km$cluster)\n\n# Распределяем переменные по кластерам\n\nfviz_pca_var(res.pca, col.var = grp, \n             palette = c(\"#0073C2FF\", \"#EFC000FF\", \"#868686FF\"),\n             legend.title = \"Cluster\")\n```\n\n### Описание отдельных измерений\n\nВ предыдущем разделе мы проанализировали переменные с позиции их вклада в главные компоненты.\n\nВозникает вопросы, что же эти компоненты из себя представляют.\n\nФункция`dimdesc()` может быть использована для анализа отдельных измерений:\n\n```{r}\nres.desc <- dimdesc(res.pca, axes = c(1,2), proba = 0.05)\n# Описание измерения 1\nres.desc$Dim.1\n```\n\nВ результатах выше, \\$quanti означает результаты по количественным переменным, переменные отсортированы по значению p-value.\n\n### Анализ отдельных наблюдений\n\nРезультаты по отдельным наблюдениям могут быть получены с помощью аналогичной функции `get_pca_ind()`. Так же, как и `get_pca_var()`, функция `get_pca_ind()` позволяет получить список матриц с результатами по наблюдениям (координаты, корреляции с осями, квадрат косинуса и вклады)\n\n```{r}\nind <- get_pca_ind(res.pca)\nind\n```\n\nПосмотрим результаты по отдельным показателям\n\n```{r}\n# Координаты наблюдений\nhead(ind$coord)\n# Качество\nhead(ind$cos2)\n# Вклады\nhead(ind$contrib)\n```\n\n### Графики качества и вкладов\n\nФункция `fviz_pca_ind()` помогает получить график по наблюдениям (спортсменам):\n\n```{r}\nfviz_pca_ind(res.pca)\n```\n\nКак и в случае с переменными, мы можем раскрасить наблюдения в зависимости от значений cos2:\n\n```{r}\nfviz_pca_ind(res.pca, col.ind = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE # Avoid text overlapping (slow if many points)\n             )\n```\n\nОтметим, что наблюдения с похожими значениями на графике располагаются близко друг к другу.\n\nСтолбчатый график по наблюдениям:\n\n```{r}\n\nfviz_cos2(res.pca, choice = \"ind\")\n```\n\nВизуализация вклада спортсменов в первые две компоненты:\n\n```{r}\nfviz_contrib(res.pca, choice = \"ind\", axes = 1:2)\n```\n\n### Анализ по группам\n\nЧтобы показать разбивку по группам, давайте воспользуемся известным нам набором по ирисам.\n\nПеременная вида “Species” будет использована в качестве группирующей переменной:\n\n```{r}\niris.pca <- PCA(iris[,-5], graph = FALSE)\n```\n\nСоздаем график:\n\n```{r}\nfviz_pca_ind(iris.pca,\n             geom.ind = \"point\", # показываем только точки, не метки\n             col.ind = iris$Species, # группирующая переменная\n             palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             addEllipses = TRUE, # эллипсы концентрации\n             legend.title = \"Группы\"\n             )\n```\n\n### Создаем биплот\n\nЭто, конечно, самый интересный момент. Чтобы сделать простой биплот по переменным и наблюдениям, можно воспользоваться следующим кодом:\n\n```{r}\nfviz_pca_biplot(res.pca, repel = TRUE,\n                col.var = \"#2E9FDF\", # Цвет переменных\n                col.ind = \"#696969\"  # Цвет наблюдений\n                )\n```\n\nОтметим, что такой график целесообразен, если у нас мало переменных и наблюдений, в противном случае он может быть нечитаемым.\n\nОтметим также, что координаты переменных и наблюдений рассчитываются не в одном пространстве. Иными словами, в биплоте для нас больше важны направления переменных, чем абсолютные значения расстояний на графике.\n\nГрубо говоря, смысл биплота заключается в следующем:\n\n-   наблюдение, которое находится с той же стороны, что и переменная, имеет большие значения именно по данной переменной;\n-   наблюдение, которое находится с другой стороны от переменной, имеет по ней маленькие значения.\n\nСделаем график по ирисам:\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                col.ind = iris$Species, palette = \"jco\", \n                addEllipses = TRUE, label = \"var\",\n                col.var = \"black\", repel = TRUE,\n                legend.title = \"Species\") \n                \n```\n\nВ следующем графике мы хотим раскрасить как наблюдения, так и переменные по группам.\n\nЧтобы разобраться с цветами, мы воспользуемся вспомогательными функциями `fill_palette()` и `color_palette()` \\[ggpubr\\].\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                # Наблюдения по группам\n                geom.ind = \"point\",\n                pointshape = 21,\n                pointsize = 2.5,\n                fill.ind = iris$Species,\n                col.ind = \"black\",\n                # Цвет переменных по группам\n                col.var = factor(c(\"sepal\", \"sepal\", \"petal\", \"petal\")),\n                \n                legend.title = list(fill = \"Species\", color = \"Clusters\"),\n                repel = TRUE        # чтобы не было пересечений\n             )+\n  ggpubr::fill_palette(\"jco\")+      # цвет для наблюдений\n  ggpubr::color_palette(\"npg\")      # цвет для переменных\n```\n\nВ следующем графике наблюдения раскрашены по группам, а переменные - по вкладу в главные компоненты (градиентная заливка).\n\n```{r}\nfviz_pca_biplot(iris.pca, \n                # Individuals\n                geom.ind = \"point\",\n                fill.ind = iris$Species, col.ind = \"black\",\n                pointshape = 21, pointsize = 2,\n                palette = \"jco\",\n                addEllipses = TRUE,\n                # Variables\n                alpha.var =\"contrib\", col.var = \"contrib\",\n                gradient.cols = \"RdYlBu\",\n                \n                legend.title = list(fill = \"Species\", color = \"Contrib\",\n                                    alpha = \"Contrib\")\n                )\n```\n\n### Дополнительные элементы\n\nПомните, мы разделили наш набор на две части - активные и дополнительные переменные?\n\nУ нас есть две количественные дополнительные переменные (`quanti.sup`, колонки 11:12), и одна дополнительная качественная переменная (`quali.sup`, колонка 13) и четыре дополнительных спортсмена (`ind.sup`, строки 24:27).\n\nДополнительные элементы не используются в основном анализе, а их координаты предсказываются исходя из информации, полученной в результате анализа, полученного на активных данных.\n\nКак такой анализ может быть проведен?\n\n```{r}\nres.pca <- PCA(decathlon2, ind.sup = 24:27, \n               quanti.sup = 11:12, quali.sup = 13, graph=FALSE)\n\n```\n\n### Количественные переменные\n\nРезультаты предсказания (координаты, корреляции и квадрат косинуса) для дополнительных переменных:\n\n```{r}\nres.pca$quanti.sup\n```\n\nВизуализация переменных (и активных, и дополнительных)\n\n```{r}\nfviz_pca_var(res.pca)\n```\n\n### Данные по наблюдениям\n\nПредсказанные результаты по наблюдениям:\n\n```{r}\nres.pca$ind.sup\n```\n\nВизуализация наблюдений (активных и дополнительных). Мы можем представить также качественные переменные (`quali.sup`), а их координаты можно извлечь через `res.pca$quali.supp$coord`.\n\n```{r}\np <- fviz_pca_ind(res.pca, col.ind.sup = \"blue\", repel = TRUE)\np <- fviz_add(p, res.pca$quali.sup$coord, color = \"red\")\np\n```\n\n### Данные по качественным переменным\n\nДополнительные качественные переменные могут также быть использованы для группировки. Это может помочь с интерпретацией данных.\n\nРезультаты по качественным переменным:\n\n```{r}\nres.pca$quali\n```\n\nЧтобы использовать эту переменную в качестве группирующей, нужно использовать аргумент `habillage` (по-французски это \"одевание\"), в который вносится индекс этой переменной.\n\n```{r}\nfviz_pca_ind(res.pca, habillage = 13,\n             addEllipses =TRUE, ellipse.type = \"confidence\",\n             palette = \"jco\", repel = TRUE) \n\n\n```\n\n### Фильтр результатов\n\nЕсли у нас много наблюдений или переменных, то можно визуализировать только некоторые из них через аргументы `select.ind` и `select.var`.\n\nМожно сделать сортировку по имени, по косинусу или вкладу.\n\nПримеры:\n\n```{r}\n# Отбор переменных с cos2 >= 0.6\nfviz_pca_var(res.pca, select.var = list(cos2 = 0.6))\n# Top 5 активных переменных с самым высоким cos2\nfviz_pca_var(res.pca, select.var= list(cos2 = 5))\n# Отбор по именам\nname <- list(name = c(\"Long.jump\", \"High.jump\", \"X100m\"))\nfviz_pca_var(res.pca, select.var = name)\n# top 5 самых важных наблюдений и переменных\nfviz_pca_biplot(res.pca, select.ind = list(contrib = 5), \n               select.var = list(contrib = 5),\n               ggtheme = theme_minimal())\n\n```\n\n## Анализ соответствий\n\n**Анализ соответствий**, по-английски - Correspondence analysis (CA), яляется расширением метода главных компонент, предназначенным для исследования взаимосвязей между качественными (категориальными) переменными. Подобно методу главных компонент, он позволяет обобщить информацию и визуализировать данные в виде двумерных графиков.\n\nВ рамках данного занятия мы будем рассматривать пример данных, представленных в виде таблице сопряженности. Координаты, полученные в ходе анализа соответствий будут использоваться для того, чтобы в графическом виде представить ассоциации между строковых и столбцовых элементов.\n\nКогда мы анализируем двумерную таблицу сопряженности, мы обычно стремимся сопоставить отдельные строки каким-либо столбцам. Например, выявляя различия между различыми типами поведения по полу, мы хотели бы выяснить, какие из них являются \"мужскими\", а какие \"женскими\".\n\nАнализ соответствий дает нам такую возможность, поскольку он представляет геометрический подход к визуализации строк и столбцов двумерной таблицы в качестве точек в пространстве меньшей размерности (меньшей - значит, что в нем меньше измерений, чем количество строк или столбцов), так, что расположение точек, соответствующих строкам или столбцам, будет нам показывать их взаимосвязи. Главная цель такого анализа - в наглядном виде представить глобальное видение этих взаимосвязей, удобное для интерпретации.\n\nМы будем анализировать набор данных, который называется `housetasks`, включенный в библиотеку `factoextra`. Не трудно догадаться, в нем содержатся данные о ведении домашнего хозяйства.\n\n```{r}\ndata(housetasks)\nhousetasks\n```\n\nНабор данных представляет собой таблицу частот, где в строках содержится описание 13 различных домашних дел и их распределение в супружеской чете:\n\n-   \"Laundry\" - стирка\n-   \"Main_meal\" - приготовление еды (основное блюдо)\n-   \"Dinner\" - ужин\n-   \"Breakfeast\" - завтрак\n-   \"Tidying\" - уборка дома\n-   \"Dishes\" - мытье посуды\n-   \"Shopping\" - покупки\n-   \"Official\" - работа с документами\n-   \"Driving\" - вождение\n-   \"Finances\" - финансы\n-   \"Insurance\" - страховка\n-   \"Repairs\" - ремонтные работы\n-   \"Holidays\" - подготовка к праздникам\n\nСтроки - разная работа, значения в таблице - частоты, полученные в зависимости от выполнения дел:\n\n-   wife - только женой\n-   alternatively - совместно (по очереди)\n-   husband - только мужем\n-   jointly - совместно (вместе)\n\n![](images/PCA/pic4.png)\n\n### Графическое представление таблицы и тест хи-квадрат\n\nНаша таблица не очень большая, и значит мы легко можем проанализировать профили строк и столбцов.\n\nОчевидно,что стирка, приготовление основного блюда и ужин чаще всего - это женские занятия.\n\nРемонт и вождение автомобили - преимущественно мужские, а вот к праздникам супруги готовятся чаще вместе.\n\nДавайте представим эти результаты графически с помощью библиотеки `gplots`и функции `balloonplot()`:\n\n```{r}\nlibrary(\"gplots\")\n# 1. Переконвертируем данные в таблицу\ndt <- as.table(as.matrix(housetasks))\n# 2. Сделаем красивый график\nballoonplot(t(dt), main =\"housetasks\", xlab =\"\", ylab=\"\",\n            label = FALSE, show.margins = FALSE)\n\n```\n\nЧтобы проверить данные на наличие взаимосвязи или независимости между двумя признаками, можно обратиться к тесту хи-квадрат, который показывает отклонение наблюдаемых частот от ожидаемых (равномерно распределенных):\n\n```{r}\nchisq <- chisq.test(housetasks)\nchisq\n\n```\n\nВ нашем примере мы видим, что переменные, представленные в строках и столбцах статистически значимо взаимосвязаны (p-value = r chisq\\$p.value).\n\n### Как провести анализ соответствий в R\n\nФормула очень напоминает метод главных компонент:\n\n```{r}\nlibrary(\"FactoMineR\")\nres.ca <- CA(housetasks, graph = FALSE)\n```\n\nВывод функции CA() включает следующие результаты:\n\n```{r}\nprint(res.ca)\n```\n\n### Визуализация и интепретация\n\nФункции, которые используются в `factoextra` для извлечения и визуализации данных, очень напоминают те, которые использовались нами в методе главных компонент:\n\n-   get_eigenvalue(res.ca): извлекает собственные значения / долю дисперсии, описываемые по каждому измерению (оси)\n-   fviz_eig(res.ca): визуализация собственных значений\n-   get_ca_row(res.ca), get_ca_col(res.ca): извлечение результатов отдельно по строкам и столбцам\n-   fviz_ca_row(res.ca), fviz_ca_col(res.ca): визуализация результатов отдельно по строкам и столбцам\n-   fviz_ca_biplot(res.ca): биплот\n\n### Собственные значения / дисперсия\n\nВспомним, что мы рассматриваем собственные значения, чтобы определиться с количеством измерений (компонент, осей), которые мы будем рассматривать. Собственные значения и соответствующие им доли дисперсии могут быть извлечены с помощью функции `get_eigenvalue()`. У первой оси собственное значение будет максимальным и оно будет уменьшаться для последующих измерений.\n\n```{r}\neig.val <- get_eigenvalue(res.ca)\neig.val\n```\n\nСобственные значения описывают количество информации, обобщаемой по каждой оси. Измрения упорядочены по убыванию и приводятся в соответствии с долями дисперсии.\n\nТак же, как и в МГК, собственные значения могут быть использованы для определения оптимального количества осей для анализа.\n\nХотя единого \"рецепта\" на этот случай не существует, хороший анализ характеризуется большой долей дисперсии, описываемой через небольшое количество измерений.\n\nВ нашем анализе первые два измерения объясняют 88.6% дисперсии, и это достаточно неплохой результат.\n\nАльтернативный метод - посмотреть на график рассеяния, построенный для упорядоченных собственных значений.\n\n```{r}\nfviz_screeplot(res.ca, addlabels = TRUE, ylim = c(0, 50))\n\n```\n\nТочка, после которой возникает спад (так называемый “локоть”) означает оптимальную размерность.\n\nМы можем также посчитать среднее собственное значение и оставить те измерения (оси), собственные значения по которым выше:\n\nУ нас 13 строк и 4 столбца, значит, если бы данные были бы случайно распределены по категориям, то ожидаемое собственное значение по каждому измерению равнялось бы: 1/(nrow(housetasks)-1) = 1/12 = 8.33%.\n\nТочно такую же процедуру нужно провести и по столбцам: 1/(ncol(housetasks)-1) = 1/3 = 33.33%\n\nВ соответствии с рекомендациями (M. T. Bendixen 1995):\n\nЛюбая ось, вносящая больше вклада, чем максимальное из этих двух процентов, должна рассматриваться в качестве важной и включаться в интерпретацию результатов анализа.\n\nУ нас максимальное значение - 33,3%\n\n```{r}\nfviz_screeplot(res.ca) +\n geom_hline(yintercept=33.33, linetype=2, color=\"red\")\n```\n\nКак хорошо видно на графике, мы должны оставить два измерения. Отметим, что оставшиеся измерения на самом деле нам мало помогут, поскольку их вклад в объяснение изменчивости данных очень мал.\n\nИзмерения 1 и 2 объясняют около 48.7% и 39.9% общей инерции (аналог дисперсии для анализа соответствий). В совокупности это составляет 88.6%.\n\n### График для строк\n\nАналогичным образом получим и визуализируем результаты для строк.\n\n```{r}\nrow <- get_ca_row(res.ca)\nrow\n```\n\nКомпоненты, содержащиеся в функции `get_ca_row()` могут быть использованы для построения графика:\n\n-   row\\$coord: координаты по каждому измерению (1, 2 and 3). Используются для построения диаграммы рассеяния.\n-   row\\$cos2: качесто представленности строк.\n-   var\\$contrib: вклад строк в процентах в определение измерений\n\n::: {.alert .alert-info role=\"alert\"}\nОтметим, что можно визуализировать данные по строкам либо 1) по качеству их представленности в факторной структуре (cos2) или 2) по их вкладу в определение направлений.\n:::\n\nКак это сделать?\n\n```{r}\n# Координаты\nhead(row$coord)\n# Cos2\nhead(row$cos2)\n# Вклады в измерения\nhead(row$contrib)\n```\n\n### Координаты строк\n\nВизуализируем только строки:\n\n```{r}\nfviz_ca_row(res.ca, repel = TRUE)\n```\n\n### Качество репрезентации строк\n\nРезультаты показывают, что таблица сопряженности была успешно представлена в пространстве меньшей размерности с помощью анализа соответствий, и мы смогли успешно описать 88.6% дисперции (инерции) данных.\n\nТем не менее, не все точки одинаково хорошо расположились вдоль двух осей (измерений).\n\nВспомним, что качество представленности переменной (строки) измеряется через показатель (cos2 - квадрат косинуса), что аналогично квадрату корреляции (или квадрату координаты по направлению).\n\nПоказатель cos2 измеряет степень ассоциации между строками / столбцами и конкретной осью.\n\nКак этот показатель извлечь?\n\n```{r}\nhead(row$cos2, 4)\n\n```\n\nЗначения cos2 изменяются в диапазоне между 0 и 1. Сумма всех cos2 для всех по всем измерениям равна 1. Чем больше сумма квадратов косинусов для отдельной строки по всем измерениям, тем лучше информация, которую она представляет, описывается полученной моделью.\n\nДавайте эту информацию представим графически:\n\n```{r}\nfviz_ca_row(res.ca, col.row = \"cos2\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n```\n\n### Альтернативный способ представления значений cos2\n\nМы можем визуализировать качество представленности строк с помощью библиотеки `corrplot`:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(row$cos2, is.corr=FALSE)\n```\n\nЕще один вариант - столбчатая диаграмма:\n\n```{r}\nfviz_cos2(res.ca, choice = \"row\", axes = 1:2)\n```\n\n### Вклад строк в измерения\n\nВклад строк (в %) в определение измерений может быть извлечена путем:\n\n```{r}\nhead(row$contrib)\n```\n\nСоответственно, строки с большими значениями вносят больший вклад в определение измерений и являются более важными.\n\nМожем сделать аналогичный корплот:\n\n```{r}\nlibrary(\"corrplot\")\ncorrplot(row$contrib, is.corr=FALSE)    \n```\n\nФункция `fviz_contrib()` полезна для анализа вклада по отдельным измерениям:\n\n```{r}\n# Вклад строк в измерение 1\nfviz_contrib(res.ca, choice = \"row\", axes = 1, top = 10)\n# Вклад строк в измерение 2\nfviz_contrib(res.ca, choice = \"row\", axes = 2, top = 10)\n\n```\n\nОбщий вклад в два измерения\n\n```{r}\nfviz_contrib(res.ca, choice = \"row\", axes = 1:2, top = 10)\n```\n\nОтметим, что такие дела, как ремонт, стирка, приготовление еды и вождение являются самыми важными по первому измерению.\n\nТогда как выходные и ремонт - для второго измерения.\n\nВизуализируем это:\n\n```{r}\nfviz_ca_row(res.ca, col.row = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE)\n```\n\nДанный график может нам дать некоторые идеи по поводу содержания осей. Очевидно, что первая ось - собственно делит наши занятия на мужские и женские - по критерию физического труда (интеллектуальной активности) - рутинного труда. Второе измерение скорее охватывает аспекты совместной деятельности или одиночной (водить машину вдвоем довольно затруднительно.\n\n### Представление переменных по столбцам\n\nЧтобы извлечь результаты по вариантам ответа, представленным в столбцах, понадобится функция `get_ca_col()`:\n\n```{r}\ncol <- get_ca_col(res.ca)\ncol\n```\n\nЧтобы обратиться к отдельным компонентам вывода, нужно набрать:\n\n```{r}\n# Координаты\nhead(col$coord)\n# Качество репрезентации\nhead(col$cos2)\n# Вклады\nhead(col$contrib)\n```\n\n### Графики качества и вклада\n\nВоспользуемся аналогичными функциями визуализации, чтобы провести анализ качества и вклада по столбцам:\n\n```{r}\nfviz_ca_col(res.ca, col.col = \"cos2\", \n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE)\n\n```\n\n```{r}\nfviz_cos2(res.ca, choice = \"col\", axes = 1:2)\n```\n\nСудя по нашим результатам, вариант ответа \"по очереди\" (Alternating) представлен первыми двумя измерениями не самым наилучшим образом.\n\nЧтобы визуализировать вклад столбцов в первые два фактора, можно использовать следующий код:\n\n```{r}\nfviz_contrib(res.ca, choice = \"col\", axes = 1:2)\n```\n\nРезультаты - аналогичные. График еще раз подтвердил, что наибольший вклад вносят три варианта ответа - \"муж\", \"жена\" и \"совместные действия\".\n\n### Делаем биплот\n\nАналогично тому, как мы делали биплот в ходе анализа методом главных компонент, можно визуализировать результаты анализа соответствий.\n\nСтандартным является симметричный биплот, в котором строки (синие точки) и столбцы (красные треугольники) представлены в одном пространстве на основе главных координат, показывающих их профили. В этом случае, только расстояние между точками одной группы может быть реально проинтерпретировано, тогда как расстояния между строками и столбцами интерпретировать напрямую некорректно, можно делать только самые общие выводы и обобщения.\n\n```{r}\nfviz_ca_biplot(res.ca, repel = TRUE)\n```\n\n### Биплот, учитывающий вклад переменных\n\nВ стандартном симметричном биплоте, который мы только что сделали, довольно трудно понять, какие точки (переменные) вносят больший вклад в полученную модель.\n\nМайкл Гринэкр (Michael Greenacre) предложил новый тип шкалирования (масштабирования), получивший название \"биплот вкладов\" (contribution biplot), который позволяет визуализировать эти моменты (M. Greenacre 2013). При таком отображении, точки, которые вносят маленький вклад и являющиеся не очень важными, располагаются ближе к центру координат.\n\nТакой график можно получить, задав аргумент `map = “rowgreen”` или `map = “colgreen”`.\n\n```{r}\nfviz_ca_biplot(res.ca, map =\"colgreen\", arrow = c(TRUE, FALSE),\n               repel = TRUE)\n```\n\nВ принципе, графики - аналогичны предыдущему, в них лишь ставится больший акцент на значимости переменных.\n\n### Описание измерений\n\nЧтобы понять, какие строки или столбцы в большей степени связаны с главными измерениями, можно подробно исследовать информацию по каждому из них, что удобно сделать с помощью функции `dimdesc()`(FactoMineR). Строки и столбцы в выводе отсортировываются по их координатам.\n\n```{r}\nres.desc <- dimdesc(res.ca, axes = c(1,2))\n```\n\n### Пример анализа по климатическому исследованию\n\nПроведем анализ соответствий на основе данных таблицы сопряженности между регионом исследования и вопросом V14, описывающем наиболее частые природные явления, происходящие в зимнее время.\n\nПодключим необходимые пакеты для загрузки и обработки данных, загрузим наши данные:\n\n```{r message=FALSE, warning=FALSE}\nlibrary(haven)\nlibrary(dplyr)\nlibrary(questionr)\ndf<-read_sav(\"База_КлимРиск_2023.sav\")\n```\n\nПоскольку вопрос V14 является вопросом с множественным выбором, создадим набор:\n\n```{r}\nV14<-df %>% \n  select(contains(\"V14\"))\n```\n\nПо набору и переменной региона сделаем таблицу сопряженности, укажем `freq=FALSE`, чтобы у нас получилась таблица с абсолютными значениями, а не с процентами (хотя результаты были бы очень похожими):\n\n```{r}\ntable_V14_region<-cross.multi.table(V14, df$Region, true.codes=list(\"да\"), freq=FALSE)\n```\n\nУдалим лишний столбец (по Монголии) и строки, в которых содержатся переменные с вариантами ответа «Другое»:\n\n```{r}\ntable_V14_region<-table_V14_region[1:10, 1:3]\n```\n\nСоздадим подписи, обозначив имена столбцов (регионы) и строк (природные явления):\n\n```{r}\ncolnames(table_V14_region)<-c(\"АК\", \"РА\", \"РТ\")\nrownames(table_V14_region)<-c(\"Перепад.темп\", \"Аном.холод\", \"Оттеп.\", \"Гололед\", \"Снегопад\", \"Лавины\", \"Пасм.дни\", \"Реч.лед\", \"Зажоры\", \"Ветра, метели\")\n```\n\nПроведем корреспондентский анализ:\n\n```{r}\nres.ca <- CA(table_V14_region, graph = FALSE)\n```\n\nПосмотрим, сколько измерений у нас получилось:\n\n```{r}\nget_eigenvalue(res.ca)\n```\n\nВидим, что наши данные описываются всего двумя измерениями, первое из которых описывает 88,8% дисперсии, второе - 11,2%.\n\n```{r}\nrow <- get_ca_row(res.ca)\nrow\n```\n\nПосмотрим показатель квадрата косинуса:\n\n```{r}\nrow$cos2\n```\n\nПочти все строки максимально хорошо описываются первым измерением, кроме гололедных явлений, по второму измерению максимальные оценки, напротив у голодеда и процессов, связанных с образованием речного льда.\n\nПосмотрим вклады:\n\n```{r}\nrow$contrib\n```\n\nВ первое измерение наибольший вклад вносили перепады температуры, оппепели и аномальные холода, тогда как для второго измерения важными были переменные, связанные с гололедом, аномальными холодами и сдвигами в периодах образования речного льда.\n\nСделаем биплот:\n\n```{r}\nfviz_ca_biplot(res.ca, repel = TRUE)\n```\n\n## Самостоятельная работа\n\n1.  Проанализировать данные психосемантического исследования по религии.\n\n{{< iconify arcticons 1dm size=42px >}}[Скачать данные](https://github.com/domelia/rcourse/blob/main/religions.sav)\n\n2.  Сделать анализ главных компонент. Вывести результаты по собственным значениям и дисперсии (вместе с графиками), по координатам (корреляциям) и вкладам - по дескрипторам и ролям\n3.  Сделать визуализацию - отдельно по дескрипторам, по ролям и биплот.\n4.  Сделать анализ соответствий в базе данных по климату по переменной V16 (вопрос с множественным выбором по природным явлениям, происходящим в летний период).\n\n## Источники\n\n::: {#refs}\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["include/webex.css"],"include-after-body":["include/webex.js"],"embed-resources":false,"output-file":"PCA_CA.html"},"language":{"toc-title-document":"Содержание","toc-title-website":"Содержание","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","other-links-title":"Другие ссылки","code-links-title":"Ссылки на код","launch-dev-container-title":"Запустить Dev Container","launch-binder-title":"Запустить Binder","article-notebook-label":"Блокнот статьи","notebook-preview-download":"Скачать блокнот","notebook-preview-download-src":"Скачать исходный код","notebook-preview-back":"Вернуться к статье","manuscript-meca-bundle":"Архив MECA","section-title-abstract":"Аннотация","section-title-appendices":"Приложения","section-title-footnotes":"Сноски","section-title-references":"использованная литература","section-title-reuse":"Повторное использование","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Пожалуйста, цитируйте эту работу как:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Просмотреть Лицензию","title-block-author-single":"Автор","title-block-author-plural":"Авторы","title-block-affiliation-single":"принадлежность","title-block-affiliation-plural":"Принадлежности","title-block-published":"Дата публикации","title-block-modified":"Файл изменен","title-block-keywords":"Ключевые слова","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Развернуть код","code-tools-hide-all-code":"Скрыть код","code-tools-view-source":"Показать код","code-tools-source-code":"Исходный код","tools-share":"Share","tools-download":"Download","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Скопировать текст","copy-button-tooltip-success":"Скопировано","repo-action-links-edit":"Редактировать страницу","repo-action-links-source":"Показать код","repo-action-links-issue":"Сообщить о проблеме","back-to-top":"Наверх","search-no-results-text":"Поиск не дал результатов","search-matching-documents-text":"Результаты поиска","search-copy-link-title":"Скопировать ссылку","search-hide-matches-text":"Скрыть дополнительные результаты","search-more-match-text":"дополнительный результат в этом документе","search-more-matches-text":"дополнительных результата(-ов) в этом документе","search-clear-button-title":"Очистить","search-text-placeholder":"","search-detached-cancel-button-title":"Отменить","search-submit-button-title":"Найти","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рисунок","crossref-tbl-title":"Таблица","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лемма","crossref-cor-title":"Следствие","crossref-prp-title":"Утверждение","crossref-cnj-title":"Гипотеза","crossref-def-title":"Определение","crossref-exm-title":"Пример","crossref-exr-title":"Упражнение","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Приложение","crossref-sec-prefix":"Глава","crossref-eq-prefix":"Уравнение","crossref-lof-title":"Список Иллюстраций","crossref-lot-title":"Список Таблиц","crossref-lol-title":"Список Каталогов","environment-proof-title":"Доказательство","environment-remark-title":"Примечание","environment-solution-title":"Решение","listing-page-order-by":"Сортировать по","listing-page-order-by-default":"предварительно выбранный","listing-page-order-by-date-asc":"Самый старый","listing-page-order-by-date-desc":"Новейшие","listing-page-order-by-number-desc":"нисходящий","listing-page-order-by-number-asc":"по возрастанию","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Описание","listing-page-field-author":"Автор","listing-page-field-filename":"Имя файла","listing-page-field-filemodified":"Файл изменен","listing-page-field-subtitle":"Подзаголовок","listing-page-field-readingtime":"Время чтения","listing-page-field-wordcount":"Подсчет слов","listing-page-field-categories":"Категории","listing-page-minutes-compact":"{0} минут","listing-page-category-all":"Все","listing-page-no-matches":"Нет подходящих элементов","listing-page-words":"{0} слов","listing-page-filter":"Фильтр","draft":"Черновик"},"metadata":{"lang":"ru","fig-responsive":true,"quarto-version":"1.5.57","comments":{"hypothesis":true},"bibliography":["references.bib"],"editor":"visual","theme":"Pulse","title":"Основы многомерного анализа: снижение размерности"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}