---
title: "Разведочный анализ данных в R"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Для чего нам нужен разведочный анализ (Exploratory Data Analysis)

**Разведочный анализ** в общем смысле – это предварительный анализ данных с целью выявления наиболее общих зависимостей, закономерностей и тенденций, характера и свойств анализируемых данных, законов распределения анализируемых величин. Именно с разведочного анализа начинается любая обработка данных результатов научного исследования.

![](https://learn.microsoft.com/en-us/azure/architecture/example-scenario/data/media/exploratory-data-analytics/sandboxing.png)

При этом, разведочный анализ - это не какой-то один статистический тест или метод. При разведочном анализе учитывается и сравнивается большое число признаков, а для поиска закономерностей или обоснования имеющихся различий используются самые разные процедуры и техники.

Термин «разведочный анализ» и набор техник, которые применяются для его проведения, был впервые введен и популяризирован американским математиком и статистиком из Принстонского университета **Джоном Тьюки**, написавшим в 1977 году книгу «Разведочный анализ данных» (Exploratory Data Analysis).

![](data:image/jpeg;base64,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)

Этот термин кажется «сухим» и «занудным», однако практики, используемые в рамках разведочного анализа, не только являются крайне важными, но и весьма волнующими для исследователя. Не случайно, сам Дж. Тьюки сравнил EDA с работой детектива: каждый новое исследование данных представляет собой «мистическую историю», которую мы должны расследовать, вскрыть скрытые свойства и секретные характеристики наших данных.

Основными целями разведочного анализа являются:

- проникновение в данные и описание их во всей полноте;
- выявление основных структур (паттернов) и тенденций;
- идентификация взаимосвязей и корреляций между переменными
- выбор наиболее важных переменных;
- обнаружение отклонений и аномалий;
- проверка основных гипотез (предположений);
- разработка начальных моделей и подготовка данных для дальнейшего анализа.

Результаты разведочного анализа не используются напрямую для выработки управленческих решений, скорее они предоставляют помощь в разработке лучшей стратегии углубленного анализа, способствуют выдвижению новых гипотез, обосновывают возможности применения тех или иных математических методов и моделей. Без разведочного анализа дальнейший анализ данных, часто включающий разработку комплексных статистических моделей, будет производиться практически «вслепую».

**Разведочный (эксплораторный, описательный)** анализ данных по своему содержанию, целям и задачам противопоставлен **подтверждающему** анализу данных (Confirmatory Data Analysis), основанному на конкретных предположениях и уже имеющихся данных.

К основным методам разведочного анализа относятся анализ распределений, особенно с помощью методов визуального анализа (гистограмм, диаграмм рассеяния, ящичных диаграмм), тестирование гипотез о соответствии определенному виду распределения, методы группового и корреляционного анализа. Довольно часто к методам разведочного анализа также относят техники, позволяющие осуществить кластеризацию и снизить размерность данных, графически представить высоко-размерные данные, включающие множество переменных, в также предсказательные модели, такие как линейная регрессия, использующие данные и статистические показатели для предсказания целевых показателей. В рамках данного пособия такие методы будут рассмотрены в следующем разделе, посвященном многомерному анализу и возможностям статистического моделирования.

## Анализ характеристик распределения количественной переменной

Мы начнем наше разведочное исследование с количественных переменных и затем перейдем к категориальным переменным, двумерному и корреляционному анализу.

Чтобы наши действия были ближе к «социологической жизни», мы будем использовать результаты исследования восприятия и оценки адаптивных стратегий населения в отношении климатических рисков в высокогорных районах Алтая.

:::callout-info
Если Вы не сохранили данные с предыдущих занятий, скачайте их еще раз.

Скачать [данные](https://github.com/domelia/R-book/blob/main/files/База_КлимРиск_2023.sav)/
:::

```{r}
library(haven)
df<-read_sav("files/База_КлимРиск_2023.sav")
```

Прежде, чем мы начнем «препарировать» наши данные, давайте взглянем на них издалека, в целом. Для этой цели хорошо подойдут библиотеки так называемого автоматизированного разведочного анализа, позволяющие быстро подготовить отчеты сразу по всему массиву данных, представить остовные статистики и графики. В R существует по меньшей мере 10 таких библиотек, наиболее известными из которых являются:
- summarytools
- DataExplorer
- visdat
- funModeling
- arsenal
- dataMaid
- dlookr

Подробный анализ данных библиотек в действии, их положительных и отрицательных сторон, можно найти в статье: *Mateusz Staniak* и *Przemysław Biecek* [**The Landscape of RPackages for Automated Exploratory Data Analysis**](https://arxiv.org/pdf/1904.02101).

Мы воспользуемся некоторыми функциями библиотеки `DataExplorer`. 
Для начала установим ее:
```{r eval=FALSE}
install.packages("DataExplorer")
```

После установки, как всегда, загружаем библиотеку в текущую сессию и запускаем ее:
```{r message=FALSE, warning=FALSE}
library(DataExplorer)
```

Давайте проведем самый общий анализ по всей базе данных с помощью функции `introduce()`, которая выдаст нам самые общие сведения: количество строк и колонок (переменных), сколько из них являются дискретными и непрерывными, если такие переменные, в которых все данные пропущены, а также данные о количестве наблюдений и пропущенных значений.

```{r eval=FALSE}
introduce(df)
```

```{r echo=FALSE}
library(tidyselect)
library(kableExtra)
introduce(df) %>% 
  t() %>% 
  kbl()
```


Чтобы визуализировать данную таблицу, можно использовать функцию `plot_intro()`. На графике отображаются основные показатели набора данных - количество дискретных и непрерывных переменных, полных наблюдений и переменных с отстутствующими значениями. 

Почему у нас так много пропусков и нет ни одной строки с полными данными? Все просто: ведь в ходе анализа учитываются абсолютно все переменные набора, включая дополнительные переменные «Другое», которые вполне могли остаться пустыми, если респондент не выбирал данный вариант ответа, а также переменные, предназначенные для определенных категорий респондентов, на которые по определению отвечали не все. Если бы мы отобрали меньшее количество переменных, которые нам нужны для конкретного анализа, результаты были бы совершенно иными. Кроме того, следует учитывать, что при подсчете «дискретных» и «непрерывных» переменных функция руководствуется результатам присвоения категорий данных в SPSS и их импорта в `haven`. Так что, если изначально тип переменной был задан неверно, то и результаты такого анализа, мягко скажем, не будут соответствовать действительности.

```{r}
plot_intro(df)
```

В доказательство вышеприведенного тезиса приведем график пропущенных значений по некоторым переменным. Можно легко заметить, что переменные образуют две группы - те, где количество пропусков не составляет выше 5% и переменные, где пропусков существенно больше (обозначены оранжевым цветом). Это ответы на вопрос 9, где спрашивалось о том, каким имуществом владели домохозяйства, проживающие в горных районах (сельхозтехника, сад, огород, пастбище, участки леса и пр.). Нет ничего удивительного в том, что более пятой части опрошенных не обладали ни одним из перечисленных вариантов, более того, часть из них, учитывая, что опрос проводился в зонах экстремального земледелия (приравненных к условиям Крайнего Севера), можно считать признаками высокого статуса и богатства (например, если у жителя есть в пользовании теплица и он может сам выращивать овощи). 

```{r}
plot_missing(df[,30:50])
```

### Основные описательные характеристики

У нас не так много количественных данных, и одной из непрерывных переменных является возраст (`age`).

Самым простым способом анализа основных характеристик распределения является базовая функция `summary()`, предоставляющая семь ключевых статистик: минимум, максимум, среднее, медиану, 1-й и 3-й квартили, а также количество пропущенных значений:
```{r}
summary(df$age)
```

Более расширенный статистический анализ можно получить, обратившись к функции `describe()`из библиотеки `psych` (не забываем устанавливать новые библиотеки). Набор аргументов по умолчанию достаточно широк: здесь уже есть и стандартное отклонение, и усеченное среднее, и показатели асимметрии и эксцесса.
```{r eval=FALSE}
psych::describe(df$age)
```
```{r echo=FALSE}
psych::describe(df$age) %>% 
  t() %>% 
  kbl(digits = 2, label = "Возраст опрошенных")
```
Впрочем, каждый из них можно получить отдельно, с помощью базовых функций, например, стандартное отклонение:
```{r}
sd(df$age, na.rm = T)
```
Дисперсия:
```{r}
var(df$age, na.rm = T)
```
Асимметрия:

```{r}
psych::skew(df$age, na.rm = T)
```
### Графические методы анализа распределения

Большую роль в анализе данных играет визуализация, и в случае анализа количественных переменных она просто незаменима. Часто именно график, без какого-либо статистического анализа, дает лучшее представление о том, что происходит с данными, тогда как статистические «точечные» оценки, такие как среднее или дисперсия, могут ввести в заблуждение. 

Количественную переменную обычно графически представляют несколькими разными способами:
- с помощью гистограмм;
- с помощью квантильного графика;
- с помощью ящичной диаграммы.

Самый быстрый и простой способ получения гистограммы - с помощью базовой функции `hist()`:
```{r}
hist(df$age, col="steelblue", xlab = "Возраст (лет)", main="Возраст опрошенных")
```
Если мы хотим более «продвинутый» вариант гистограммы, можно обратиться к возможностям библиотеки `ggstatsplots`, основанной на философии создания визуальных материалов в рамках библиотеки `ggplot2` и предназначенной для создания публикабельных визуализаций, сопровожденной результатами статистического анализа и возможностями проверки статистических гипотез. При несколько излишней сложности, это, пожалуй, лучшее, что есть сегодня в плане описательного анализа. Это не просто библиотека, создающая графики, это одновременно и способ визуализации, и способ проведения статистического анализа, включая представление регрессионных моделей и мета-анализ.

```{r}
ggstatsplot::gghistostats(
  data            = df,
  x               = age,
  xlab            = "Возраст",
  effsize.type = "d",
  type = "parametric",
  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян
)
```
Результаты визуального анализа указывают на то, что наше среднее (44,0 года) довольно сильно отклоняется от общероссийских данных, что было протестировано с помощью одновыборочного t-критерия. Однако, довольно заметно, что у наших данных положительная асимметрия  и довольно длинный «хвост» из больших значений. Попробуем робастный подход, где вместо среднего используется усеченное среднее (по умолчанию в настройках указывается значение «усечения» -  0.2), а для подсчета p-значения при сравнении средних используется метод [бутстрэпа](https://ru.wikipedia.org/wiki/%D0%91%D1%83%D1%82%D1%81%D1%82%D1%80%D1%8D%D0%BF_(%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0). Результаты неутешительные - различия по-прежнему значимые. 
```{r}
ggstatsplot::gghistostats(
  data            = df,
  x               = age,
  xlab            = "Возраст",
  effsize.type = "d",
  type = "robust",
  test.value = 40.4 #Протестируем гипотезу об отличии среднего возраста по выборке от среднего возраста россиян
)
```

Еще один очень важный график: квантильный или Q-Q plot. 

Архитектура этого графика проста: по оси x откладываются квантили для эмпирических данных, а по оси y - квантили распределения, с которыми мы их сравниваем (обычно - нормальное). Таким образом, Q-Q plot это диаграмма рассеяния, в которой два набора квантилей представлены друг напротив друга. Если оба они происходят из одного распределения, мы увидим точки, формирующие прямую. 

Что такое квантиль?

Квантиль — это одна из точек, делящих функцию плотности распределения на участки, вероятность попадания в которые одинакова, то есть на участки одинаковой площади.


![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ced/171/7c6/ced1717c6ccf73d530fa4fedc8532e87.png)

**Квантильная функция** — это функция, которая по значению вероятности `P` возвращает такое число (квантиль) `q`, что вероятность того, что случайная величина примет значение меньше `q` равняется `P`:

![](https://habrastorage.org/getpro/habr/upload_files/233/dca/709/233dca7099c3c5e4085256e671d9c832.svg)
В базовом R, чтобы создать такой график, нужно соединить две функции - `qqnorm () и `qqline()`. Одна создает, собственно квантильный график, другая - референтную прямую, на которую можно ориентироваться при оценке полученных значений.


```{r}
qqnorm(df$age, frame = FALSE)
qqline(df$age, col = "steelblue", lwd = 2)
```

Как всегда, могут быть и другие варианты. На мой личный вкус один из лучших QQ-plot создается в библиотеке `ggpubr`, позволяющей добавить на график доверительные интервалы для квантилей, а также выбрать тему, применить трансформации к шкалам ("log2", "log10", "sqrt"), изменить другие настройки:
```{r warning=F}
ggpubr::ggqqplot(df, x = "age", color = "steelblue")
```

Еще одна форма графического представления количественных данных - ящичная диаграмма.

Анатомию данного графика лучше представить в визуальном виде (см. рисунок ниже). 
В центре графика - медиана, сам «ящик» формируется на основе межквартильного размаха (IQR), а «усы» ограничиваются либо минимальным и максимальным значениями, либо границами `Q3+1,5*IQR`и `Q1-1,5*IQR`, если в распределении имеются выбросы.

![](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_boxplots.jpg)
Можно воспользоваться простой функцией `boxplot(), либо использовать более изощренные варианты.
```{r}
boxplot(df$age, col="steelblue")
```
```{r warning=FALSE}
library(ggplot2)
ggplot(df, aes(y=age, fill="red")) + 
  geom_boxplot()+
  theme_bw()+
  theme(legend.position="none")
```

### Нахождение аномальных наблюдений

Уже на гистограмме и квантиль-квантильном графе хорошо видны все «огрехи» распределения, а ящичная диаграмма даже выносит особые наблюдения («статистические выбросы») за пределы основного графика.

Мы могли бы представить в виде диаграммы стандартизированные значения, и сразу понять, сколько и как много в нашей выборке наблюдений, превышающих допустимый предел (например, лежащих далее, чем 3 «сигмы» от нулевого значения):
```{r}
df$z_age <- scale(df$age)
hist(df$z_age)

```
Давайте посмотрим на описательные статистики:
```{r}
summary(df$z_age)
```
Мы видим, что у нас нет маленьких значений за пределами «-3», но есть некоторые значения, превышающие «+3).

Мы можем посмотреть номера (строки) этих наблюдений:
```{r}
which(df$z_age > 3.0)
```

Таких значений три - 562, 593, 872. Это серьезные долгожители:

```{r}
df[c(562,593,872),]$age
```

Вопрос о том, как выявлять аномальные значения и что с ними делать, не является тривиальным. Помимо графических методов, есть и специальные статистические методы, позволяющие вычленить наблюдения, содержащие нетипичные значения.

#### Фильтр Хэмпеля

Так, еще один метод, известный как фильтр Хэмпеля, рассматривает в качестве выбросов значения, попадающих в интервал  ($I$), образуемый медианой плюс или минус три абсолютных отклонения от медианы (median absolute, MAD):

$$I = [median - 3 \cdot MAD; median + 3 \cdot MAD]$$
где $MAD$ определяется как:

$MAD = median(|X_i - \tilde{X}|)$

Давайте определим нижнюю и верхнюю границы фильтра и отберем наблюдения, которые не попадают в указанный диапазон:
```{r}
lower_bound <- median(df$age, na.rm = T) - 3 * mad(df$age, na.rm=T, constant = 1)
lower_bound
```

```{r}
upper_bound <- median(df$age, na.rm = T) + 3 * mad(df$age, na.rm=T, constant = 1)
upper_bound
```

```{r}
outlier_ind <- which(df$age < lower_bound | df$age > upper_bound)
outlier_ind
```
Легко увидеть, что наблюдений гораздо больше, чем было выявлено с помощью z-значений, что указывает на то, что фильтр Хэмпеля является довольно консервативным подходом.


#### Статистические тесты для выявления аномалий

Кроме графических методов и механического отбора, нетипичные наблюдения можно выявлять и с помощью специальных тестов, например, таких как:

- Тест Груббса
- Тест Диксона
- Тест Роснера 

Эти три статистических теста являются частью более формальных техник нахождения выбросов, так как они основаны на вычислении тестовой статистики, которая сопоставляется с табличными критическими значениями, основанными на объеме выборки и определяемого доверительного уровня).

##### Grubbs’s test

Тест Груббса позволяет сделать вывод о том, являются ли максимальное и минимальное значение выбросами. 


$H_0$: максимальное значение **не** является аномальным.
$H_1$: максимальное значение является аномальным.

Аналогичным образом формулируются гипотезы о минимальных значениях:

$H_0$: минимальное значение **не** является аномальным.
$H_1$: минимальное значение является аномальным.

Как и для любого статистического теста, мы решаем, если p-значение меньше выбранного уровня значимости (чаще всего α=0,05) нулевая гипотеза отклоняется и мы делаем вывод, о том, что значения являются выбросами.

Этот тест не подходит для выборок, в которых содержится менее 6 наблюдений.

Чтобы выполнить тест Груббса в R, мы будем использовать функцию `grubbs.test()` из библиотеки `{outliers}`:

```{r}
# install.packages("outliers")
library(outliers)
test <- grubbs.test(df$age, type=10)
test
```
Тест «говорит» нам о том, что максимальное значение не является выбросом.

{{< iconify arcticons writer size=42px >}} **Самостоятельное задание**:

Проверьте, является ли выбросом минимальное значение. Для этого в настройках установите opposite = TRUE. Проверьте гипотезу о принадлежности к выбросам обоих - минимального и максимального значений. Поменяйте настройки на type=11.

##### Тест Диксона

Подобно тесту Груббса, тест Диксона используется для определения того, является ли минимальное или максимальное значение выбросом. Если у нас есть подозрение относительно других значений, мы должны тестировать их индивидуально. 

Еще одно ограничение: этот тест хорошо работает только на маленьких выборках (n≤25).

Чтобы попробовать этот метод на наших данных, мы должны сократить нашу выборку и использовать соответствующую функцию из той же библиотеки:

```{r}
subdat <- df[1:20, ]
test <- dixon.test(subdat$age)
test

```

##### Тест Роснера

К теста Роснера есть несколько преимуществ:
- его можно использовать для вычленения нескольких выбросов за один раз
- позволяет решать проблемы маскировки, когда один выброс, близкий по значению к другому выбросу, остается незамеченным
- подходит для больших выборок.
`
В R функция  `rosnerTest()` находится в библиотеке `{EnvStats}`. 
Функция требует по меньшей мере двух аргументов: ссылки на данные и количество выбросов (по умолчанию 3).

Формула теста следующая:
Наблюдаемые значения сортируются от меньшего к большему, далее определяется максимальное значение выбросов (не больше 10), и затем считается серия статистических тестов, путем последовательного удаления значений (высоких или низких), которые максимально удалены от среднего значения и пересчета стандартных значений по формуле:
 
$$\large R_{i+1} = \frac{|x^{(i)} - \bar x^{(i)}|}{s^{(i)}}$$
Как только все статистики $ R_1...R_k$  посчитаны, начинается проверка гипотез путем сопоставления с критическими значениями для определенного уровня значимости.

 Попробуем провести этот тест на наших данных:

```{r message=F, warning=F}
#install.packages("EnvStats")
library(EnvStats)
test <- rosnerTest(df$age,
  k = 3
)
test
```

Видим, что результаты также схожи с теми, что мы получили в ходе анализа стандартизированных значений, что неудивительно, учитывая сходство статистических процедур. 

### Проверка на нормальность

Подчиняются ли анализируемые количественные переменные закону нормального распределения вероятностей? Очень многие статистические методы предполагают положительный ответ на этот вопрос, и поэтому проверка исследуемых переменных на нормальность распределения является важной составной частью разведочного анализа данных.

Как известно, кривая нормального распределения имеет красивый «колоколообразный вид» и описывается формулой функции плотности вероятности (probability density function, PDF): 

$$f(x) = \frac{e^{-(x - \mu)^{2}/(2\sigma^{2}) }} {\sigma\sqrt{2\pi}}$$

```{r echo=FALSE}
curve(dnorm(x, 0, 1), from=-4, to=4)
```


Например, мы желаем проверить гипотезу о равенстве средних значений в двух независимых выборках. Для этой цели подходит критерий Стьюдента. Но применение критерия Стьюдента обосновано, только если данные подчиняются нормальному распределению. Поэтому перед применением критерия необходимо проверить гипотезу о нормальности исходных данных. Или проверка остатков линейной регрессии на нормальность — позволяет проверить, соответствует ли применяемая модель регрессии исходным данным.

Нормальное распределение естественным образом возникает практически везде, где речь идет об измерении с ошибками. Более того, в силу центральной предельной теоремы, распределение многих выборочных величин (например, выборочного среднего) при достаточно больших объемах выборки хорошо аппроксимируется нормальным распределением вне зависимости от того, какое распределение было у выборки исходно. 

Проверяя условие нормальности распределения данных, необходимо, однако, хорошо представлять себе, в каких случаях его выполнение является критическим для применения конкретного статистического метода. Так, например, метод главных компонент (Principle Components Analysis, PCA) не требует, чтобы данные были распределены нормально. Линейная регрессия (Linear Regression) хотя и предполагает нормальность распределения зависимой переменной, является достаточно робастным методом при незначительных отклонениях от этого условия. В то же время для успешного применения дискриминантного анализа (Discriminant Analysis) нормальность распределениях признаков в каждой группе классифицируемых объектов - условие обязательное (Мастицкий, 2012).


Проверку выборки на нормальность можно производить несколькими путями. 

- Большое распространение получили графические методы – анализ распределения с помощью гистограммы, диаграммы плотности, визуально показывающие, насколько велики отклонения от нормальности.

Мы уже строили для наших данных квантиль-квантиль график, гистограмму и ящичную диаграмму. Пожалуй, единственный график, который мы еще не делали - график плотности.

```{r warning=FALSE}
 ggplot(df, aes(x=age)) + 
  geom_density(fill="lightblue")+
  theme_bw()
  
```

- Можно использовать и данные описательных статистик, помня как в нормальном распределении соотносятся среднее, мода, медиана, какими должны быть асимметрия и эксцесс, выполняется ли «правило 3-х сигм». Обычно обращают внимание на показатели асимметрии и эксцесса, анализируют их абсолютные значения и сравнивают их со стандартными ошибками. 
Выше мы пробовали функцию `describe()` из библиотеки `psych`. Еще один хороший вариант - функция `Desc()` из библиотеки `DescTools`:

```{r}
library(DescTools)
Desc(df$age, plotit = TRUE)
```

Отдельно можно посчитать показатели асимметрии и эксцесса вместе с доверительными интервалами. У нормального распределения они должны быть близкими к нулю.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Negative_and_positive_skew_diagrams_%28English%29.svg/669px-Negative_and_positive_skew_diagrams_%28English%29.svg.png)
![](https://img.tfd.com/mk/K/X2604-K-11.png)

Асимметрия:

```{r}
Skew(df$age, na.rm=TRUE, conf.level = 0.95, ci.type = "classic")
```

Эксцесс:
  
```{r}
Kurt(df$age, na.rm=TRUE, method=2, conf.level = 0.95, ci.type = "classic")
```


- особая группа методов — критерии нормальности. Их существует множество - по меньшей мере 15. Подробные материалы про все критерии с формулами и нюансами интерпретации можно посмотреть [вот здесь](https://yadi.sk/i/QwrWjkIkrKAwF)


В R реализованы практически все имеющиеся тесты на нормальность — либо в виде стандарных функций, либо в виде функций, входящих в состав отдельных пакетов. Примером базовой функции является `shapiro.test()`, при помощи которой можно выполнить широко используемый тест Шапиро-Уилка

#### Тест Шапиро-Уилка

Тест Шапиро-Уилка был впервые опубликован в 1965 году Самюэлем Санфордом Шапиро и Мартином Уилком.

$$W=\frac{(\Sigma^n_{i=1}a_ix_{(i)})^2}{\Sigma^n_{i=1}(x_i-\bar{x})^2}$$
где:

$x_i$ – упорядоченные значения анализируемой переменной
$a_i$ – константы, созданные на основе ковариаций, дисперсий и средних значений по выборке (размера $n$) из нормального распределения (обычно берутся из таблиц).

Считается одним из лучших и наиболее мощных тестов.

```{r}
shapiro.test(df$age)
```

Основные классические критерии проверки на нормальность собраны в пакете `nortest`. Пакет можно установить с CRAN при помощи вызова функции `install.packages()`:

```{r eval=FALSE}
install.packages("nortest")
```


#### Тест Колмогорова-Смирнова

наверное, одним из самых известных является тест Колмогорова-Смирнова, носящий имена российских математиков Андрея Николаевича Колмогорова и Николая Васильевича Смирнова.

Статистика  $D$ Колмогорова-Смирнова вычисляется как максимум модуля разности между эмпирической и теоретической функциями распределения. Эта статистика критерия согласия используется для проверки гипотезы о том, что наблюдения взяты из указанного распределения:

$$D = \max_{1 \le i \le N} \left( F(Y_{i}) -
               \frac{i-1} {N}, \frac{i}{N} - F(Y_{i}) \right)$$
где $F$ является теоретическим кумулятивным распределением, которое должно обязательно принадлежать к семейству непрерывных распределений. Нулевая гипотеза отклоняется в случае, если тестовая статистика, $D$, превышает критическое значение.

Когда данные сравниваются с теоретическим нормальным распределением, используется поправка Лиллиефорса.

```{r}
nortest::lillie.test(df$age)
```
```{r warning=FALSE}
plot(ecdf(scale(df$age)), col="red", main="Эмпирическая и теоретическая кумулятивные функции")
curve(pnorm, from = -10, to = 10, add = TRUE, col="blue")
```

#### Тест Андерсона-Дарлинга

Тест Андерсона-Дарлинга (Stephens, 1974) используется для тестирования гипотезы о том, что выборочные данные имеют специфическое распределение. Это модификация теста Колмогорова-Смирнова (K-S test), в которой больший вес придается крайним значениям (хвостам), по сравнению с оригинальным тестом

Формула для вычисления критерия такова:

$$A^{2} = -N - S$$

$$S = \sum_{i=1}^{N}\frac{(2i - 1)}{N}[\ln{F(Y_{i})} + \ln{(1 - F(Y_{N+1-i}))}]$$

где $F$ - это кумулятивная функция распределения, показывающая вероятность того, что целевое значение меньше указанного значения либо равно ему.

В библиотеке `nortest` тест Андерсона-Дарлинга реализован в функции `ad.test()`:
```{r}
nortest::ad.test(df$age)
```

#### Тест Крамера-фон-Мизеса

Тест Крамера-фон-Мизеса является еще одной альтернативой тесту Колмогорова-Смирнова и представляет собой комплексный тест для проверки нормальности. Он использует сумму квадратов различий между наблюдаемыми и ожидаемыми кумулятивными пропорциями в качестве тестовой статистики. 

Тест имеет следующую формулу:

$$\begin{align}
W_n^2:=n\int(F_n(x)-F_0(x))^2\,\mathrm{d}F_0(x).
\end{align}$$

Если $H_0: F=F_0$ справедливо, то  $W^2_n$ являются маленькими значениями. Соответственно, отвержение гипотезы происходит при больших значениях $W^2_n$. Считается, что тест Крамера-фон-Мизеса более мощный, по сравнению с классическим тестом Колмогорова-Смирнова.

В библиотеке `nortest` для теста Крамера-фон-Мизеса используется функция `cvm.test()`:
```{r}
nortest::cvm.test(df$age)
```

## Анализ категориальных переменных

Рассмотрев возможности разведочного анализа количественных переменных, перейдем к категориальным данным, представленным в номинальных и порядковых шкалах

### Описание таблиц без их представления в тексте

Во многих случаях в ходе анализа нам нужны просто цифры, ведь не все результаты представляются в виде таблиц и графиков, что-то просто описывается словами, поэтому иногда проще и быстрее использовать базовый код, без премудростей.

Представим ситуацию, что мы описываем нашу выборочную совокупность и хотим представить информацию по количеству опрошенных по разным регионам исследования.

Итак, если нам нужны простые частоты, не проценты, одним из простых решений будет функция из базового R `table ()`. 

Например, посмотрим распределение по регионам, предварительно переведя все переменные факторные, поскольку их большинство:

```{r echo=TRUE}
df <- haven::as_factor(df)
table(df$Region)
```



Если нам нужны не абсолютные, а относительные частоты по отдельным вопросам, для которых мы не собираемся делать какие-то таблицы или графики (то есть эти данные нужны только для описания), то для этой цели можно использовать , базовую функцию `prop.table`. 

Например, мы хотим узнать пропорции по полу во всех регионах исследования (умножим на 100, чтобы получить значения в процентах, а не долях: 

```{r}
prop.table(table(df$V1))*100

```
С помощью этих же функций можно создать и двумерные таблицы:
```{r}
prop.table(table(df$V1, df$Region), margin = 2)*100
```

Более интересный вариант предлагает функция `flat_table` (переводится как "плоская таблица") из библиотеки `sjmisc`. 


```{r echo=TRUE}
sjmisc::flat_table(df, V1, margin = "cell")
```

Мы видим, что в наших исследованиях приняло участие гораздо больше женщин (почти 68%), чем мужчин (35%).

Если нужна двумерная таблица, функция `flat_table` также подойдет (так же как и функции `prop.table`, `sjt.xtab` и другие, запомним, что в R всегда можно сделать одно и то же разными путями, здесь дело вкуса):


```{r echo=TRUE}
table<-sjmisc::flat_table(df, Region, V1, margin = "row")# df - наша база данных, Region V1 - переменные для строк и столбцов, margin = "row"  - процент по строке
table

```

Выглядит не очень с точки зрения оформления, зато мы быстро получили результаты и можем их описать. Видим, что женщины превалируют во всех регионах, из доля составляет более 60%, в Республике Тыва - 75%.

Более того, мы можем сохранить эту таблицу в формате датафрейма и потом использовать в других приложениях:
```{r}
table<-tidyr::as_tibble(table)
table
```

Если мы посмотрим, то получилось не совсем то, что нам бы хотелось: у нас получилась таблица в «длинном формате», вместо широкого. К счастью это можно быстро исправить с помощью уже знакомой нам функции `pivot_wider()`из библиотеки `tidyr`, являющейся частью экосистемы `tidyverse`.

```{r}
library(tidyr)
table<-table %>% 
  pivot_wider(names_from = V1, values_from = Freq)
table
```

Еще нам постоянно мешает это единственное наблюдение из Монголии. Давайте его уберем и пересчитаем все заново.

Для начала отфильтруем переменную `Region` так, чтобы в нее входили все регионы, кроме Монголии:

```{r}
library(dplyr)
df<-df %>% 
  filter(Region!="Монголия")
```

Попробуем сделать простую таблицу:
```{r}
table(df$Region, df$V1)
```
Как видим, наблюдение мы удалили, но метка (уровень факторной переменной) осталась, и нам нужно его убрать. Сделать это можно с помощью функции `droplevels`. Удалим уровень и сделаем новую таблицу
```{r}
df$Region<-droplevels(df$Region)
sjmisc::flat_table(df, Region, V1, margin = "row")
```
Все получилось!

Между тем, очевидно, что для хорошей статьи (диссертации, отчета об исследовании) описания результатов частотного анализа недостаточно, требуется представлять результаты комплексно, сразу по нескольким переменным, часто с учетом группировки, и приводить доказательства значимости имеющихся различий на основе применения статистических методов.

### Создание таблиц по нескольким переменным: возможности библиотек `gtsummary` и `flextable`

* **flextable** -- чудо-библиотека от Дэвида Гоэля - француза и сотрудника ArData, созданная специально для работы с таблицами и улучшения их отображения в различных форматах, в частности в Word и Power Point
* **gtsummary** -- библиотека для создания эффектных таблиц с описательными статистиками для научных публикаций

Предположим, что для нашей будущей статьи, которую мы готовим по результатам исследования, мы хотим создать большую таблицу, содержащую распределения сразу по нескольким переменным, описывающим все важные демографические и социальные характеристики, такие как пол, возраст по группам, социальный статус, в том числе - с учетом региональных различий. Желательно также посчитать, являются ли эти различия значимыми, используя для этого критерий $\chi^2$ Пирсона. 

Библиотека `gtsummary` была создана специально для того, чтобы быстро создавать гибкие с точки зрения форматирования таблицы с описательными статистиками и результатами регрессионного анализа, оформленные по стандартам для научных публикаций. 

Настоятельно рекомендуется посетить сайт проекта и подробно ознакомиться с возможностями данной библиотеки. 
https://www.danieldsjoberg.com/gtsummary/index.html

Для начала создадим общую таблицу, где в строках будут располагаться данные по возрасту, полу, региону проживания, социальному статусу, а также наличию гражданства другой страны.

```{r, message = FALSE, warning=FALSE}
library(dplyr)
#install.packages("gtsummary") - убрать решетку и запустить строку
library(gtsummary)
#вспоминаем урок по dplyr
table<-df %>% 
  select(Region, V1, age_cats3, V10, V6)  #отберем нужные переменные в отдельный сет и сохраним его под именем table
# создадим таблицу
table %>% 
  tbl_summary(missing="no") #функция tbl_summary позволяет создать комплексные таблицы

```


В принципе, очень неплохо. Добавим группировку по региону и поменяем заголовок у переменных с "Characteristic" на "Характеристику":

```{r, message = FALSE, warning=FALSE}
table %>% 
  tbl_summary(by=Region, missing="no") %>%#by=V004 - так мы обозначаем группирующую переменную
  modify_header(#функция, позволяющая изменить заголовок
    update = list(
      label ~ "Характеристика" #
    )
  )
```

Прочитать подробнее о функции tbl_summary, ее атрибутах, с подробным разбором примеров и возможностей изменения таблицы:
http://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html

Можно сделать и простую двумерную таблицу:
```{r}
 table %>%
  tbl_cross(row = V1, col = age_cats3, percent = "cell", missing="no", ) %>%
  add_p(test="chisq.test") %>% #добавляем статистику хи-квадрат
  modify_header(#функция, позволяющая изменить заголовок
    update = list(
      label ~ "**Характеристика**" #
    )
  ) %>% 
  modify_caption("**Взаимосвязь пола и возраста** (N = {N})") #меняем заголовок на нужный, причем заголовок вставляем количество опрошенных
```

 

### Пример анализа вопроса с множественными ответами

Для выполнения данного задания нам понадобится `questionr` - библиотека, позволяющая анализировать таблицы с множественными ответами.

Прежде чем выполнить последующий код, установите пакет questionr на свой комьютер и запустите библиотеку:
```{r, fig.width=10, fig.height=3}
#install.packages("questionr") - убрать решетку и запустить строку
library(questionr)
```

У нас в анкете был вопрос 9, в котором изучалось, чем владеет домохозяйство. Можно было выбрать несколько вариантов ответа, а также дать собственный вариант ответа - «Другое». Ответы были закодированы дихотомическим способом, выбор кодировался как 1, а его отсутствие - как 0. 

Как в других программах статистической обработки, в R нам потребуется сделать два шага для того, чтобы проанализировать вопрос с множественным выбором:
- создать набор данных, в который объединяются отдельные подвопросы;
- сделать таблицу, которая может быть как одномерной, так и многомерной.

Давайте объединим все подвопросы вопроса V9 в один набор и сохраним его под отдельным именем  - V9. Воспользуемся знакомыми нам функциями `select()` - для отбора переменных и `contains()` - отбора переменных, имена которых содержат определенный паттерн:

```{r message=FALSE, warning=FALSE}
library(dplyr)
V9<-df %>% 
  select(contains("V9")) %>% 
  select_if(is.factor)#дополнительный select нужен, чтобы убрать текстовую переменную «другое»
```

Далее, создадим таблицу и сохраним ее в качестве отдельного датафрейма.

```{r}
library(questionr)
library(dplyr)
V9tab<-V9 %>% 
multi.table(true.codes=list("да"), freq=TRUE) %>% 
    as.data.frame() %>% 
  rename(Pct=`%multi`) %>% 
  arrange(desc(Pct))
V9tab
```
Да, выглядит так себе, но зато все посчитано) сразу.

Поясним, что `true.codes=list("да")` - обозначаем вариант ответа, используемый для подсчета частот и процентов, `freq=TRUE` - вывод процентов, а не только частот.


Как добавить метки вопросов в нашу таблицу? 
Извлечем метки вопросов по блоку V9 в отдельное место:


```{r message=FALSE, warning=FALSE}
library(sjlabelled)
V9labs<-df %>% 
select(contains("V9")) %>% 
  select_if(is.factor) %>% 
  get_label()
V9labs
```

Присвоим имена в переменную `n`:
```{r}
V9tab$n<-V9labs
V9tab
```

### Таблица сопряженности с множественными ответами


```{r}
V9Regiontab<-cross.multi.table(V9, df$Region, true.codes=list("да"), freq=TRUE)
V9Regiontab<-as_tibble(V9Regiontab)
V9Regiontab$n<-V9labs
V9Regiontab<-V9Regiontab %>% 
  relocate(n)
```


### Графики для категориальных переменных

Основными графиками для категориальных переменных являются круговые и столбиковые диаграммы, а также мозаичные и ассоциативные графики, когда в анализе задействовано более двух переменных.

Давайте создадим такие графики для переменных по возрасту. Красивые минималистичные графики с небольшим количеством кода и исправлений можно создать с помощью библиотеки `ggpubr` от Alboukadel Kassambara (биолог, автор книг по биоинформатике и биологии рака).

Создадим одномерную таблицу для возраста и двумерную для взаимосвязи между полом и возрастом.

```{r}
age<- as.data.frame(sjmisc::flat_table(df, age_cats3, margin = "cell", digits = 1))
age_sex<-as.data.frame(sjmisc::flat_table(df, age_cats3, V1, margin = "row", digits = 1))
```

Сделаем простую столбиковую диаграмму по возрастным группам, в качестве «изюминки» добавим красивые шрифты.

Прежде чем сделать сам график, установим шрифты, чтобы потом ими можно было пользоваться постоянно.
```{r eval=FALSE}
install.packages("extrafont")
library(extrafont)
font_import()#шрифты устанавливаются сразу все, это может занять некоторое время
```

```{r echo=FALSE, message=FALSE}
library(extrafont)
```

В результате будут импортированы следующие шрифты:
![](http://gradientdescending.com/plots/fonttable_big.png)
После установки шрифты нужно загружать каждую сессию: 
```{r}
loadfonts(device = "win", quiet = TRUE)
```

Теперь займемся самим графиком.
Разберем его структуру строчка за строчкой:
- `ggplot(data=age, aes(x=age_cats3, y=Freq)) +` - создаем базовый график, где по оси x у нас будут возрастные категории, а по y - проценты
- `geom_bar(stat="identity", fill="steelblue", width = 0.6)+` - добавляем слой для столбиковой диаграммы, `stat="identity"` - означает, что мы будем использовать данные «как есть», а не агрегировать на основе исходных, `fill="steelblue"` - задаем цвет, `width = 0.6` - устанавливаем ширину столбцов чуть меньше обычного, для красоты))
- `geom_text(aes(label=scales::number(Freq,accuracy=0.1, decimal.mark = ",")),  family = "Ink Free", vjust=0.5, hjust=-0.5, color="steelblue", size=4)+` - тут много всего, эта часть кода отвечает за подписи к столбцам. `label=number(Freq,accuracy=0.1, decimal.mark = ","))` - устанавливаем подписи в числовом формате, запятую в качестве разделителя и округление до одного знака после запятой, `family = "Ink Free", vjust=0.5, hjust=-0.5` - задаем шрифт Ink Free, делаем выравнивание, чтобы число было ровно посредине столбца и слегка выходило за его пределы (можно поэкспериментировать с этими настройками), `color="steelblue", size=4` - эти настройки отвечают за цвет и размер текста
- `coord_flip()` - переворачиваем диаграмму в горизонтальную проекцию
- `theme_void()`- устанавливаем тему, в которой есть только белый фон
- `expand_limits(y=c(0,50))` - раздвигаем границы по оси y, там, где проценты (это неважно, что при повороте диаграмма «ложится на бок» и оси вроде как меняются местами)
- `theme(axis.text.y = element_text(size = 10, family = "Ink Free")` - устанавливаем размер и семейство шрифтов для подписей - категорий возраста
- `scale_x_discrete(limits=rev)` - ну и, напоследок, меняем порядок категорий, от младшей возрастной группы к старшей
```{r}
#| fig-width: 7
#| fig-height: 3
library(ggplot2)
library(scales)#нужна для того, чтобы отформатировать подпись
ggplot(data=age, aes(x=age_cats3, y=Freq)) +
  geom_bar(stat="identity", fill="steelblue", width = 0.6)+
  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = ",")),  family = "Ink Free", vjust=0.5, hjust=-0.5, color="steelblue", size=4)+
  coord_flip()+
  theme_void()+
  expand_limits(y=c(0,50))+
  theme(axis.text.y = element_text(size = 10, family = "Ink Free"))+
  scale_x_discrete(limits=rev)
```

Добавим данные по полу. В нашем коде почти ничего не поменялось, за исключением некоторых моментов:
- `fill=V1` - мы добавили в исходный график, чтобы сделать разбивку по полу
- в `geom_bar(stat="identity", position="dodge", width = 0.6)` добавили `position="dodge"` - чтобы столбцы располагались рядом друг с другом, такой же аргумент добавлен и в `geom_text`
- в конце появилось две новых строки   `theme(legend.position="bottom")+  theme(legend.title=element_blank())`, они нужны для оформления легенды

```{r}
#| fig-width: 7
#| fig-height: 3
library(ggplot2)
library(scales)#нужна для того, чтобы отформатировать подпись
ggplot(data=age_sex, aes(x=age_cats3, y=Freq, fill=V1)) +
  geom_bar(stat="identity", position="dodge", width = 0.6)+
  geom_text(aes(label=number(Freq,accuracy=0.1, decimal.mark = ",")),  position = position_dodge(width = 0.6), hjust=-0.3, family = "Ink Free", size=4)+
  coord_flip()+
  theme_void()+
  expand_limits(y=c(0,100))+
  theme(axis.text.y = element_text(size = 10, family = "Ink Free"))+
  scale_x_discrete(limits=rev)+
  theme(legend.position="bottom")+
  theme(legend.title=element_blank())
```

 В качестве альтернативы можно создать сгруппированные столбиковые диаграммы в библиотеке `ggstatsplot`:
 

```{r}
ggstatsplot::ggbarstats(df, x = V1, y = age_cats3)
```
 
 
 создать круговую диаграмму:
 
```{r warning=FALSE}
#| fig-width: 4
#| fig-height: 4
ggplot(age, aes(x = "", y = Freq, fill = age_cats3)) +
  geom_col(color = "black") +
  geom_label(aes(label=number(Freq,accuracy=0.1, decimal.mark = ",")), color = "white",
            position = position_stack(vjust = 0.5),
            show.legend = FALSE) +
  guides(fill = guide_legend(title = "Возраст")) +
  scale_fill_viridis_d() +#эта строка добавляет цветовую палитру
  coord_polar(theta = "y") + 
  theme_void()
```
 
 
 Более простым решением является создание круговой диаграммы с помощью функции `ggpiestats` из библиотеки `ggstatsplot`:


```{r}
ggstatsplot::ggpiestats(df, age_cats3, legend.title = "Возраст")

```
С помощью этой же функции можно создать серию круговых диаграмм:
```{r}
ggstatsplot::ggpiestats(df, V1, age_cats3)
```
Посмотреть отдельно хи-квадрат:

```{r}
chisq.test(df$V1, df$age_cats3)
```

Сделаем график для вопросов с множественными ответами, по вопросу V9. В описаниях вариантов ответов есть длинные формулировки, которые будут не очень хорошо смотреться на графике, поэтому прежде, чем создавать график, давайте уберем все, что написано в скобках, так как это скорее не основная, а уточняющая информация.

Для этого мы воспользуемся функцией `gsub`, в которую включим выражение, позволяющее отсечь текст, лежащий после знака `(`.


```{r}
V9tab$n<-gsub("\\(.*", "", V9tab$n)
```

Хотя в таблице значения отсортированы, на графике они все равно будут отображаться в том порядке, в котором представлены уровни факторной переменной. Поэтому, чтобы на графике у нас были отображены значения по убыванию (мы же не хотим, чтобы у нас получился хаос из 14 вариантов ответа), нам нужно отсортировать уровни,  для чего нам потребуется библиотека `forcats`.

И поскольку ширина подписей, несмотря на то, что мы их сократили, будет довольно существенной, мы сделаем самые длинные подписи в две строки, что, в свою очередь, потребует работы с библиотекой `stringr` (раз это новые для нас библиотеки и мы про них не слышали, нужно их установить).
```{r}
library(forcats)
library(stringr)
#| fig-width: 200%
V9tab %>%
  mutate(n = fct_reorder(n, Pct)) %>% # переставим местами уровни
ggplot(aes(x=n, y=Pct, fill=n)) + # создадим типовой график
  geom_bar(stat="identity", width = 0.6)+  # добавим geom
  geom_text(aes(label=number(Pct,accuracy=0.1, decimal.mark = ",")), hjust=-0.3, family = "Ink Free", size=4)+   # поработаем с подписями данных
  expand_limits(y=c(0,80))+# увеличим лимит оси 
  coord_flip()+  # перевернем график в горизонтальное положение
  theme_void()+   # добавим минималистичную тему
  theme(axis.text.y = element_text(size = 10, family = "Ink Free"))+    # установим шрифт для подписей
  theme(legend.position="none")+       # уберем легенду
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30))       # Сделаем длинные подписи в несколько строк
```

## Самостоятельная работа

1. Провести комплексную проверку на нормальность переменной `Sepal.Length` из набора `iris.
2. Провести одномерный анализ по переменным V12, V13, V15. Сделать двумерный анализ по региону и возрасту.
3. Проанализировать переменные с множественным выбором V14 и V16, также сделать двумерный анализ по региону. По всем видам анализа сделать таблицы и графики.
4. Представить все в виде отдельного документа - по желанию в каком формате.

